# 决策树

对于一个分类问题, 假设数据集{Xi}有n个样本, p个特征, 类别值Yi有k个取值。

想要建立一个模型对这样的数据进行分类, 理论上只要将样本空间划分为k个不相交的区域就可以了, 简单的做法有LDA和kNN. 

- LDA的决策边界是线性的 => 线性决策边界太弱鸡
- 而kNN的决策边界是非线性的 => 惰性学习, 遇到大规模数据就炸



决策树每次选择一个特征, 在这个特征上对样本空间进行划分

- 在划分的子样本空间上, 选择未被使用的离散特征(或已被使用的连续特征), 继续划分子空间
-  这样递归地下去, 直至无法划分或者满足某个准则



关键点：

- 如何构建树
- 如何选择最优属性



## ID3

使用信息增益作为准则 => 生成多叉树

- 偏向于选择可取值较多的属性



## C4.5

使用信息增益率作为选择准则 => 生成多叉树



## CART(分类与回归树)

使用基尼指数

- CART内部是二叉树
  - 结点的特征取值为"是"和"否", 左分支为"是", 右分支为"否"



构建决策树时, 一个叶子节点可以满足数据集中的多个样本$D_k$

- 在分类的情况下, 叶子节点的类别就是$D_k$中优势样本的类别
- 在回归的情况下, 叶子节点的值是$D_k$标签值的均值
  - CART在处理回归问题时并不是像线性回归那样, 能够将样本空间映射到无穷的实域, 而是**有限的点集**.





# [Gradient Boosting](https://statweb.stanford.edu/~jhf/ftp/trebst.pdf)

用每一轮的基学习器去拟合当前模型的梯度

对残差的学习

- 梯度是残差的近似

## 导论

假设要在数据集$\{(x_i, y_i)\}$上训练一个函数F(X), 使得损失函数$L(y,F(x))$在(x,y)的联合分布上最小化

那么有

- 注意：每进行一次期望，相当于对边缘分布进行积分，消除该边缘分布变量⭐
  - 期望的定义：在概率空间上做积分
  - ![image-20210420104141773](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210420104142.png)

$$
F^* = arg min_F E_{y,x} [L(y, F(x))] = arg min_F E_{x} [E_y(L(y, F(x)))|x]
$$

可以定义参数化的函数簇, 来约束这样的F(X), 即F(x; P)



==将该函数定义为**加法模型**==, 则函数形式可写为：

- ==h为基函数==`@SuS：正交基底`
- $a_m$为基函数的参数
- $β_m$为加法模型权重

$$
F(x; \{ \beta_m, a_m\}_1^M) = \sum_{m=1}^M \beta_m \cdot h(x; a_m)
$$

### 参数空间|数值优化

对于上面定义的可以, 找到最优的参数$P^∗$, 就找到了最优函数。

可以通过数值优化的方法求解最优参数$P^∗$
$$
P^* = arg min_P \ \Phi(P)
$$

$$
\Phi(P) = E_{y,x}[L(y, F(x; P))]
$$

数值优化的求解过程是一个迭代的过程, 因此可以将$P^∗$写为`@me|启发：将数值优化应用到机器学习当中`
$$
P^*=\sum_{m=0}^M  p_m
$$
其中$p_0$是初始值, $\{p_m\}_1^M$ 是迭代过程中的增量(步长)

- 可以理解为从p0开始, 迭代M−1次, 每次都会获得一个增量
- 最终$P∗$的值是初始值与迭代中增量的和

每一步的增量$p_m$可以用数值优化方法求解



#### 最速梯度下降法

根据参数空间当前的梯度值, 可以迭代地对参数进行优化

在迭代的每一步中, $p_m$处的梯度为
$$
g_m = g_{jm} = \{[\frac{\partial\Phi(P)}{\partial P_j}|_{P=P_{m-1}}] \}
$$

- 其中，$P_{m-1} = \sum_{i=0}^{m-1}p_i$



接下来要去求, 当前的迭代步长应该是多少，取$p_m=−ρ_m \cdot g_m$

这里$ρ_m$的求解如下：
$$
-\rho_m = arg min_{\rho} \Phi(P_{m-1} - \rho \cdot g_m)
$$
上面这个式子的含义是, 在当前梯度方向上, 取使得目标函数最小的最大步长, 即用最快的速度下降(最速梯度)

就是在当前的$P_{m−1}$处, 取沿着梯度方向尽可能地下降, 取最大的步长为$p_m$

- 这里的ρm可以通过线性搜索求出

这样一直迭代下去, 直到满足条件就能求出一个$P^∗$出来



### 函数空间的优化

上面的优化过程中, 固定了基函数的形式, 以及参数的数量, 优化过程是在**参数空间**完成的

如果基函数是非参数化形式, 就引入了函数空间的优化



将F(X)在每个x点处的值当作一个"参数", 优化目标为
$$
\Phi(F) = E_{y, \bold{x}}[L(y, F(\bold{x}))] = E_{\bold{x}} [E_y(L(y, F(\bold{x})))|\bold{x}]
$$

- 等价于在每个x点处定义：$\Phi(F(\bold{x})) = E_{y}[L(y, F(\bold{x}))|\bold{x}]$

函数空间有无数个点, 但是我们的数据集只有有限个点



类似于在参数空间的优化过程, 这里也将函数写成加法形式：
$$
F^*(\bold{x}) = \sum_{m=0}^M f_m(\bold{x})
$$
同样的, 有$f_0(\bold{x})$是初始的猜测,$\{f_m(\bold{x})\}_1^M$是函数增量

同样地用最速下降法, 有$f_m(\bold{x})=-\rho_m \cdot g_m(\bold{x})$



同样地有$F_{m-1}(\bold{x}) = \sum_{i=0}^{m-1}f_i(\bold{x})$

这里导数为

![image-20210420103939819](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210420103940.png)

![image-20210420104021485](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210420104021.png)

#### 交换积分求导顺序

假设各种规律性都非常好, 接下来我们可以做积分求导交换顺序了 [Leibniz integral rule, **莱布尼茨积分法则**](https://en.wikipedia.org/wiki/Leibniz_integral_rule)



### 数据有限的情况

在求解梯度的时候用到了期望的计算

然而在实际上有限的数据集中, 对$E_y[⋅|\bold{x}]$是不准确的

> 原文
>
> *Strength must be borrowed from nearby data points by imposing smoothness on the solution. *
>
> *One way to do this is to assume a parameterized form such as (2) and do parameter optimization as discussed in Sec 1.1 to minimize the corresponding data based estimate of expected loss.*

既然解决不了上面那个问题, 那就带一些先验进去, 假设函数的形式是如(GBM 2)的参数形式. 然后用参数优化的方式最小化损失.



根据(GBM 2)的定义形式, 最优参数为

![image-20210420104413082](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210420104413.png)



#### 贪心思路⭐

- 原本是$\sum_{m=1}^M$，改为前一个基模型$F_{m-1}$与h(x)最新基模型($\beta$调整权重)的和

在没有可行解的情况下, 可以==使用greedy-stagewise去优化参数==, 对m=1,2,…,M

![image-20210420104429494](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210420104429.png)

在求完每个stage的参数后, 更新函数形式.

但是有时候，对于特定的损失函数或是基学习器，上式很难求解



这时候需要换一个角度：

![image-20210420104457332](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210420104457.png)



类比于梯度下降法, 上式可以看作是在当前位置$F_{m−1}(\bold{x})$沿着方向$h(\bold{x};a_m)$前进了$β_m$. 但是因为已经假定了h(x)的函数簇, 相当于是在限制了函数簇的有约束最速下降



类似地, 基于数据的无约束下的梯度形式为：

![image-20210420104654754](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210420104655.png)


在$F_{m−1}(\bold{x})$的N维数据空间中, 获得的$−g_m={−g_m(\bold{x}_i)}_1^N$

这里的梯度都是定义在数据点上的, 并不能推广到其他位置, 为了让这个信息能够泛化, 既然已经定义了h(x)的函数簇, 那就用h(x)去生成$h_m={h(\bold{x}_i;a_m)}_1^N$, 尽可能平行于$−g_m$.(在数据点上尽可能接近, 这里还是在函数空间内优化)

拟合梯度在这里出现了, 因此有

![image-20210420104913167](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210420104913.png)

可以得到

![image-20210420104934154](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210420104934.png)

这一步完成后, 就可以进一步更新F(x).

![image-20210420104457332](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210420104457.png)



这里就讲完了, 为什么会去做拟合梯度这样一个事情

由此导出了广义的最速下降求解方式

![image-20210420105009275](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210420105009.png)



### 拟合残差是什么？

GBDT的方法里讲了梯度是怎么来的, 那拟合残差又是什么情况?

对于回归树来说, 损失函数为：

![image-20210420105100026](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210420105100.png)

求偏导：最后的结果也就是残差
$$
\frac{\partial L}{\partial F} = \tilde{y}_i = y_i - F_{m-1}(x_i)
$$


## GBDT

在参数空间中的梯度优化很好理解, 那个累加的形式就是从起始点加上每一步的偏移量

同样的类比, 在函数空间优化也是可以这样理解

- 不严谨的说法是, 在函数空间中, 起始点是一个函数, 同样是梯度下降法, 这里的增量是函数



所以$F_m(\bold{x})=F_{m−1}(\bold{x})+h(\bold{x};a_m)$：就是每次在当前的点, 偏移$h(\bold{x};a_m)$, 即函数空间的梯度下降



## Xgboost

在GBDT的基础上进行改进， 基学习器是CART

目标函数

- 损失函数的近似：泰勒展开 + 决策树等价变形
- 添加正则项



Shrinkage|基学习器/基模型：因子$\eta$



列抽样|随机森林：随着学习器的数量增加, 随机森林可以收敛到更低的泛化误差



节点分裂|近似贪心算法

- 特征的所有取值进行排序
- 然后按照数据的分位数(分位点, quantile)进行分割, 通俗地来说类似于将数据放入n个桶中



分位数加权：近似算法的设定基础上, 并不是直接按照特征的取值进行分位点划分 => 二阶导数$h_i$

分位数公式：

![image-20210420105735339](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210420105735.png)

### 缺失值处理

在C4.5和CART算法中， 出现缺失值后将样本**划分到每个子结点中**， 同时调整它的权值

在XGBoost中, 对每个特征会学到一个最优的划分方向, 在该特征上出现缺失值时, 就把样本划分到学到的最优方向上



### 工程|并行设计

预先对数据进行了排序，然后保存为 block结构，后面的迭代中重复地使用这个结构，大大减小计算量。

block结构也使得可并行计算，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么==各个特征==的增益计算就可以开多线程进行。



## LightGBM

### 分裂点

GBDT中查找最佳分裂点需要遍历特征的取值

XGBoost中对特征按照二阶梯度进行排序, 创建桶去降低特征的取值数量, 加快查找速度

LightGBM使用histogram-based方法, 将查找分裂点的时间复杂度从(#data × #feature)降低到(#bin × #feature).



### 样本数量|Gradient-based One-Side Sampling(GOSS)

AdaBoost方法中, 每个样本都有对应的权重

在GBDT中没有, 不过GBDT中的样本梯度也可以表示样本的重要性



GOSS方法保留梯度值大的样本, 同时对梯度值小的样本进行采样, 用来降低训练时样本的数量



### 特征数量|Exclusive Feature Bundling(EFB)

EFB的设想是, 样本的特征是稀疏的, 通过对特征进行聚合, 可以将时间复杂度从(#data × #features) 降低到(#data × #bundle)

有些特征值不会同时为零, 那么这些特征便可以合并到一起



## Catboost

CatBoost为了更好的处理 GBDT 特征中的categorical features

- 库中的学习算法基于GPU实现，打分算法基于CPU实现



一般的特征工程中, 都会提前将categorical feature进行编码：

- 对于low-cardinality的特征, 可以直接用one-hot编码
- 对于high-cardinality的特征, 可以用target-encoding编码处理



CatBoost使用的是对称树, 自由度更小, 但是速度更快, 每个叶结点都可以被编码为一串二元数组, 可以快速进行打分



在GBDT的模型训练阶段，同样会因为训练数据与测试数据分布不同的问题产生预测偏移(Prediction Shift)和残差偏移(Residual Shift)的问题



CatBoost采用了排序提升（Ordered Boosting）的方式：

- 首先对所有的数据进行随机排列
- 然后在计算第 i 步残差时候的模型只利用了随机排列中前 i-1个样本





# #参考文献

[link: 原文|博客 2019.09.13](https://i.steer.space/blog/2019/09/from-decision-tree-to-catboost)

1. Classification and regression trees, http://pages.stat.wisc.edu/~loh/treeprogs/guide/wires11.pdf [↩](https://i.steer.space/blog/2019/09/from-decision-tree-to-catboost#fnref:1)
2. GBM的论文 1999|Greedy Function Approximation: A Gradient Boosting Machine, https://statweb.stanford.edu/~jhf/ftp/trebst.pdf [↩](https://i.steer.space/blog/2019/09/from-decision-tree-to-catboost#fnref:2)[↩](https://i.steer.space/blog/2019/09/from-decision-tree-to-catboost#fnref2:2)
3. XGBoost: A Scalable Tree Boosting System, https://arxiv.org/abs/1603.02754 [↩](https://i.steer.space/blog/2019/09/from-decision-tree-to-catboost#fnref:3)
4. LightGBM: A Highly Efficient Gradient Boosting Decision Tree, https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf [↩](https://i.steer.space/blog/2019/09/from-decision-tree-to-catboost#fnref:4)
5. CatBoost: gradient boosting with categorical features support, http://learningsys.org/nips17/assets/papers/paper_11.pdf [↩](https://i.steer.space/blog/2019/09/from-decision-tree-to-catboost#fnref:5)
6. Introduction to Boosted Trees, https://homes.cs.washington.edu/~tqchen/pdf/BoostedTree.pdf [↩](https://i.steer.space/blog/2019/09/from-decision-tree-to-catboost#fnref:6)

还有西瓜书决策树章节和统计学习方法的决策树,提升方法部分.



问题背景, 引入问题, 这部分设计是为了解决什么问题, 很有承接关系, 讲得比较清楚. 

而国内的书一般是直接定义一个问题, 解决一个问题, 而==很少讲为什么==.@知其然，更要知其所以然 => 提高泛化能力