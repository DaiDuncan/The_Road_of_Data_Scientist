link: 期刊 2017.06](https://www.jiqizhixin.com/graph/technologies/11fab423-a92b-48d5-8212-79b1ecb46551)

- [link: wiki|半监督学习](https://en.wikipedia.org/wiki/Semi-supervised_learning)

- [link: 原文paper](http://pages.cs.wisc.edu/~jerryzhu/ssl/pub/SSL_EoML.pdf)



> 美国威斯康星大学麦迪逊分校计算机系 Sheldon & Marianne Lubar 教授。
>
> [朱晓进](http://pages.cs.wisc.edu/~jerryzhu/)1993年毕业于上海交通大学并获得计算机学士学位，1996年获得美国卡内基梅隆大学计算机系的硕士学位，2005年，在CMU获得计算机科学博士学位。
>
> 其导师是计算机科学中人工智能、机器学习等领域的世界级大师John Lafferty。
>
> 朱晓进在CMU的博士论文为Semi-Supervised Learning with Graphs。
>
> 研究重点是机器学习。
>
> 2010年获得美国国家科学基金会CAREER奖，
>
> 2013年获得ICML经典论文奖。



半监督学习(Semi-Supervised Learning，SSL) 使用标记和未标记的数据来执行有监督的学习或无监督的学习任务。

属于无监督学习（没有任何标记的训练数据）和监督学习（完全标记的训练数据）之间。

许多机器学习研究人员发现，将**未标记数据**与**少量标记数据**结合使用可以显着提高学习准确性。

对于学习问题的标记数据的获取通常需要熟练的人类代理（例如转录音频片段）或物理实验（例如，确定蛋白质的3D结构或确定在特定位置处是否存在油）





半监督学习可进一步划分为**纯（pure）半监督学习**和**直推学习（transductive learning）**。

- 前者假定训练数据中的未标记样本**并非待预测的数据**，
- 而后者则假定学习过程中所考虑的未标记样本**恰是待预测数据**。

纯半监督学习是基于“开放世界”假设，希望学得模型能适用于训练过程中未观察到的数据，

而直推学习是基于“封闭世界”假设，仅试图对**学习过程中观察到的未标记数据进行预测**。



下图直观的表现出**主动学习**、**纯半监督学习**、**直推学习**的区别：

<img src="https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210420114935.png" alt="img" style="zoom: 50%;" />

[周志华，《机器学习》清华大学出版社; 第1版 (2016年1月1日) ]

人类对半监督学习问题的反应得出了关于未标记数据影响程度的不同结论。

更自然的学习问题也可以被视为半监督学习的实例。

- 许多人的概念学习包括**少量的直接资料指导**和**大量无标记的经验**。

- 人类婴儿对无标记自然类别的结构很敏感，例如狗和猫的图像，或男性和女性的脸《Younger B. A.; Fearing D. D. (1999). "Parsing Items into Separate Categories: Developmental Change in Infant Categorization"》。[15]最近的研究表明，婴儿和儿童不仅**考虑了可用的未标记示例**，而且还**考虑了产生标记示例的抽样过程**。

描述来源：wiki, URL：https://en.wikipedia.org/wiki/Semi-supervised_learning 





## 发展历史

Merz等人在1992年提出了SSL这个术语，并首次将SSL用于分类问题。

接着Shahshahani和Landgrebe展开了对SSL的研究。

协同训练方法由Blum和Mitchell提出，基于不同的视图**训练出两个不同的学习机**，提高了训练样本的置信度。

Vapnik和Sterin提出了TSVM(Transductive Support Vector Machine)，用于估计类标签的线性预测函数。

- 为了求解TSVM，Joachims提出了SVM (Support Vector Machine)方法，Bie和Cristianini将TSVM放松为半定规划问题从而进行求解。

许多研究学者广泛研究将期望最大算法(Expectation Maximum，EM)与高斯混合模型(Gaussian Mixture Model，GMM)相结合的生成式SSL方法。

Blum等人提出了最小割法(Mincut)，首次将图论应用于解决SSL问题。

Zhu等人提出的调和函数法(Harmonic Function)==将预测函数从离散形式扩展到连续形式==。

由Belkin等人提出的流形正则化法(Manifold Regularization)将流形学习的思想用于SSL场景。

Klein等人提出首个用于聚类的半监督距离度量学习方法，**学习一种距离度量**。

在半监督学习成为一个热门领域之后，出现了许多利用**无类标签的样例**提高学习算法预测精度和加快速度的学习方法，因此出现了大量改进的半监督学习方法。

Nigam等人将EM和朴素贝叶斯结合，通过引入加权系数动态调整无类标签的样例的影响提高了分类准确度，建立每类中具有多个混合部分的模型，使贝叶斯偏差减小。

Zhou和Goldman提出了协同训练改进算法，不需要充分冗余的视图，而利用两个不同类型的分类器来完成学习。

Shang等人提出一种新的半监督学习方法，能同时解决**有类标签样本稀疏**和**具有附加无类标签样例成对约束**的问题。



来源：半监督集成学习综述，计算机科学期刊，第44卷第 6A期，2017年6月



半监督学习的研究的历史可以追溯到20世纪70年代，这一时期，出现了自训练(Self-Training)、直推学习(Transductive Learning)、生成式模型(Generative Model)等学习方法。

到了20世纪90年代，对半监督学习的研究变得更加狂热，新的理论的出现，以及自然语言的处理、文本分类和计算机视觉中的新应用的发展，促进了半监督学习的发展，出现了协同训练（Co-Training）和转导支持向量机（Transductive Support Vector Machine，TSVM）等新方法。

来源：wiki, URL: https://en.wikipedia.org/wiki/Semi-supervised_learning#History 



### **主要事件**⭐

| 年份 | 事件                                              | 相关论文                                                     |
| ---- | ------------------------------------------------- | ------------------------------------------------------------ |
| 1998 | Blum, A., & Mitchell, T.首次提出协同训练          | Blum, A., & Mitchell, T. (1998, July). Combining labeled and unlabeled data with co-training. In Proceedings of the eleventh annual conference on Computational learning theory (pp. 92-100). ACM. |
| 2005 | Zhu, X.对半监督学习进行的回顾                     | Zhu, X. (2005). Semi-supervised learning literature survey.  |
| 2014 | Zhou, X., & Belkin, M对半监督学习方法进行讲解     | Zhou, X., & Belkin, M. (2014). Semi-supervised learning. In Academic Press Library in Signal Processing (Vol. 1, pp. 1239-1269). Elsevier. |
| 2015 | Rasmus, A., Berglund, M.,提出诞生半监督 ladderNet | Rasmus, A., Berglund, M., Honkala, M., Valpola, H., & Raiko, T. (2015). Semi-supervised learning with ladder networks. In Advances in Neural Information Processing Systems (pp. 3546-3554). |



## 发展分析

### **瓶颈**

目前对SSL的理论分析还不够深入。

当前大部分SSL利用的数据是**无噪声干扰的数据**，而且依赖的==基本假设==没有充分考虑噪声干扰下无类标签数据分布的不确定性以及复杂性，但是**在实际应用中通常难以得到无噪声数据**。

通常训练数据是随机选取的，即有类标签的样例和无类标签的样例**独立同分布**，但是在实际应用中，无类标签的样例可能来自与有类标签的样例分布不同或未知的场景，并且有可能带有噪声。

从各种SSL算法的实现过程可以看出，SSL问题大多为**非凸、非平滑问题**，或**整数规划和组合优化问题**，**存在多个局部最优解**，

- 例如求解SSL产生式方法目标函数的EM算法只能得到局部极大值
- 目前主要采用各种放松方法把目标函数==近似转化为凸或连续最优化问题==，不易得到全局最优解，算法的时空复杂性很高。



### **未来发展方向**

经过大量研究人员的长期努力，SSL领域的研究已取得了一定发展，提出了不少SSL方法，同时已将SSL应用于许多实际领域。

但目前这个领域的研究仍存在许多有待进一步解决的问题，未来的研究方向包括以下一些内容。



**理论分析**

目前对SSL的理论分析还不够深入。

==在类标签错误或成对约束不正确时==学习方法的性能如何改变，

- 选择**不同的正约束和负约束的比例**会对降维的性能造成什么影响，
- 除了通常采用的分类精度和运算速度之外，还有没有**其他更合适的评价指标**，
- 对学习性能起到改进作用的是准确的最优化求解算法，还是使用的学习模型中的数据表示和学习方法，
- 最优解对学习结果的影响有多大，未来还需要进一步探讨这些问题。



**抗干扰性与可靠性**

当前大部分SSL利用的数据是**无噪声干扰的数据**，而且依赖的基本假设没有充分考虑噪声干扰下无类标签数据分布的不确定性以及复杂性，但是在实际应用中通常难以得到无噪声数据。

未来需要研究如何根据实际问题选择合适的SSL方法，更好地利用无类标签的样例帮助提高学习的准确性和快速性，并减小大量无类标签数据引起的计算复杂性，可以考虑引入鲁棒统计理论解决该抗噪声干扰问题。

此外，大量实验研究证明当模型假设正时，无类标签的样例能够帮助改进学习性能；

- **而在错误的模型假设上，SSL不仅不会对学习性能起到改进作用，甚至会产生错误，恶化学习性能**。

如何验证做出的模型假设是否正确，选择哪种SSL方法能够更合适地帮助提高学习性能，除了己有的假设之外，还可以在无类标签的样例上进行哪些假设，新的假设是否会产生新的法，SSL能否有效用于大型的无类标签的数据，这些问题还有待未来研究.

此外，导致SSL性能下降的原因除了模型假设不符合实际情况外，还有学习过程中标记无类标签的样例累积的噪声，是否还有其他原因使无类标签的样例造成学习能力的下降，也是未来需要进一步研究的问题。



**训练样例与参数的选取**

通常训练数据是随机选取的，即有类标签的样例和无类标签的样例**独立同分布**，但是在实际应用中，无类标签的样例可能来自与有类标签的样例分布不同或未知的场景，并且有可能带有噪声。

==未来的研究需要找到一个好的方法将SSL和主动学习相结合==，选取有利于学习模型的训练样例，并确定SSL,能够有效进行所需要的有类标签的样本数量的下界。

此外，许多研究人员将SL和UL二算法扩展用于SSL，但是许多这些算法是根据先验信息得到训练数据集的参数，并利用这些参数改进算法在SSL中的性能.目前都是人工选取一种SSL方法，并设定学习数，保证SSL的性能优于SL和UL，但是当选取的SSL方法与学习任务不匹配或者参数的设定不合适时，会成SSL的性能比SL或UL更差.如何自动根据学习任务选取合适的SSL方法并准确得到参数是未来SSL需要深入研究的内容，可以考虑用**全贝叶斯学习理论**解决。



**优化求解**

从各种SSL算法的实现过程可以看出，SSL问题大多为非凸、非平滑问题，或整数规划和组合优化问题，存在多个局部最优解，例如求解SSL产生式方法目标函数的EM算法只能得到局部极大值目前主要采用各种放松方法把目标函数近似转化为凸或连续最优化问题，不易得到全局最优解，算法的时空复杂性很高，问题的求解依赖于最优化理论的突破，未来需要研究新的算法求解全局最优解。



**研究拓展**

SSL从产生以来，主要用于实验室中处理**人工合成数据**，未来的研究一方而需要讨论SSL可以显著提高哪些学习任务的性能，拓展SSL在现实领域的实际应用，另一方而需要制定出一个统一的令人信服的SSL方法的使用规程。

此外，==目前有许多的半监督分类方法，而对半监督回归问题的研究比较有限==。

未来有待继续研究半监督分类和半监督回归之间的关系，并提出其他半监督回归方法。

Contributor: Ruiying Cai

