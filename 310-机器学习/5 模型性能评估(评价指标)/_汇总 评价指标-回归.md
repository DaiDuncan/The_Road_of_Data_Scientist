拟合问题比较简单，所用到的衡量指标也相对直观，假设：

- $y_i$是第i个样本的真实值
- $\hat{y}_i$是第i个样本的预测值



## 示例|线性回归

一元变量 & 二元变量

<img src="https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316212310.png" alt="image-20210316212310371" style="zoom:80%;" />

### 残差不合适

![image-20210316212343758](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316212343.png)



## 1 MAE平均绝对误差

平均绝对误差MAE（Mean Absolute Error）又被称为L1范数损失

![image-20210316164730367](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316164730.png)

### 思考|MAE有哪些不足？

MAE虽能较好衡量回归模型的好坏，但是绝对值的存在导致**函数不光滑**，在某些点上不能求导，可以考虑将绝对值改为残差的平方，这就是均方误差。



## 2 MSE平均平方误差 => RMSE均方根误差

```python
metrics.mean_squared_error(y_true, y_pred)
```

Mean Squared Error

一般情况下， RMSE 能够很好地反映回归模型预测值与真实值的偏离程度

但在实际问题中，如果存在个别偏离程度非常大的**离群点(Outlier）时**,即使离群点数量非常少,也会让RMSE指标变得很差。



==遵循一个假设，即误差无偏，遵循正态分布==

- “平方根”使该指标能够显示大的偏差
- 有更多样本时，使用RMSE重建误差分布被认为更可靠
- ==RMSE受异常值的影响很大==。因此，请确保在使用此指标之前已从数据集中删除了异常值。
- 与平均绝对误差相比，RMSE提供更高的权重并惩罚大错误

![image-20210316164746382](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316164746.png)



### 思考|还有没有比MSE更合理一些的指标？

由于MSE与我们的==目标变量的量纲==不一致，为了保证量纲一致性，我们需要对MSE进行开方 。





## 2.1 均方根对数误差

Root Mean Squared Error

在均方根对数误差的情况下，采用预测和实际值的对数

预测值和真值都很庞大时不希望处理预测值和实际值存在的==巨大差异==的话，通常采用RMSLE

![image-20210316173910686](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316173910.png)

- 如果预测值和实际值都很小：RMSE和RMSLE相同
- 如果预测值或实际值很大：RMSE> RMSLE
- 如果预测值和实际值都很大：RMSE> RMSLE（RMSLE几乎可以忽略不计）



### 思考|RMSE有没有不足的地方？有没有规范化（无量纲化的指标）？

上面的几种衡量标准的取值大小与具体的应用场景有关系，很难定义统一的规则来衡量模型的好坏

- 比如说利用机器学习算法预测上海的房价RMSE在2000元，我们是可以接受的
- 但是当四五线城市的房价RMSE为2000元，我们还可以接受吗？



## 2.2 MAPE

平均绝对百分比误差（Mean Absolute Percent Error, MAPE）

<img src="https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317141037.png" alt="image-20210317141037735" style="zoom:80%;" />

相比RMSE,MAPE相当于把每个点的误差进行了归一化,降低了个别离群点带来的绝对误差的影响



## 3 解释变异

```python
metrics.explained_variance_score(y_true, y_pred)
```

fraction of variance unexplained

![image-20210316164801165](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316164801.png)



## 4 决定系数$R^2$

```python
metrics.r2_score(y_true, y_pred)
```

注意：==增加变量时==，以下两个指标都被改善

- 决定系数：$R_i^2$
- MSE：均方差误差

![Some metrics are influenced by  Scale  feet, meters, inches, etc  Variables  Model Assum tions and T  es  Common Model  Evaluation Metrics  MSE  Mean-Squared Error  AIC  Akaike Information Criteria  BIC  Bayesian Information Criteria  Mallow's CP ](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317143731.png)





Coefficient of determination是一个无量纲化的指标

- 反映因变量的全部变异，能**通过回归关系被自变量解释的比例**
  - 如果结果是0，就说明模型预测不能预测因变量
  - 如果结果是1。就说明是函数关系

![image-20210316213828415](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316213828.png)

上式恒等变形：

![image-20210316213925708](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316213925.png)



[补充|证明：SST=SSR+SSE 2019.12.15](https://blog.csdn.net/weixin_43145361/article/details/103546382)

- 图示：a+b=c => 那么$a^2 + b^2 = c^2$成立吗？
- 基于前提：拟合误差最小 => 辅助条件：
  - 设$\hat{y}_i = \beta_0 + \beta_1 \cdot x_i$ => $S=\sum_{i=1}^n e_i^2 = \sum(y_i - \hat{y}_i)^2$
  - $\frac{\partial S}{\partial \beta_0}=\sum 2(y_i - \beta_0 -\beta_1 \cdot x_i)=\sum(y_i - \hat{y}_i)=0$
  - 同理：$\frac{\partial S}{\partial \beta_1}=\sum x_i(y_i - \beta_0 -\beta_1 \cdot x_i)=\sum x_i(y_i - \hat{y}_i)=0$
    - $x_i=\frac{1}{\beta_1}(\hat{y}_i - \beta_0)$ => $\sum \hat{y}_i(y_i - \hat{y}_i)=0$
- 上面两者结合得到结果

![image-20210422120243124](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210422120243.png)

已知RMSE降低时，模型的性能将会提高。但仅凭这些值并不直观

在分类问题的情况下，如果模型的准确度为0.8，可以衡量模型对随机模型的有效性，哪个准确度为0.5。

因此，随机模型可以作为基准。

但是在谈论RMSE指标时，却没有比较基准。

这里可以使用R-Squared指标。R-Squared的公式如下：

![image-20210316174053042](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316174053.png)

- MSE（模型）：预测值与实际值的平均误差
- MSE（基线）：==平均预测值==与实际值的平均误差





Coefficient of determination又被称为$R^2$分数

![image-20210316164827455](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316164827.png)

### 思考| 以上评估指标有没有缺陷，如果有，该怎样改进？

以上的评估指标是==基于误差的均值==对进行评估的，均值对异常点（outliers）较敏感，如果样本中有一些异常值出现，会对以上指标的值有较大影响，即均值是非鲁棒的。



### 解决评估指标鲁棒性问题⭐

1 剔除异常值

设定一个相对误差 ，当该值超过一定的阈值时，则认为其是一个异常点，剔除这个异常点

将异常点剔除之 后。再计算平均误差来对模型进行评价



2 使用误差的分位数来代替

如利用中位数来代替平均数。

例如 MAPE：$MAPE=median(\frac{|y_i - \hat{y}_i|}{y_i})$

MAPE是一个相对误差的中位数，当然也可以使用别的分位数。





### Adjusted R-Squared

调整后的可决系数（参考）

模型表现与baseline相同时，R-Squared为0。

模型越好，$R^2$值越高。最佳模型含所有正确预测值时，R-Squared为1。

但是，向模型添加新功能时，R-Squared值会增加或保持不变。R-Squared不会因添加了对模型无任何价值的功能而被判“处罚”。

因此，R-Squared的改进版本是经过调整的R-Squared。

调整后的R-Squared的公式如下：

![image-20210316174209434](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316174209.png)

- k：特征数量
- n：样本数量

此指标**会考虑特征的数量**。

添加更多特征时，分母项n-（k +1）减小，因此整个表达式在增大。

==如果R-Squared没有增大，那意味着添加的功能对模型没有价值。==

因此总的来说，在1上减去一个更大的值，调整的r2，反而会减少。



# 小结⭐

1 MSE、MAE、MAPE 与 R2 、Adjusted R2 都可以描述模型拟合的精确程度

- 但 R2和 Adjusted R2，大致可以分为一类。因为 R2 范围为 0 到 1，给了所有模型一个相同的比较标准，Adjusted R2 有可能小于 0，但也大致在 0 到 1 这个范围内。

- 而 MSE、MAE、MAPE 的值与数据有关，范围没有限制。



2 MSE、MAE、RSE、RMSE、$R^2$性能指标都存在一个问题：在模型中包括新加的变量时，将始终增加R2并降低RMSE

即预测变量在解释结果上即便没有显着贡献，但当加入新的预测变量进模型时，也会对上述性能指标产生影响，这些性能指标对模型的变化是非常敏感的



3 Adjusted R2有效地考虑了模型中的预测变量数量的不同，从而使各个模型可比较



4 还有其他四个重要指标- AIC，AICc，BIC和Mallows Cp

它们通常用于模型评估和选择，是MSE的**无偏估计**

这些指标数值越低，表示模型越好

| 指标                                 |                                                              |
| ------------------------------------ | ------------------------------------------------------------ |
| AIC（Akaike‘s Information Criteria） | 对模型中包含额外变量的行为进行惩罚<br />每当增加一个新变量时，它将增加一个惩罚值，从而达到控制额外预测变量的效果。AIC越低，模型越好 |
| AICc是AIC的变体版本                  | 主要是针对小样本量进行了校正                                 |
| BIC（Bayesian information criteria） | AIC的另一种变体，它利用了贝叶斯原理，当模型中增加新的变量时，它将受到比AIC更大的惩罚 |
| Mallows Cp                           | AIC的另一种变体，由Colin Mallows发明                         |


在统计学中，有一个原则就是，如果简单跟复杂效果一样，永远默认简单模型更好。



注意，以上这些回归指标都是对内部数据性能进行评价。

即，它们是根据用于构建回归模型的相同数据计算得出的。他们表示的是该模型与现有数据（训练数据集）的拟合程度，但并不衡量模型与新的测试数据集的拟合程度。

通常，我们并不十分在乎模型在训练数据上的效果如何。我们更在乎的是，我们建的模型对另一个完全独立的测试数据集的预测准确性。

但是，并不是每个研究都能找个一个或者多个相对独立的测试数据集，因此，我们有了==交叉验证法==和==自举重采样（bootstrap-resampling）验证法==来对该模型对测试数据集的预测准确性进行评估。





# 经典|copula熵方法⭐

copent包

1 相关性

> Ma, Jian. “Discovering Association with Copula Entropy.” arXiv preprint arXiv:1907.12268 (2019).Discovering Association with Copula Entropyarxiv.org

Pearson相关系数是一种统计学史上重要的相关性度量概念，虽然应用广泛，但却具有线性和高斯性等局限性。

Copula熵则是一种更**高级的相关性度量**，它没有线性和高斯性的假设，是一个多变量的相关性度量。

论文将二者进行了对比，并利用著名的NHANES医学体检数据证实了copula熵的显著优越性。



2 特征选择

> Ma, Jian. “Variable Selection with Copula Entropy.” Chinese Journal of Applied Probability and Statistics (accepted). See also arXiv preprint arXiv:1910.12389 (2019).Variable Selection with Copula Entropyarxiv.org

推荐使用Copula熵方法，研究表明其优于目前所有主流方法。

- Adaptive LASSO
- Ridge Regression
- Elastic Net
- AIC
- BIC
- Distance Correlation
- Hilbert-Schmidt Independence Criterion (HSIC)

证明了copula熵方法在预测能力和可解释性能两方面的优越性



3 时序因果发现

> Ma, Jian. “Estimating Transfer Entropy via Copula Entropy.” arXiv preprint arXiv:1910.04375 (2019).Estimating Transfer Entropy via Copula Entropyarxiv.org

传递熵是度量时序之间因果关系的概念，它可被认为是格兰杰因果检验的非线性版本。

论文基于copula熵估计给出了传递熵估计的非参数方法，并利用这个方法研究了气象因素和PM2.5之间的因果关系。



[link: MATLAB实战—最优Copula函数的选择](https://zhuanlan.zhihu.com/p/129887258)



# 补充|[AIC BIC Mallows Cp](https://zhuanlan.zhihu.com/p/78665263)

建模过程中，会有一些备选解释变量，选择不同的变量组合会得到不同的模型，而信息准则就是刻画这些模型相对于 “ 真实模型 ” 的信息损失。

| 指标                                            | L是该模型下的最大似然函数<br />n是数据数量<br />k是模型的变量个数 |
| ----------------------------------------------- | ------------------------------------------------------------ |
| 赤池信息量 （akaike information criterion）     | $AIC = - 2ln(L) + 2k$                                        |
| 贝叶斯信息量 （bayesian information criterion） | $BIC=-2ln(L)+ln(n) \cdot k$                                  |
| 汉南 - 奎因信息量 （quinn criterion）           | $HQ=-2ln(L)+ln(ln(n)) \cdot k$                               |

在模型拟合时，增加参数可使得似然概率增大，但是却引入了额外的变量，因此 AIC 和 BIC 都在目标式中添加了模型参数个数的惩罚项，也就是第二项。

当 n≥8 时，$ln(n) \cdot k \ge 2k$，所以，BIC 相比 AIC **在大数据量时**对模型参数惩罚得更多，==导致 BIC 更倾向于选择参数少的简单模型==。



- 





# #补充|非线性回归

一般的假设是，多项式回归比简单的线性回归更能拟合数据

但是更高次（100）多项式模型严重过拟合数据

