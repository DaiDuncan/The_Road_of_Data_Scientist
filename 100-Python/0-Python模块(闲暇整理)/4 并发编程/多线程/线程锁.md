## 背景|python多线程同时写一个数据不安全

为什么多线程在不加锁的情况下同时修改一个变量是不安全的, 启动5个线程，每个线程都会对变量a执行100000次加1操作， 最后print(a)时：最直观的猜想，a的值是500000

然而实际情况却并不是这样

```python
import threading
import time

a = 0
def worker():
    time.sleep(1)
    global a
    for i in range(100000):
        a += 1


thread_lst = []
for i in range(5):
    t = threading.Thread(target=worker)
    thread_lst.append(t)

for t in thread_lst:
    t.start()

for t in thread_lst:
    t.join()

print(a)
```

a最终的值会小于500000

首先必须弄清楚，对变量加1这个操作是怎样完成的，在程序里，你只需要写a = a + 1 就可以完成一次对变量的加1操作，但在计算机内部，真实的加1过程却经历了很多



下图是一个线程对变量执行加1的过程：

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210201195442.png" alt="image-20210201195441781" style="zoom:80%;" />

对变量执行加1操作，分为3个步骤

1. 将变量的值读取到寄存器中
2. 在寄存器中进行加1操作
3. 将寄存器中的值写回到内存中





再来看两个线程同时对变量a进行加1操作的过程：

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210201195515.png" alt="image-20210201195515007" style="zoom:80%;" />

线程A在t1时刻启动，线程B在t2时刻启动，问题就出在t2这个时刻，仔细观察示意图，你会注意到几点事实

1. 内存里，a的值是1
2. 线程A已经在寄存器里将1变为2
3. 线程B将==内存中的1==读取到寄存器B中

t2时刻，线程B在线程A还没有完成一次加1操作时，将内存中的数据读取到寄存器中。

t3时刻，线程A将2写回到内存中，而这一刻，线程B在寄存器中进行加1操作，寄存器中的值是2

t4时刻，线程B将2写回到内存，两个线程都执行了加1操作，可内存中变量a的值仍然是2。



通过两个线程执行加1操作过程的分析，相信你已经明白了，问题的根本在于对于我们所写的一行代码，计算机在执行时有很多操作，而==这些操作之间会互相影响==，这导致了线程不安全





# 线程锁

使用python进行多线程编程时, 为了防止多线程同时修改同一个变量, 使用threading.Lock()对关键操作加锁

- 进程有自己独立的内存单元

- 而线程则共享创建他们的进程的内存单元

多线程在运行时，如果要对同一个资源进行使用，那么就会面临资源共享的问题，处理不当，会对数据造成破坏





## 资源共享

为了避免多线程之间互相影响的情况，我们需要在==对共享资源进行修改时加锁==：同一个时刻，只能有一个线程获得这把锁，然后对数据进行操作，其他的线程只能等待。

这样，就可以避免多个线程同时修改一份数据。



可以使用threading.Lock()对关键操作加锁：

```python
import threading
import time

m_lock = threading.Lock()

a = 0
def worker():
    time.sleep(1)
    global a
    for i in range(100000):
        m_lock.acquire()    # 加锁：锁之后的变量都只能单线程操作
        a += 1
        m_lock.release()    # 释放锁

thread_lst = []
for i in range(5):
    t = threading.Thread(target=worker)
    thread_lst.append(t)

for t in thread_lst:
    t.start()

for t in thread_lst:
    t.join()

print(a)
```

仅仅添加了两行代码，进行加锁和释放锁的操作，就可以获得锁期望的结果了，最终a的值是500000



也可以使用with语句来简化代码，避免忘记释放锁

```python
def worker():
    time.sleep(1)
    global a
    for i in range(100000):
        with m_lock:
            a += 1
```







# 多线程锁|Lock和RLock的区别

为了确保对共享资源的访问，python提供了两种锁，一个是上一篇提到的Lock，还有一个就是RLock，他们的区别在于：

1. Lock是可用的==最低级别的同步指令，一个线程只能请求一次==，而RLock是可以被一个线程请求多次的同步指令
2. 当Lock处于锁定状态时，不被特定的线程所拥有，而RLock使用了“拥有的线程”和“递归等级”的概念，因此处于锁定状态时，可以被线程拥有

## Lock

加上一把锁，来确保同一个时刻，只能有一个线程进行操作，就像加1的操作，要==等到彻底执行完，也就是写回到内存后==才允许其他线程进行操作



## RLock

它可以被一个线程多次请求，只要你保证每一个acquire对应一个release就可以保证线程不会发生死锁，它比Lock更加安全，尤其当程序复杂时，推荐你使用RLock



## 死锁

Lock在下面的情形下会发生死锁：

```python
Lock.acquire()
Lock.acquire()
Lock.release()
Lock.release()
```

连续两次acquire请求，会导致死锁，因为第一次获得锁之后还没有释放时，第二次acquire请求紧接着就到来，可是acquire会让程序阻塞，无法执行release()，这就导致锁永远无法释放，死锁是非常危险非常严重的问题



## 可重入锁

RLock就不存在死锁问题

```python
RLock.acquire()
RLock.acquire()
RLock.release()
RLock.release()
```

不过要保证有多少次acquire()，就有多少次release()





## 怎么会多次请求锁呢？

RLock的优势在于，在同一个线程里可以多次申请锁，而Lock则不能，必须在释放之后才能再次申请

那么，这样做也没问题啊，不会出现第一次申请后，在释放前又申请的可能啊，在编写代码的时候，完全可以认为的控制这种情况的发生。

然而事实并非如此，我现在假设一种情形，使得死锁的发生不可避免：

```python
import threading

m_lock = threading.Lock()

def h():
    with m_lock:
        print('h')

def g():
    with m_lock:
        print('g')

h()
g()
```

h()和g()中都用了Lock，在多线程环境下，他们可以做到相安无事



但是，程序的结构总是处于变化中，尤其是那些庞大的系统，一个小小的变化可能牵一发而动全身，假设发生了下面的变化

```python
import threading

m_lock = threading.Lock()
# m_lock = threading.RLock()

def h():
    with m_lock:
        g()		#在h()函数中，获得锁以后要执行g()
        print('h')

def g():
    with m_lock:
        print('g')

h()
g()
```

在h()函数中，获得锁以后要执行g()，那么此时，程序就会发生死锁

在大的项目里，情况会比这更加复杂，你很难通过眼前的几行代码发现这种死锁的情况，因为很可能发生死锁的地方是在==很深层次的调用过程中==，因此，使用RLock是非常安全的选择.



执行上面的代码，程序不会输出任何信息，也永远不会结束，因为已经发生了死锁，将注释的Lock替换成RLock，程序立马可以执行