@参考资料(已下载) Matrix CookBook

# 一、矩阵求导

一般来讲，我们约定$x=(x_1,x_2,...x_N)^T$，这是分母布局/列向量。

常见的矩阵求导方式有：向量对向量求导，标量对向量求导，向量对标量求导。

## 1 向量对向量求导

![这里写图片描述](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img3/20210603202022.jpeg)



## 2 标量对向量求导

![这里写图片描述](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img3/20210603202110.jpeg)



![这里写图片描述](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img3/20210603202127.jpeg)





## 3 向量对标量求导

![这里写图片描述](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img3/20210603202140.jpeg)





# 二、常用的矩阵求导公式@ML

![image-20210603202844505](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img3/20210603202845.png)





# 三、几种重要的矩阵

## 1 梯度Gradient

- 实值函数y对向量X求导

![image-20210603202334444](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img3/20210603202334.png)

- 实值函数 y对矩阵X求导

![image-20210603202448505](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img3/20210603202448.png)



## 2 雅克比矩阵Jacobian matrix

$f(x)$是列向量函数$f_1(x), f_2(x),...,f_k(x)$

向量$x=(x_1,x_2,...x_L)^T$

![image-20210603202637824](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img3/20210603202638.png)

## 3 海森矩阵Hessian matrix

$f(x)$是一个二阶可微分的标量函数

$x=(x_1,x_2,...x_N)^T$

![image-20210603202741887](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img3/20210603202742.png)

