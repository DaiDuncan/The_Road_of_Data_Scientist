- [什么是线性回归？](https://easyai.tech/ai-definition/linear-regression/#what)
- [线性回归的优缺点](https://easyai.tech/ai-definition/linear-regression/#yqd)
- [8 种Python线性回归的方法的速度评测](https://easyai.tech/ai-definition/linear-regression/#pingce)
- [线性回归 VS 逻辑回归](https://easyai.tech/ai-definition/linear-regression/#vs)
- [百度百科+维基百科](https://easyai.tech/ai-definition/linear-regression/#baidu)
- [扩展阅读](https://easyai.tech/ai-definition/linear-regression/#links)

> 线性回归是很基础的机器学习算法，本文将通俗易懂的介绍线性回归的基本概念，优缺点，8 种方法的速度评测，还有和逻辑回归的比较。

 

## 什么是线性回归？

![线性回归的位置](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-08-30-weizhi.png)





**什么是回归？**

**回归的目的是为了预测**，比如预测明天的天气温度，预测股票的走势…

回归之所以能预测是因为他通过历史数据，摸透了“套路”，然后通过这个套路来预测未来的结果。

![回归的底层逻辑](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-08-30-taolu.png)

 

**什么是线性？**

“越…，越…”符合这种说法的就可能是线性个关系：

「房子」越大，「租金」就越高

「汉堡」买的越多，花的「钱」就越多

杯子里的「水」越多，「重量」就越大

……

但是并非所有“越…，越…”都是线性的，比如“充电越久，电量越高”，他就类似下面的非线性曲线：

![充电时间和电量是非线性关系](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-08-30-feixianxing.png)

线性关系不仅仅只能存在 2 个变量（二维平面）。

3 个变量时（三维空间），线性关系就是一个平面，4 个变量时（四维空间），线性关系就是一个体。以此类推…

![线性关系可以是多个变量](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-08-30-xianxing.png)





**什么是线性回归？**

线性回归本来是是统计学里的概念，现在经常被用在机器学习中。

如果 2 个或者多个变量之间存在“线性关系”，那么我们就可以通过历史数据，摸清变量之间的“套路”，建立一个有效的模型，来预测未来的变量结果。

![通俗解释线性回归](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-08-30-xxhg.png)

 

## 线性回归的优缺点

![线性回归的优缺点](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-08-30-youquedian.png)

优点：

1. 建模速度快，不需要很复杂的计算，在数据量大的情况下依然运行速度很快。
2. 可以根据系数给出每个变量的理解和解释

缺点：不能很好地拟合非线性数据。所以需要先判断变量之间是否是线性关系。



**为什么在深度学习大杀四方的今天还使用线性回归呢？**

一方面，线性回归所能够模拟的关系其实远不止线性关系。

线性回归中的“线性”指的是系数的线性，而通过**对特征的非线性变换**(添加高次项、交叉项)，以及广义线性模型的推广，输出和特征之间的函数关系可以是高度非线性的。

另一方面，也是更为重要的一点，**线性模型的易解释性**使得它在物理学、经济学、商学等领域中占据了难以取代的地位。

 

## 8 种Python线性回归的方法的速度评测

1. Scipy.polyfit( ) or numpy.polyfit( )
2. Stats.linregress( )
3. Optimize.curve_fit( )
4. numpy.linalg.lstsq
5. Statsmodels.OLS ( )
6. 简单的乘法求矩阵的逆
7. 首先计算x的Moore-Penrose广义伪逆矩阵，然后与y取点积
8. sklearn.linear_model.LinearRegression( )

![8 种线性回归方法速度评测结果](https://easy-ai.oss-cn-shanghai.aliyuncs.com/2019-08-30-pingce.png)

结果：令人惊讶的是，与广泛被使用的scikit-learnlinear_model相比，==简单矩阵的逆求解的方案反而更加快速。==

详细评测可以查看原文《[Data science with Python: 8 ways to do linear regression and measure their speed](https://www.freecodecamp.org/news/data-science-with-python-8-ways-to-do-linear-regression-and-measure-their-speed-b5577d75f8b/)》

 

## 线性回归 VS 逻辑回归

@`+逻辑回归`





## 百度百科+维基百科

百度百科版本

线性回归是利用数理统计中回归分析，来确定两种或两种以上变量间相互依赖的定量关系的一种统计分析方法，运用十分广泛。

其表达形式为y = w’x+e，e为误差服从均值为0的正态分布。



回归分析中，只包括一个自变量和一个因变量，且二者的关系可用一条直线近似表示，这种回归分析称为一元线性回归分析。

如果回归分析中包括两个或两个以上的自变量，且因变量和自变量之间是线性关系，则称为多元线性回归分析。

[查看详情](https://baike.baidu.com/item/线性回归/8190345?fr=aladdin)



维基百科版本

在统计学中，线性回归是一种线性方法，用于建模标量响应（或因变量）与一个或多个解释变量（或独立变量）之间的关系。一个解释变量的情况称为简单线性回归。对于多个解释变量，该过程称为多元线性回归。该术语不同于多元线性回归，其中预测了多个相关因变量，而不是单个标量变量。

在线性回归中，使用线性预测函数对关系进行建模，其中未知模型参数是根据数据估计的。这种模型称为线性模型。

最常见的是，给定解释变量（或预测变量）的值的响应的条件均值被假定为这些值的仿射函数 ; 不太常见的是，使用条件中值或一些其他分位数。

与所有形式的回归分析一样，线性回归**侧重于条件概率分布给出预测变量值的响应**，而不是所有这些变量的联合概率分布，这是多变量分析的领域。

[查看详情](https://en.wikipedia.org/wiki/Linear_regression)



# #参考文献

[用Python的Scikit-Learn库实现线性回归](https://mp.weixin.qq.com/s/fAu0jwL_V-2WN6Loa3wdcQ)

[机器学习算法_线性回归](https://mp.weixin.qq.com/s/9XnYZWJXxrNxHP7H38Z7Nw)

[通俗理解线性回归（一）](https://blog.csdn.net/alw_123/article/details/82193535)



- [人工神经网络 - Artificial Neural Network | ANN](https://easyai.tech/ai-definition/ann/)
- [逻辑回归 - Logistic regression](https://easyai.tech/ai-definition/logistic-regression/) 3
- [Attention 机制](https://easyai.tech/ai-definition/attention/) 17
- [Latent Dirichlet Allocation|LDA](https://easyai.tech/ai-definition/latent-dirichlet-allocationlda/)
- [K均值聚类（k-means clustering）](https://easyai.tech/ai-definition/k-means-clustering/) 1