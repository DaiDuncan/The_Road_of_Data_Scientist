# [概率论](https://easyai.tech/ai-definition/probability-theory/)

概率论是研究**随机现象数量规律**的数学分支。

随机现象是相对于决定性现象而言的。在一定条件下必然发生某一结果的现象称为决定性现象。

例如在标准大气压下，纯水加热到100℃时水必然会沸腾等。随机现象则是指在基本条件不变的情况下，每一次试验或观察前，不能肯定会出现哪种结果，呈现出偶然性。



例如，掷一硬币，可能出现正面或反面。随机现象的实现和对它的观察称为随机试验。

随机试验的每一可能结果称为一个基本事件，一个或一组基本事件统称随机事件，或简称事件。

典型的随机试验有掷骰子、扔硬币、抽扑克牌以及轮盘游戏等。



概率论是与概率有关的数学分支。

虽然存在几种不同的概率解释，但概率论通过一组公理来表达它，从而以严格的数学方式对待概念。

典型地，这些公理在一个方面正规化概率概率空间，**其中分配一个量度 0和1之间取值，称为概率测度**，对一组的结果被称为的样本空间。

这些结果的任何指定子集称为事件。

概率论中的中心主体包括离散和连续随机变量，概率分布和随机过程，它们提供非确定性或不确定过程或测量量的数学抽象，这些过程可以是单次出现或随机随时间演变。



# [先验概率](https://easyai.tech/ai-definition/prior-probability/)

先验概率（prior probability）是指**根据以往经验和分析得到的概率**，它往往作为”由因求果”问题中的”因”出现的概率。

在贝叶斯统计推断中，不确定数量的先验概率分布是在考虑一些因素之前表达对这一数量的置信程度的概率分布。

例如，先验概率分布可能代表在将来的选举中投票给特定政治家的选民相对比例的概率分布。

未知的数量可以是模型的参数或者是潜在变量。



在[贝叶斯统计](https://zh.wikipedia.org/wiki/贝叶斯定理)中，某一不确定量p的**先验概率**（Prior probability）分布是在考虑“观测数据”前，**能表达p不确定性的概率分布**。

它旨在描述这个不确定量的**不确定程度**，而不是这个不确定量的随机性。

这个不确定量可以是一个参数，或者是一个隐含变量（英语：latent variable）。

依据应用领域的不同，先验概率又叫做先验概率、先验概率、事前先验概率、居先概率。[[1\]](https://zh.wikipedia.org/wiki/先验概率#cite_note-1)

| “Prior probability”的各地常用别名 |          |
| :-------------------------------- | -------- |
| 中国大陆                          | 先验概率 |
| 台湾                              | 事前机率 |
| 港澳                              | 先验概率 |
| 日本、韩国汉字                    | 事前确率 |

在使用[贝叶斯定理](https://zh.wikipedia.org/wiki/贝叶斯定理)时，我们通过将先验概率与[似然函数](https://zh.wikipedia.org/wiki/似然函数)相乘，随后标准化(分母的全概率公式)，来得到[后验概率](https://zh.wikipedia.org/wiki/后验概率)分布，也就是给出某数据(样本x，也是结果)，该不确定量的条件分布(后验推断)。

==先验概率通常是主观的猜测==，为了使计算后验概率方便，有时候会选择[共轭先验](https://zh.wikipedia.org/wiki/共轭先验)。

如果后验概率和先验概率是同一族的，则认为它们是共轭分布，这个先验概率就是对应于似然函数的共轭先验。





# [后验概率](https://easyai.tech/ai-definition/posterior-probability/)

后验概率是信息理论的基本概念之一。

在一个通信系统中，在收到某个消息之后，接收端所了解到的该消息发送的概率称为后验概率。 

后验概率的计算要以先验概率为基础。后验概率可以根据通过贝叶斯公式，用先验概率和**似然函数**计算出来。



在贝叶斯统计，所述后验概率一个的随机事件或不确定的命题是条件概率是分配相关后证据或背景考虑。

类似地，后验概率分布是**未知量的概率分布**，作为随机变量处理，条件是从实验或调查中获得的证据。

在这种情况下，“后验”是指在考虑与被审查的具体案件**有关的相关证据之后**。

例如，如果一个人在一个**随机点**上挖掘，就会发现（“非后验”）概率，如果他们在**金属探测器响起的地方**挖掘，则会发现埋藏宝藏的后验概率。



# [最大似然估计 MLE](https://easyai.tech/ai-definition/maximum-likelihood-estimate/)

Maximum Likelihood Estimate

最大似然估计是一种统计方法，它用来求一个**样本集**的相关概率密度函数的==参数==。

这个方法最早是遗传学家以及统计学家罗纳德·费雪爵士在1912年至1922年间开始使用的。

“似然”是对likelihood 的一种较为贴近文言文的翻译，“似然”用现代的中文来说即“可能性”。

故而，若称之为“最大可能性估计”则更加通俗易懂。





在统计学中，最大似然估计（MLE）是一种==在给定观察的情况下估计统计模型的参数==的方法。

在给定观察结果的情况下，MLE尝试找到**使似然函数最大化的参数值**。得到的估计称为最大似然估计，其也缩写为MLE。

最大似然法用于广泛的统计分析。

例如，假设我们对成年雌性企鹅的高度感兴趣，但无法测量群体中每只企鹅的高度（由于成本或时间的限制）。

假设高度正常分布有一些未知的均值和方差，可以用MLE估计均值和方差，同时只知道总体人口的某些样本的高度。

MLE将通过将均值和方差作为参数并找到特定的参数值来实现这一点，这些参数值使得观察到的结果在给定正态模型的情况下**最可能**。

从贝叶斯推断的角度来看，==MLE是最大后验估计（[MAP](https://easyai.tech/ai-definition/maximum-a-posteriori-estimation/)）的特殊情况，其假设参数的均匀 先验分布==。@最大熵(不确定性最大的先验分布)

另一方面，从频率论推断的角度来看，MLE是在**不使用先验分布的情况下**获得参数估计的几种方法之一。

通过不对参数进行概率陈述来避免使用引物，而仅考虑它们的估计，其属性完全由观察和统计模型定义。





# [最大后验概率 MAP](https://easyai.tech/ai-definition/maximum-a-posteriori-estimation/)

Maximum a posteriori estimation

统计学中，MAP为最大后验概率（Maximum a posteriori）的缩写。

估计方法根据经验数据获得对难以观察的量的点估计。

它与最大似然估计中的 Fisher方法有密切关系，但是它**使用了一个增大的优化目标**，这种方法将被估计量的先验分布融合到其中。

所以最大后验估计可以看作是**规则化（regularization）的最大似然估计**。





在贝叶斯统计，一个最大后验概率（MAP）估计是未知数，即等于的**估计模式的的后验分布**。

MAP可用于基于经验数据获得未观测量的点估计。

它与最大似然（ML）估计方法密切相关，但采用了**包含先验分布的增强优化目标**（量化通过相关事件的先前知识获得的额外信息）超过想要估计的数量。

因此，MAP估计可以被视为**ML估计的正则化**。

