# [TPU Tensor Processing Unit](https://easyai.tech/ai-definition/tpu%ef%bc%88tensor-processing-unit%ef%bc%89/)

[TPU](https://easyai.tech/ai-definition/tpu（tensor-processing-unit）/)（Tensor Processing Unit）即张量处理单元，是一款为机器学习而定制的芯片，经过了专门深度机器学习方面的训练，它有更高效能（每瓦计算能力）。



TPU是AI加速器 应用特定的集成电路由显影（[ASIC](https://easyai.tech/ai-definition/asic/)）谷歌用于特异性神经网络 机器学习。



# [GPU Graphics Processing Unit](https://easyai.tech/ai-definition/gpugraphics-processing-unit/)

图形处理器（英语：Graphics Processing Unit，缩写：GPU），又称**显示核心**、视觉处理器、显示芯片，是一种专门在个人电脑、工作站、游戏机和一些移动设备（如平板电脑、智能手机等）上图像运算工作的微处理器。

用途是将计算机系统**所需要的显示信息**进行转换驱动，并向显示器提供行扫描信号，控制显示器的正确显示，是连接显示器和个人电脑主板的重要元件，也是“人机对话”的重要设备之一。

显卡作为电脑主机里的一个重要组成部分，承担**输出显示图形的任务**，对于从事专业图形设计的人来说显卡非常重要。



图形处理单元（GPU）是一个专门的电子电路设计成迅速操纵和改变存储器加速的创建图像在一个帧缓冲器旨在用于输出到显示装置。

**GPU用于嵌入式系统**，移动电话，个人计算机，工作站和游戏控制台。

现代GPU在处理计算机图形和图像处理方面非常有效。

它们高度并行的结构使它们比通用的更有效用于**并行处理**大块数据的算法的CPU。

在个人计算机中，GPU可以存在于视频卡上或嵌入在主板上。

在某些CPU中，它们嵌入在CPU 芯片上。



GPU至少在20世纪80年代一直被使用，它在1999年由Nvidia推广，他将GeForce 256作为“世界上第一个GPU” 推向市场。

它被呈现为“具有集成变换，光照，三角形设置/剪切和渲染引擎的单芯片处理器”。

竞争对手ATI Technologies在2002年发布了Radeon 9700，创造了“ 视觉处理单元 ”或VPU这一术语。



CPU 能力更强大，能做很多事情，适合处理复杂的任务。

GPU 结构简单，可以形成人海战术，适合处理重复简单的任务。

知乎上有一个回答很应景：

![GPU和CPU的差别](http://easy-ai.oss-cn-shanghai.aliyuncs.com/easy-ai/2019/01/gpuvscpu.png)



 

> 一个数学教授和100个小学生PK。
>
> 第一回合，四则运算，一百个题。教授拿到卷子一道道算。一百个小学生各拿一道题。教授刚开始算到第二题的时候，小学生集体交卷。第一回合小学生碾压教授。
>
> 
>
> 第二回合，高等函数。一百个题。当教授搞定后。一百个小学生还不知道在干嘛…….第二回合，教授碾压一百个小学生。好理解吗？
>
> 这就是CPU和GPU的浅显比较。

 



# FPGA vs. ASIC

[ASIC Application Specific Integrated Circuit](https://easyai.tech/ai-definition/asic/)

目前，在集成电路界ASIC被认为是一种为专门目的而设计的集成电路。

是指**应特定用户要求**和特定电子系统的需要而设计、制造的集成电路。

ASIC的特点是面向特定用户的需求，ASIC在批量生产时与通用集成电路相比具有体积更小、功耗更低、可靠性提高、性能提高、保密性增强、成本降低等优点。



==应用专用集成电路（ASIC）是集成电路的定制用于特定用途==，而不是旨在用于一般用途（IC）。

例如，设计用于在数字录音机或高效 ==比特币挖掘机中运行的芯片是ASIC==。

专用标准产品（ASSP）介于ASIC和7400系列或4000系列等行业标准集成电路之间。



随着功能尺寸的缩小和设计工具多年来的不断改进，ASIC中最大的复杂性（以及功能）已经从5,000个逻辑门增加到超过1亿个。

现代的ASIC**通常包括**整个微处理器，存储器块，包括ROM，RAM，EEPROM，快闪存储器等大型构造块。

这种ASIC通常被称为SoC（片上系统）。

数字ASIC的设计者通常使用硬件描述语言（HDL）（例如Verilog或VHDL）来**描述ASIC的功能**。



现场可编程门阵列（[FPGA](https://easyai.tech/ai-definition/fpga/)）是现代技术，用于从标准部件构建面包板或原型; 

可编程逻辑模块和可编程互连允许在许多不同的应用中使用相同的FP[GA](https://easyai.tech/ai-definition/genetic-algorithm/)。

对于较小的设计或较低的产量，FPGA可能比ASIC设计更具成本效益，即使在生产中也是如此。

ASIC 的非经常性工程（NRE）成本可能达到数百万美元。

因此，设备制造商通常更喜欢**用于原型设计的 FPGA** 和具有低产量的设备以及**用于非常大的生产量的 ASIC**，其中NRE成本可以在许多设备上摊销。



[FPGA Field－Programmable Gate Array](https://easyai.tech/ai-definition/fpga/)

FP[GA](https://easyai.tech/ai-definition/genetic-algorithm/)（Field－Programmable Gate Array），即现场可编程门阵列，它是在PAL、GAL、CPLD等可编程器件的基础上进一步发展的产物。

它是作为专用集成电路（[ASIC](https://easyai.tech/ai-definition/asic/)）领域中的一种**半定制电路**而出现的，既解决了定制电路的不足，又克服了原有可编程器件门电路数有限的缺点。



现场可编程门阵列是集成电路设计成由客户或制造后设计者被配置-因此，术语“ 现场可编程 ”。

FPGA配置通常使用**硬件描述语言（HDL）来指定**，类似于用于专用集成电路（ASIC）的语言。

电路图以前用于指定配置，但由于电子设计自动化工具的出现，这种情况越来越少见。



Xilinx的Spartan FPGA包含一系列可编程 逻辑块，以及允许块“连接在一起”的可重新配置互连层次，就像许多可以在不同配置中相互连接的逻辑门一样。

逻辑块可以配置为执行复杂的组合功能，或仅仅是简单的逻辑门，如AND和XOR。

在大多数FPGA中，逻辑块还包括**存储器元件**，其可以是简单的触发器或更完整的存储器块。

许多FPGA可以重新编程以实现不同的逻辑功能，**允许在计算机软件中执行灵活的可重新配置计算**。





# #参考文献

## TPU

[TPU 官方介绍——来自 Google](https://cloud.google.com/tpu/)（需要科学上网）

[如何看待谷歌公开 tensorflow 专用处理器 TPU?](https://www.zhihu.com/question/46692744/answer/158897410)

「视频」[Google I/O ’18 大会上介绍 TPU 的部分](https://www.youtube.com/watch?v=zEOtG-ChmZE)（需要科学上网）



## GPU

[一文了解AI芯片投资走向 GPU收益将滑落第二](https://mp.weixin.qq.com/s/HlI7XC1vgEVdZh58kHFC1g)（2019-3-9）

[基于FPGA的深度学习加速器综述：挑战与机遇](https://baijiahao.baidu.com/s?id=1623521092738591808)

[AI芯片混战，谁能挑战英伟达？](https://easyai.tech/blog/a-cambrian-explosion-in-deep-learning/)

[FPGA 对比 ASIC & FPGA 对比GPU](https://www.zhihu.com/question/28639592/answer/129947384)



## FPGA vs. ASIC

[FPGA vs. ASIC，谁将引领移动端人工智能潮流？](https://zhuanlan.zhihu.com/p/22604670)



[AI算法在FPGA芯片上还有这种操作？](https://mp.weixin.qq.com/s/x4f0Waouk82dM__IyjP3mg)

[“5G+AI”带来FPGA新增长引擎](https://mp.weixin.qq.com/s/E_j9MuYWbN2V0lnA_DpvGQ)（2019-4）

[FPGA技术的未来发展：谁与AI平分秋色](https://mp.weixin.qq.com/s/gQr1UfPKjquQqkYMHoBqpw)（2019-3）

[基于FPGA的深度学习加速器综述：挑战与机遇](https://baijiahao.baidu.com/s?id=1623521092738591808)

[AI芯片混战，谁能挑战英伟达？](https://easyai.tech/blog/a-cambrian-explosion-in-deep-learning/)

[FPGA 对比 ASIC & FPGA 对比GPU](https://www.zhihu.com/question/28639592/answer/129947384)