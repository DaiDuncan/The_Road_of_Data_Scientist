[分类特征 2021.03.30](https://easyai.tech/ai-definition/classify-feature/)

> 分类特征是重要的一类特征。
>
> 分类特征是离散的，非连续的。
>
> 本文将针对小型分类和大型分类介绍5种主流的编码方式。以及各自的优缺点。

 

## 什么是分类（类别）特征？

分类特征是用来表示分类的，他不像数值类特征是连续的，分类特征是离散的。

比如：

- 性别
- 城市
- 颜色
- IP地址
- 用户的账号ID

![https://easy-ai.oss-accelerate.aliyuncs.com/2021-03-30-lisan.png](https://easy-ai.oss-accelerate.aliyuncs.com/2021-03-30-lisan.png)

**有些分类特征也是数值**，比如账号ID，IP地址。

- 但是这些数值并不是连续的。



连续的数字是数值类特征，离散的数字是分类特征。

关于连续和离散的解释可以看看这篇文章：《[关于连续和离散的理解](https://zhuanlan.zhihu.com/p/101155810)》

## 小型分类特征的编码方式

![https://easy-ai.oss-accelerate.aliyuncs.com/2021-03-30-small-data.png](https://easy-ai.oss-accelerate.aliyuncs.com/2021-03-30-small-data.png)

### 自然数编码/序列编码-Ordinal Encoding

**某些分类本来就有一定的排序**，这种情况下就可以使用简单的自然数编码。

例如学位：

学士-0

硕士-1

博士-2

### 独热编码-One-Hot Encoding

对于城市、颜色、品牌、材质…这些特征就不适合用自然数编码，因为这些**特征是没有排序关系**的。

使用==独热编码可以让不同的分类处在「平等的地位」==，不会因为数值的大小而对分类造成影响。

例如颜色分类（假设只有3种颜色）：

红色-100

黄色-010

蓝色-001

跟独热编码类似还有「虚拟编码-Dummy Encoding」和「效果编码-Effect Encoding」。

实现方式比较相似，不过有一些略微的差别，并且适用在不同的场景。

感兴趣的可以看看这篇文章：

《[虚拟变量和独热编码的区别](https://www.cnblogs.com/HuZihu/p/9692554.html)》

《[赋值方法：效应编码](https://zhuanlan.zhihu.com/p/121822813)》

## 大型分类特征的编码方式

![https://easy-ai.oss-accelerate.aliyuncs.com/2021-03-30-big-data.png](https://easy-ai.oss-accelerate.aliyuncs.com/2021-03-30-big-data.png)

### 目标编码-Target Encoding|Catboost TS

目标编码是表示分类列的一种非常有效的方法，并且**仅占用一个特征空间**，也称为**均值编码**。

该列中的每个值都==被该类别的平均目标值替代==。

这可以更直接地表示分类变量和目标变量之间的关系。

目标编码的扩展阅读：《[目标编码简介](https://blog.zenggyu.com/zh/post/2020-01-01/目标编码简介/)》

### 散列编码-Hash encoding

散列函数也是大家常听到的哈希函数。

散列函数是一个确定性函数，它映射一个潜在的无界整数到有限整数范围[1，m]。

假如有一个分类有1万个值，如果使用独热编码，编码会非常长。

- 而使用了散列编码，不管分类有多少不同的值，都会==转换成长度固定的编码==。@编码：霍夫曼编码

### 分箱计数-Bin-Counting？？

分箱计数的思维有点复杂：他不是用分类变量的值作为特征，而是**使用目标变量取这个值的条件概率**。

换句话说，我们不对分类变量的值进行编码，而是要==计算分类变量值与要预测的目标变量之间的相关统计量==。

## 不同编码的优缺点总结

### 独热编码-One-Hot Encoding

优点：

1. 容易实现
2. 分类很精确
3. **可用于在线学习**

缺点：

1. 计算效率不高
2. **不能适应可增长的类别**
3. 只适用于线性模型
4. 对于大数据集，需要**大规模的分布式优化**

### 散列编码-Hash encoding

优点：

1. 容易实现
2. 模型训练成本更低
3. **容易适应新类别**
4. **容易处理稀有类**
5. 可用于在线学习

缺点：

1. 只适合线性模型或核方法
2. **散列后的特征无法解释**
3. 精确度难以保证

### 分箱计数-Bin-Counting

优点：

1. 训练阶段的计算负担最小
2. 可用于**基于树的模型**
3. 容易适应新的类别
4. 可使用back-off方法或最小计数图处理稀有类
5. **可解释**

缺点：

1. 需要历史数据
2. **需要延迟更新，不完全适合在线学习**
3. **很可能导致数据泄露**

上面内容摘自：《[精通特征工程](https://book.douban.com/subject/33400236/)》

## 总结

分类特征是离散的特征，数值类特征是连续的。

**对于小型分类**，常用的编码方式有：

1. 自然数编码/序列编码-Ordinal Encoding
2. 独热编码-One-Hot Encoding
3. 虚拟编码-Dummy Encoding
4. 效果编码-Effect Encoding

**对于大型分类**，常用的编码方式有：

1. 目标编码-Target Encoding
2. 散列编码-Hash encoding
3. 分箱计数-Bin-Counting

相关文章推荐：

《[机器学习之类别特征处理](https://www.biaodianfu.com/categorical-feature.html#目标编码（Target_Encoding/Mean_Encoding）)》

《[特征工程(四): 类别特征](https://cloud.tencent.com/developer/article/1528406)》

