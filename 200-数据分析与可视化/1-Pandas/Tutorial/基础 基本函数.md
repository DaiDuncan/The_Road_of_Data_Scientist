 [Link: 官网|基本函数](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html)

```python
import numpy as np
import pandas as pd

### 创建数据对象
In [1]: index = pd.date_range('1/1/2000', periods=8)

In [2]: s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])

In [3]: df = pd.DataFrame(np.random.randn(8, 3), index=index,
   ...:                   columns=['A', 'B', 'C'])
   ...: 

In [4]: long_series = pd.Series(np.random.randn(1000))
```



# 基本操作

```python
ser.head()
df.head()

ser.tail()
df.tail()

df[slice]
df.columns
df.columns = [x.lower() for x in df.columns] #列名都小写

### 转化为array
ser.to_numpy()
np.asarray(ser)
```



# 加速运算：numexpr库，bottleneck库

- `numexpr` uses smart chunking, caching, and multiple cores
- `bottleneck` is a set of specialized cython routines that are especially fast when dealing with arrays that ==have `nans`==

加速特定类型的运算(二元数值运算，布尔运算)，尤其是处理大型数据集

```python
pd.set_option('compute.use_bottleneck', False)
pd.set_option('compute.use_numexpr', False)
```



# 灵活的二元运算

### 广播机制

```python
add()
sub()
mul()
div()

radd()
rsub()

### 数据集
In [19]: df
Out[19]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [20]: row = df.iloc[1] # df.loc['b']
In [21]: column = df['two']

    
# 减去原先的b行
In [22]: df.sub(row, axis='columns') #等价于 axis=1(跨列) => 行
Out[22]: 
        one       two     three
a  1.051928 -0.139606       NaN
b  0.000000  0.000000  0.000000
c  0.352192 -0.433754  1.277825
d       NaN -1.632779 -0.562782


# 减去原先的two列
In [24]: df.sub(column, axis='index') #等价于 axis=0(跨行) => 列
Out[24]: 
        one  two     three
a -0.377535  0.0       NaN
b -1.569069  0.0 -1.962513
c -0.783123  0.0 -0.250933
d       NaN  0.0 -0.892516
```



# 缺失值

```python
df.add(df2, fill_value=0)
```



# 比较

## 二元比较

```python
# eq, ne, lt, gt, le, ge
df.gt(df2)
df2.ne(df)
```



## 布尔比较

```python
empty()
any()
all()
bool()

(df > 0).all() #每一列统计，得到series
(df > 0).any() #每一列统计，得到series
(df > 0).any().any() #针对series再进行.any()，得到一个值

df.empty
pd.DataFrame(columns=list('ABC')).empty

### 针对单个元素：用bool()
In [53]: pd.Series([True]).bool()
Out[53]: True

In [54]: pd.Series([False]).bool()
Out[54]: False

In [55]: pd.DataFrame([[True]]).bool()
Out[55]: True

In [56]: pd.DataFrame([[False]]).bool()
Out[56]: False
    
### 注意：错误用法
# 以下两者涉及多值的比较
>>> if df:
...     pass

>>> df and df2


### 判断目标是否等价
In [57]: df + df == df * 2
Out[57]: 
     one   two  three
a   True  True  False
b   True  True   True
c   True  True   True
d  False  True   True

In [58]: (df + df == df * 2).all()
Out[58]: 
one      False
two       True
three    False
dtype: bool
# 结论：NaNs比较不相等
In [59]: np.nan == np.nan
Out[59]: False


### 改变判断的方法：即便有NaNs的情况
In [60]: (df + df).equals(df * 2)
Out[60]: True
    
### 注意：NaNs对应的顺序应该相同
In [61]: df1 = pd.DataFrame({'col': ['foo', 0, np.nan]})

In [62]: df2 = pd.DataFrame({'col': [np.nan, 0, 'foo']}, index=[2, 1, 0])

In [63]: df1.equals(df2)
Out[63]: False

In [64]: df1.equals(df2.sort_index())
Out[64]: True
```



### 数组对象的比较

```python
### 与单个元素的比较
In [65]: pd.Series(['foo', 'bar', 'baz']) == 'foo'
Out[65]: 
0     True
1    False
2    False
dtype: bool

In [66]: pd.Index(['foo', 'bar', 'baz']) == 'foo'
Out[66]: array([ True, False, False])
  


### 元素数量相同时的比较
# 比较Index
In [67]: pd.Series(['foo', 'bar', 'baz']) == pd.Index(['foo', 'bar', 'qux'])
Out[67]: 
0     True
1     True
2    False
dtype: bool

# 比较Series(数组元素)
In [68]: pd.Series(['foo', 'bar', 'baz']) == np.array(['foo', 'bar', 'qux'])
Out[68]: 
0     True
1     True
2    False
dtype: bool
    
### 注意：与numpy array的区别
# 单个元素可广播
In [69]: np.array([1, 2, 3]) == np.array([2])
Out[69]: array([False,  True, False])

# 不可广播：整体比较
In [70]: np.array([1, 2, 3]) == np.array([1, 2])
Out[70]: False
```



# combine|数据集覆盖：np.where()

```python
In [71]: df1 = pd.DataFrame({'A': [1., np.nan, 3., 5., np.nan],
   ....:                     'B': [np.nan, 2., 3., np.nan, 6.]})
   ....: 

In [72]: df2 = pd.DataFrame({'A': [5., 2., 4., np.nan, 3., 7.],
   ....:                     'B': [np.nan, np.nan, 3., 4., 6., 8.]})
   ....: 

In [73]: df1
Out[73]: 
     A    B
0  1.0  NaN
1  NaN  2.0
2  3.0  3.0
3  5.0  NaN
4  NaN  6.0

In [74]: df2
Out[74]: 
     A    B
0  5.0  NaN
1  2.0  NaN
2  4.0  3.0
3  NaN  4.0
4  3.0  6.0
5  7.0  8.0

In [75]: df1.combine_first(df2)
Out[75]: 
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0

'''解释说明
1. 值覆盖NaNs, 除非两个都是NaNs
2. 以df1的值为基准
'''

### 本质
def combiner(x, y):
    return np.where(pd.isna(x), y, x)
```





# ⭐描述统计

- **Series**: no axis argument needed
- **DataFrame**: ==“index” (axis=0, default), “columns” (axis=1)==

## 基本统计方法

| Function   | Description                                |
| :--------- | :----------------------------------------- |
| `count`    | Number of non-NA observations              |
| `sum`      | Sum of values                              |
| `mean`     | Mean of values                             |
| `mad`      | Mean absolute deviation                    |
| `median`   | Arithmetic median of values                |
| `min`      | Minimum                                    |
| `max`      | Maximum                                    |
| `mode`     | Mode                                       |
| `abs`      | Absolute Value                             |
| `prod`     | Product of values                          |
| `std`      | Bessel-corrected sample standard deviation |
| `var`      | Unbiased variance                          |
| `sem`      | Standard error of the mean                 |
| `skew`     | Sample skewness (3rd moment)               |
| `kurt`     | Sample kurtosis (4th moment)               |
| `quantile` | Sample quantile (value at %)               |
| `cumsum`   | Cumulative sum                             |
| `cumprod`  | Cumulative product                         |
| `cummax`   | Cumulative maximum                         |
| `cummin`   | Cumulative minimum                         |

```python
### 数据集
In [77]: df
Out[77]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172


In [78]: df.mean(0) #0表示跨行：即对列进行统计
Out[78]: 
one      0.811094
two      1.360588
three    0.187958
dtype: float64
    
In [79]: df.mean(1) #1表示跨列：即对行进行统计
Out[79]: 
a    1.583749
b    0.734929
c    1.133683
d   -0.166914
dtype: float64 
    
    
### 共同的参数
skipna=True/False # np.mean()等方法自动剔除NaNs
```





## 数据总结描述

```python
### .describe():数值 => 分位值
In [93]: series = pd.Series(np.random.randn(1000))

In [94]: series[::2] = np.nan

In [95]: series.describe()
Out[95]: 
count    500.000000
mean      -0.021292
std        1.015906
min       -2.683763
25%       -0.699070
50%       -0.069718
75%        0.714483
max        3.160915
dtype: float64

In [96]: frame = pd.DataFrame(np.random.randn(1000, 5),
   ....:                      columns=['a', 'b', 'c', 'd', 'e'])
   ....: 

In [97]: frame.iloc[::2] = np.nan

In [98]: frame.describe()
Out[98]: 
                a           b           c           d           e
count  500.000000  500.000000  500.000000  500.000000  500.000000
mean     0.033387    0.030045   -0.043719   -0.051686    0.005979
std      1.017152    0.978743    1.025270    1.015988    1.006695
min     -3.000951   -2.637901   -3.303099   -3.159200   -3.188821
25%     -0.647623   -0.576449   -0.712369   -0.691338   -0.691115
50%      0.047578   -0.021499   -0.023888   -0.032652   -0.025363
75%      0.729907    0.775880    0.618896    0.670047    0.649748
max      2.740139    2.752332    3.004229    2.728702    3.240991

# 指定分位值
series.describe(percentiles=[.05, .25, .75, .95]) #默认包含 中值

# 参数include/exclude 选择包含或者剔除的数据类型
frame.describe(include=['object'])
frame.describe(include=['number'])
frame.describe(include='all')
```



## 返回最值的index

```python
In [107]: s1 = pd.Series(np.random.randn(5))

In [108]: s1
Out[108]: 
0    1.118076
1   -0.352051
2   -1.242883
3   -1.277155
4   -0.641184
dtype: float64

In [109]: s1.idxmin(), s1.idxmax()
Out[109]: (3, 0)

In [110]: df1 = pd.DataFrame(np.random.randn(5, 3), columns=['A', 'B', 'C'])

In [111]: df1
Out[111]: 
          A         B         C
0 -0.327863 -0.946180 -0.137570
1 -0.186235 -0.257213 -0.486567
2 -0.507027 -0.871259 -0.111110
3  2.000339 -2.430505  0.089759
4 -0.321434 -0.033695  0.096271

In [112]: df1.idxmin(axis=0) #跨行：针对列
Out[112]: 
A    2
B    3
C    1
dtype: int64

In [113]: df1.idxmax(axis=1)
Out[113]: 
0    C
1    A
2    C
3    A
4    C
dtype: object

### 备注：
# 有多个相同的最值：返回第一个匹配的对象
# idxmin, idxmax对应NumPy中的argmin, argmax
```



## 分布的统计

```python
s.value_counts()
pd.value_counts(data)

# 多列数据
In [122]: data = {"a": [1, 2, 3, 4], "b": ["x", "x", "y", "y"]}

In [123]: frame = pd.DataFrame(data)

In [124]: frame.value_counts()
Out[124]: 
a  b
4  y    1
3  y    1
2  x    1
1  x    1
dtype: int64
```



## 众数

```python
In [125]: s5 = pd.Series([1, 1, 3, 3, 3, 5, 5, 7, 7, 7])

In [126]: s5.mode()
Out[126]: 
0    3
1    7
dtype: int64

In [127]: df5 = pd.DataFrame({"A": np.random.randint(0, 7, size=50),
   .....:                     "B": np.random.randint(-10, 15, size=50)})
   .....: 

In [128]: df5.mode()
Out[128]: 
     A   B
0  1.0  -9
1  NaN  10
2  NaN  13
```





## 分组、分位

Discretization and quantiling

```python
arr = np.random.randn(30)
factor = pd.cut(arr, 4)
factor = pd.qcut(arr, [0, .25, .5, .75, 1]) #给定分位数的分组
```



---

---

# ⭐函数应用

用哪种方法取决于操作的对象是DataFrame 或 Series ，是行或列，还是元素

```python
### 创建函数
# 基于输入的df，创建新的列'city_name'(从city_and_code中提取city)
In [141]: def extract_city_name(df):
   .....:     """
   .....:     Chicago, IL -> Chicago for city_name column
   .....:     """
   .....:     df['city_name'] = df['city_and_code'].str.split(",").str.get(0)
   .....:     return df
   .....: 

# 基于输入的country_name，创建新的列'city_and_country'
In [142]: def add_country_name(df, country_name=None):
   .....:     """
   .....:     Chicago -> Chicago-US for city_name column
   .....:     """
   .....:     col = 'city_name'
   .....:     df['city_and_country'] = df[col] + country_name
   .....:     return df
   .....: 

In [143]: df_p = pd.DataFrame({'city_and_code': ['Chicago, IL']})
```



## 1. 表格级Tablewise   .pipe()

通过**链式调用**函数时，最好使用`pipe()`方法

```python
### 官方文档
func(g(h(df), arg1=a), arg2=b, arg3=c)  

# pipe等效表示：
(df.pipe(h)
   .pipe(g, arg1=a)
   .pipe(func, arg2=b, arg3=c)
)  


In [144]: add_country_name(extract_city_name(df_p), country_name='US')
Out[144]: 
  city_and_code city_name city_and_country
0   Chicago, IL   Chicago        ChicagoUS

### 等价于.pipe()
In [145]: (df_p.pipe(extract_city_name)
   .....:      .pipe(add_country_name, country_name="US"))
   .....: 
Out[145]: 
  city_and_code city_name city_and_country
0   Chicago, IL   Chicago        ChicagoUS


### 注意：如果是多个参数 =>  (callable, data_keyword)
### callable是函数名，data_keyword是数据和后续参数
# 示例：statsmodels中的回归分析 

In [146]: import statsmodels.formula.api as sm
In [147]: bb = pd.read_csv('data/baseball.csv', index_col='id')

In [148]: (bb.query('h > 0')
   .....:    .assign(ln_h=lambda df: np.log(df.h)) #@Tutorial-基础 数据结构：基于assign()创建新的column
   .....:    .pipe((sm.ols, 'data'), 'hr ~ ln_h + year + g + C(lg)')
   .....:    .fit()
   .....:    .summary()
   .....:  )
   .....: 
Out[148]: 
<class 'statsmodels.iolib.summary.Summary'>
```

备注：[Link: 库statsmodels.formula.api.ols](statsmodels.formula.api.ols)

- 第一个参数是表达式formula
- 第二个参数是数据data



[Link: 示例statsmodels.formula.api.ols](statsmodels.formula.api.ols)](statsmodels.formula.api.ols)

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20201207101250.png" alt="image-20201207101250678" style="zoom:67%;" />

```python
mod = ols(formula='Lottery ~ Literacy + Wealth + Region', data=df)
res = mod.fit()
print(res.summary())

### 分类变量：如果region是整数值，但我们视为分类变量
res = ols(formula='Lottery ~ Literacy + Wealth + C(Region)', data=df).fit()
print(res.params)

### 补充：-表示剔除某个成分
# 剔除截距intercept
res = ols(formula='Lottery ~ Literacy + Wealth + C(Region) -1 ', data=df).fit()
print(res.params)

### 补充：表达式中含有自定义函数
def log_plus_1(x):
    return np.log(x) + 1.
res = smf.ols(formula='Lottery ~ log_plus_1(Literacy)', data=df).fit()
print(res.params)
```

备注：

- unix：dplyr, magrittr
- R：%>%



## 2. 行/列级 Row or Column-wise   .apply()

`apply()`方法可以沿着 DataFrame 的轴应用任何函数，比如，描述性统计方法，该方法支持 axis 参数



```python
### .apply(, axis=0) 默认跨行/针对列
In [149]: df.apply(np.mean)
Out[149]: 
one      0.811094
two      1.360588
three    0.187958
dtype: float64

In [150]: df.apply(np.mean, axis=1)
Out[150]: 
a    1.583749
b    0.734929
c    1.133683
d   -0.166914
dtype: float64

In [151]: df.apply(lambda x: x.max() - x.min())
Out[151]: 
one      1.051928
two      1.632779
three    1.840607
dtype: float64

In [152]: df.apply(np.cumsum)
Out[152]: 
        one       two     three
a  1.394981  1.772517       NaN
b  1.738035  3.684640 -0.050390
c  2.433281  5.163008  1.177045
d       NaN  5.442353  0.563873

In [153]: df.apply(np.exp)
Out[153]: 
        one       two     three
a  4.034899  5.885648       NaN
b  1.409244  6.767440  0.950858
c  2.004201  4.385785  3.412466
d       NaN  1.322262  0.541630


### 补充：提取字符串作为方法
In [154]: df.apply('mean')
Out[154]: 
one      0.811094
two      1.360588
three    0.187958
dtype: float64

In [155]: df.apply('mean', axis=1)
Out[155]: 
a    1.583749
b    0.734929
c    1.133683
d   -0.166914
dtype: float64
```

备注：函数影响最后的输出类型

- 如果函数返回Series，那么应用.apply()最终返回DataFrame
- 如果函数返回其他类型，那么最终返回Series

注意：默认输出类型，可以通过参数result_type覆盖重写

- reduce
- broadcast
- expand(是否扩展为一个DataFrame)



```python
### 应用：返回目标对象出现的位置 index
In [156]: tsdf = pd.DataFrame(np.random.randn(1000, 3), columns=['A', 'B', 'C'],
   .....:                     index=pd.date_range('1/1/2000', periods=1000))
   .....: 

In [157]: tsdf.apply(lambda x: x.idxmax())
Out[157]: 
A   2000-08-06
B   2001-01-18
C   2001-07-18
dtype: datetime64[ns]


### 补充：传递函数的更多参数
def subtract_and_divide(x, sub, divide=1):
    return (x - sub) / divide

df.apply(subtract_and_divide, args=(5,), divide=3)


### 补充：函数可以是Series的方法
In [158]: tsdf
Out[158]: 
                   A         B         C
2000-01-01 -0.158131 -0.232466  0.321604
2000-01-02 -1.810340 -3.105758  0.433834
2000-01-03 -1.209847 -1.156793 -0.136794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08 -0.653602  0.178875  1.008298
2000-01-09  1.007996  0.462824  0.254472
2000-01-10  0.307473  0.600337  1.643950

In [159]: tsdf.apply(pd.Series.interpolate) # 差值(默认跨行：针对列)
Out[159]: 
                   A         B         C
2000-01-01 -0.158131 -0.232466  0.321604
2000-01-02 -1.810340 -3.105758  0.433834
2000-01-03 -1.209847 -1.156793 -0.136794
2000-01-04 -1.098598 -0.889659  0.092225
2000-01-05 -0.987349 -0.622526  0.321243
2000-01-06 -0.876100 -0.355392  0.550262
2000-01-07 -0.764851 -0.088259  0.779280
2000-01-08 -0.653602  0.178875  1.008298
2000-01-09  1.007996  0.462824  0.254472
2000-01-10  0.307473  0.600337  1.643950

### 补充：参数raw
# raw = True 在apply函数前，现将每一行/列转换为Series
```



## 3. 聚合API   .aggregate()   .agg()   transform()

快速、简洁地执行多个聚合操作

```python
# 数据集
In [160]: tsdf = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],
   .....:                     index=pd.date_range('1/1/2000', periods=10))
   .....: 

In [161]: tsdf.iloc[3:7] = np.nan

In [162]: tsdf
Out[162]: 
                   A         B         C
2000-01-01  1.257606  1.004194  0.167574
2000-01-02 -0.749892  0.288112 -0.757304
2000-01-03 -0.207550 -0.298599  0.116018
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.814347 -0.257623  0.869226
2000-01-09 -0.250663 -1.206601  0.896839
2000-01-10  2.169758 -1.333363  0.283157


### 单个aggregation
In [163]: tsdf.agg(np.sum)
Out[163]: 
A    3.033606
B   -1.803879
C    1.575510
dtype: float64

In [164]: tsdf.agg('sum')
Out[164]: 
A    3.033606
B   -1.803879
C    1.575510
dtype: float64

# these are equivalent to a ``.sum()`` because we are aggregating
# on a single function
In [165]: tsdf.sum()
Out[165]: 
A    3.033606
B   -1.803879
C    1.575510
dtype: float64
    
    
### 针对Series的单个aggregation：返回scalar标量
In [166]: tsdf['A'].agg('sum') #针对Series
Out[166]: 3.033606102414146
```

### .agg()

```python
In [167]: tsdf.agg(['sum'])
Out[167]: 
            A         B        C
sum  3.033606 -1.803879  1.57551

### 多个aggregation：结果是，每一个aggregation都是最终DataFrame的一行
In [168]: tsdf.agg(['sum', 'mean'])
Out[168]: 
             A         B         C
sum   3.033606 -1.803879  1.575510
mean  0.505601 -0.300647  0.262585


### 针对Series：多个aggregation最终结果是Series
In [169]: tsdf['A'].agg(['sum', 'mean'])
Out[169]: 
sum     3.033606
mean    0.505601
Name: A, dtype: float64
        

        
### 补充：传递lambda函数，最终显示lambda
In [170]: tsdf['A'].agg(['sum', lambda x: x.mean()])
Out[170]: 
sum         3.033606
<lambda>    0.505601
Name: A, dtype: float64
        
# 传递自定义函数，显示自定义函数的名称
In [171]: def mymean(x):
   .....:     return x.mean()
   .....: 

In [172]: tsdf['A'].agg(['sum', mymean])
Out[172]: 
sum       3.033606
mymean    0.505601
Name: A, dtype: float64
```



```python
### 多个aggregation：以dict的形式呈现
In [173]: tsdf.agg({'A': 'mean', 'B': 'sum'})
Out[173]: 
A    0.505601
B   -1.803879
dtype: float64
    
    
### 多个aggregation：以list的形式呈现
In [174]: tsdf.agg({'A': ['mean', 'min'], 'B': 'sum'})
Out[174]: 
             A         B
mean  0.505601       NaN
min  -0.749892       NaN
sum        NaN -1.803879
```



```python
### 补充：多种dtypes
# 数据集
In [175]: mdf = pd.DataFrame({'A': [1, 2, 3],
   .....:                     'B': [1., 2., 3.],
   .....:                     'C': ['foo', 'bar', 'baz'],
   .....:                     'D': pd.date_range('20130101', periods=3)})
   .....: 

In [176]: mdf.dtypes
Out[176]: 
A             int64
B           float64
C            object
D    datetime64[ns]
dtype: object
    
    
# C和D列的函数运算无意义
In [177]: mdf.agg(['min', 'sum'])
Out[177]: 
     A    B          C          D
min  1  1.0        bar 2013-01-01
sum  6  6.0  foobarbaz        NaT
```



```python
### 补充：函数命名的应用
In [178]: from functools import partial

In [179]: q_25 = partial(pd.Series.quantile, q=0.25)

In [180]: q_25.__name__ = '25%'

In [181]: q_75 = partial(pd.Series.quantile, q=0.75)

In [182]: q_75.__name__ = '75%'

In [183]: tsdf.agg(['count', 'mean', 'std', 'min', q_25, 'median', q_75, 'max'])
Out[183]: 
               A         B         C
count   6.000000  6.000000  6.000000
mean    0.505601 -0.300647  0.262585
std     1.103362  0.887508  0.606860
min    -0.749892 -1.333363 -0.757304
25%    -0.239885 -0.979600  0.128907
median  0.303398 -0.278111  0.225365
75%     1.146791  0.151678  0.722709
max     2.169758  1.004194  0.896839
```



### .transform()

```python
### 数据集dataset
In [184]: tsdf = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],
   .....:                     index=pd.date_range('1/1/2000', periods=10))
   .....: 

In [185]: tsdf.iloc[3:7] = np.nan

In [186]: tsdf
Out[186]: 
                   A         B         C
2000-01-01 -0.428759 -0.864890 -0.675341
2000-01-02 -0.168731  1.338144 -1.279321
2000-01-03 -1.621034  0.438107  0.903794
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374 -1.240447 -0.201052
2000-01-09 -0.157795  0.791197 -1.144209
2000-01-10 -0.030876  0.371900  0.061932


### 示例
# 以下等价于np.abs(tsdf)
In [187]: tsdf.transform(np.abs)
In [188]: tsdf.transform('abs')
In [189]: tsdf.transform(lambda x: x.abs())

# 针对Series，输出Series
In [191]: tsdf['A'].transform(np.abs)
Out[191]: 
2000-01-01    0.428759
2000-01-02    0.168731
2000-01-03    1.621034
2000-01-04         NaN
2000-01-05         NaN
2000-01-06         NaN
2000-01-07         NaN
2000-01-08    0.254374
2000-01-09    0.157795
2000-01-10    0.030876
Freq: D, Name: A, dtype: float64
```



```python
### 针对多个函数
In [192]: tsdf.transform([np.abs, lambda x: x + 1])
Out[192]: 
                   A                   B                   C          
            absolute  <lambda>  absolute  <lambda>  absolute  <lambda>
2000-01-01  0.428759  0.571241  0.864890  0.135110  0.675341  0.324659
2000-01-02  0.168731  0.831269  1.338144  2.338144  1.279321 -0.279321
2000-01-03  1.621034 -0.621034  0.438107  1.438107  0.903794  1.903794
2000-01-04       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-08  0.254374  1.254374  1.240447 -0.240447  0.201052  0.798948
2000-01-09  0.157795  0.842205  0.791197  1.791197  1.144209 -0.144209
2000-01-10  0.030876  0.969124  0.371900  1.371900  0.061932  1.061932


# 针对Series，输出DataFrame
In [193]: tsdf['A'].transform([np.abs, lambda x: x + 1])
Out[193]: 
            absolute  <lambda>
2000-01-01  0.428759  0.571241
2000-01-02  0.168731  0.831269
2000-01-03  1.621034 -0.621034
2000-01-04       NaN       NaN
2000-01-05       NaN       NaN
2000-01-06       NaN       NaN
2000-01-07       NaN       NaN
2000-01-08  0.254374  1.254374
2000-01-09  0.157795  0.842205
2000-01-10  0.030876  0.969124
```



```python
### 以dict的形式
In [194]: tsdf.transform({'A': np.abs, 'B': lambda x: x + 1})
    
### 嵌套list的字典：得到MultiIndexed DataFrame
In [195]: tsdf.transform({'A': np.abs, 'B': [lambda x: x + 1, 'sqrt']})
Out[195]: 
                   A         B          
            absolute  <lambda>      sqrt
2000-01-01  0.428759  0.135110       NaN
2000-01-02  0.168731  2.338144  1.156782
2000-01-03  1.621034  1.438107  0.661897
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.254374 -0.240447       NaN
2000-01-09  0.157795  1.791197  0.889493
2000-01-10  0.030876  1.371900  0.609836
```



## 4. 元素级 .map   .applymap()

并不是所有的函数都适用于向量(接受Numpy数组，输出另一个数组或值)

- .applymap()针对DataFrame
- .map()针对Series

==支持任何输入单个值，并返回单个值的 Python函数==

比如：`df[Column].apply(lambda x: x.split()[0])`  pd.Series本身没有`.split()`，但可以针对每个数据进行函数操作

```python
In [196]: df4
Out[196]: 
        one       two     three
a  1.394981  1.772517       NaN
b  0.343054  1.912123 -0.050390
c  0.695246  1.478369  1.227435
d       NaN  0.279344 -0.613172

In [197]: def f(x):
   .....:     return len(str(x))
   .....: 

In [198]: df4['one'].map(f)
Out[198]: 
a    18
b    19
c    18
d     3
Name: one, dtype: int64

In [199]: df4.applymap(f)
Out[199]: 
   one  two  three
a   18   17      3
b   19   18     20
c   18   18     16
d    3   19     19


### 补充：Series.map()可基于另一个Series进行映射变换
In [200]: s = pd.Series(['six', 'seven', 'six', 'seven', 'six'],
   .....:               index=['a', 'b', 'c', 'd', 'e'])
   .....: 

In [201]: t = pd.Series({'six': 6., 'seven': 7.})

In [202]: s
Out[202]: 
a      six
b    seven
c      six
d    seven
e      six
dtype: object

In [203]: s.map(t) #基于t进行映射变换 => 如果不看官方文档，压根不会往这方面想
Out[203]: 
a    6.0
b    7.0
c    6.0
d    7.0
e    6.0
dtype: float64
```