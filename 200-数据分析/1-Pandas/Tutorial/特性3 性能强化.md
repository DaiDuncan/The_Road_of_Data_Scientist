底层原理：[Link: Enhancing performance](https://pandas.pydata.org/pandas-docs/stable/user_guide/enhancingperf.html)



- Cython (writing C extensions for pandas)
  - [Pure Python](https://pandas.pydata.org/pandas-docs/stable/user_guide/enhancingperf.html#pure-python)
  - [Plain Cython](https://pandas.pydata.org/pandas-docs/stable/user_guide/enhancingperf.html#plain-cython)
  - [Adding type](https://pandas.pydata.org/pandas-docs/stable/user_guide/enhancingperf.html#adding-type)
  - [Using ndarray](https://pandas.pydata.org/pandas-docs/stable/user_guide/enhancingperf.html#using-ndarray)
  - [More advanced techniques](https://pandas.pydata.org/pandas-docs/stable/user_guide/enhancingperf.html#more-advanced-techniques)
- [Using Numba](https://pandas.pydata.org/pandas-docs/stable/user_guide/enhancingperf.html#using-numba)
- [Expression evaluation via eval()](https://pandas.pydata.org/pandas-docs/stable/user_guide/enhancingperf.html#expression-evaluation-via-eval)

---

# Cython|C的扩展

对于许多用例，用纯Python和NumPy编写熊猫就足够了。但是，在==某些计算量很大的应用==中，可以加载到cython来实现相当大的加速。

## 重构

删除for循环 => 尝试NumPy向量化



最终的cythonized解决方案比纯Python解决方案快约100倍

## 纯Python

```python
In [1]: df = pd.DataFrame({'a': np.random.randn(1000),
   ...:                    'b': np.random.randn(1000),
   ...:                    'N': np.random.randint(100, 1000, (1000)),
   ...:                    'x': 'x'})
   ...: 

In [2]: df
Out[2]: 
            a         b    N  x
0    0.469112 -0.218470  585  x
1   -0.282863 -0.061645  841  x
2   -1.509059 -0.723780  251  x
3   -1.135632  0.551225  972  x
4    1.212112 -0.497767  181  x
..        ...       ...  ... ..
995 -1.512743  0.874737  374  x
996  0.933753  1.120790  246  x
997 -0.308013  0.198768  157  x
998 -0.079915  1.757555  977  x
999 -1.010589 -1.115680  770  x

[1000 rows x 4 columns]

### 目标：逐行应用函数
# 纯Python
In [3]: def f(x):
   ...:     return x * (x - 1)
   ...: 

In [4]: def integrate_f(a, b, N):
   ...:     s = 0
   ...:     dx = (b - a) / N
   ...:     for i in range(N):
   ...:         s += f(a + i * dx)
   ...:     return s * dx
   ...: 
        
        
# df.apply
In [7]: %timeit df.apply(lambda x: integrate_f(x['a'], x['b'], x['N']), axis=1)
10 loops, best of 3: 174 ms per loop
    
### prun（ipython magic函数）：计算在此操作中花费的时间
In [5]: %prun -l 4 df.apply(lambda x: integrate_f(x['a'], x['b'], x['N']), axis=1)  # noqa E999
         622830 function calls (622809 primitive calls) in 0.181 seconds

   Ordered by: internal time
   List reduced from 214 to 4 due to restriction <4>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1000    0.104    0.000    0.149    0.000 <ipython-input-4-c2a74e076cf0>:1(integrate_f)
   552423    0.044    0.000    0.044    0.000 <ipython-input-3-c138bdd570e3>:1(f)
     3000    0.005    0.000    0.023    0.000 series.py:868(__getitem__)
     3000    0.003    0.000    0.016    0.000 series.py:973(_get_value)
```

大部分时间都花在integrate_f或中f，因此我们将集中精力进行这两个功能的计算。





## Plain Cython

```python
### 将Cython魔术函数导入ipython
In [6]: %load_ext Cython
    
    
In [7]: %%cython
   ...: def f_plain(x):
   ...:     return x * (x - 1)
   ...: def integrate_f_plain(a, b, N):
   ...:     s = 0
   ...:     dx = (b - a) / N
   ...:     for i in range(N):
   ...:         s += f_plain(a + i * dx)
   ...:     return s * dx


In [4]: %timeit df.apply(lambda x: integrate_f_plain(x['a'], x['b'], x['N']), axis=1)
10 loops, best of 3: 85.5 ms per loop
```

这已经节省了三分之一时间



## 添加类型

```python
In [8]: %%cython
   ...: cdef double f_typed(double x) except? -2:
   ...:     return x * (x - 1)
   ...: cpdef double integrate_f_typed(double a, double b, int N):  #添加类型
   ...:     cdef int i
   ...:     cdef double s, dx
   ...:     s = 0
   ...:     dx = (b - a) / N
   ...:     for i in range(N):
   ...:         s += f_typed(a + i * dx)
   ...:     return s * dx
   ...: 
        
In [4]: %timeit df.apply(lambda x: integrate_f_typed(x['a'], x['b'], x['N']), axis=1)
10 loops, best of 3: 20.3 ms per loop
    
    
In [9]: %prun -l 4 df.apply(lambda x: integrate_f_typed(x['a'], x['b'], x['N']), axis=1)
         70396 function calls (70375 primitive calls) in 0.031 seconds

   Ordered by: internal time
   List reduced from 208 to 4 due to restriction <4>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     3000    0.004    0.000    0.020    0.000 series.py:868(__getitem__)
     3000    0.003    0.000    0.014    0.000 series.py:973(_get_value)
     3000    0.002    0.000    0.006    0.000 base.py:2854(get_loc)
     3000    0.002    0.000    0.004    0.000 base.py:4979(_maybe_cast_indexer)
```

比原始python实现快十倍以上





## 使用ndarray

目标：从每一行创建一个Series，并从索引和序列（每行三次）获取结果

函数调用在Python中运算消耗大，因此也许我们可以通过对应用部分进行cythonize来将其最小化

- 将ndarrays传递给Cython函数，幸运的是Cython与NumPy的配合非常好

```python
In [10]: %%cython
   ....: cimport numpy as np
   ....: import numpy as np
   ....: cdef double f_typed(double x) except? -2:
   ....:     return x * (x - 1)
   ....: cpdef double integrate_f_typed(double a, double b, int N):
   ....:     cdef int i
   ....:     cdef double s, dx
   ....:     s = 0
   ....:     dx = (b - a) / N
   ....:     for i in range(N):
   ....:         s += f_typed(a + i * dx)
   ....:     return s * dx
   ....: cpdef np.ndarray[double] apply_integrate_f(np.ndarray col_a, np.ndarray col_b,
   ....:                                            np.ndarray col_N):
   ....:     assert (col_a.dtype == np.float
   ....:             and col_b.dtype == np.float and col_N.dtype == np.int)
   ....:     cdef Py_ssize_t i, n = len(col_N)
   ....:     assert (len(col_a) == len(col_b) == n)
   ....:     cdef np.ndarray[double] res = np.empty(n)
   ....:     for i in range(len(col_a)):
   ....:         res[i] = integrate_f_typed(col_a[i], col_b[i], col_N[i])
   ....:     return res
```

创建一个零数组并在行上循环，应用integrate_f_typed，然后将其放入零数组

不能将aSeries作为ndarray类型参数直接传递给Cython函数。而是ndarray使用 传递实际值Series.to_numpy()。原因是==Cython定义 基于ndarray==而不是传递的Series

```python
apply_integrate_f(df['a'].to_numpy(),
                  df['b'].to_numpy(),
                  df['N'].to_numpy())

### 错误方式
# apply_integrate_f(df['a'], df['b'], df['N'])
```

这样的循环在Python中非常慢，但在Cython中，对NumPy数组的循环是快速的。

```python
In [4]: %timeit apply_integrate_f(df['a'].to_numpy(),
                                  df['b'].to_numpy(),
                                  df['N'].to_numpy())
1000 loops, best of 3: 1.25 ms per loop
    
### 再次检查时间消耗在哪里
In [11]: %%prun -l 4 apply_integrate_f(df['a'].to_numpy(),
   ....:                               df['b'].to_numpy(),
   ....:                               df['N'].to_numpy())
   ....: 
         218 function calls in 0.001 seconds

   Ordered by: internal time
   List reduced from 59 to 4 due to restriction <4>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.001    0.001    0.001    0.001 {built-in method _cython_magic_6881e8aa4e75f7c54d4f9fef93591f6a.apply_integrate_f}
        3    0.000    0.000    0.000    0.000 frame.py:2869(__getitem__)
        3    0.000    0.000    0.000    0.000 managers.py:993(iget)
        1    0.000    0.000    0.001    0.001 {built-in method builtins.exec}
```

现在大部分时间都花在了上apply_integrate_f

```python
In [12]: %%cython
   ....: cimport cython
   ....: cimport numpy as np
   ....: import numpy as np
   ....: cdef double f_typed(double x) except? -2:
   ....:     return x * (x - 1)
   ....: cpdef double integrate_f_typed(double a, double b, int N):
   ....:     cdef int i
   ....:     cdef double s, dx
   ....:     s = 0
   ....:     dx = (b - a) / N
   ....:     for i in range(N):
   ....:         s += f_typed(a + i * dx)
   ....:     return s * dx
   ....: @cython.boundscheck(False)
   ....: @cython.wraparound(False)
   ....: cpdef np.ndarray[double] apply_integrate_f_wrap(np.ndarray[double] col_a,
   ....:                                                 np.ndarray[double] col_b,
   ....:                                                 np.ndarray[int] col_N):
   ....:     cdef int i, n = len(col_N)
   ....:     assert len(col_a) == len(col_b) == n
   ....:     cdef np.ndarray[double] res = np.empty(n)
   ....:     for i in range(n):
   ....:         res[i] = integrate_f_typed(col_a[i], col_b[i], col_N[i])
   ....:     return res
   ....: 
        
        
In [4]: %timeit apply_integrate_f_wrap(df['a'].to_numpy(),
                                       df['b'].to_numpy(),
                                       df['N'].to_numpy())
1000 loops, best of 3: 987 us per loop
```



## 小结

代码风格类似C





# Numba

静态编译Cython代码的最新替代方法：是使用动态jit编译器Numba

Numba使您能够使用直接用Python编写的高性能函数来加速您的应用程序。通过一些注释，可以将==面向数组且数学运算繁重的Python代码==**即时编译**为本机指令，其性能与C，C ++和Fortran相似，而无需切换语言或Python解释器

Numba通过在导入时间，运行时或静态（使用附带的pycc工具）使用LLVM编译器基础结构生成优化的机器代码来工作。Numba支持Python编译以在CPU或GPU硬件上运行，并且旨在与Python科学软件堆栈集成

```python
conda install numba
'''
从Numba版本0.20开始，不能将pandas对象直接传递给Numba编译的函数
将Pandas对象下面的NumPy数组传递给Numba编译的函数
'''
import numba


@numba.jit  #jit装饰器
def f_plain(x):
    return x * (x - 1)


@numba.jit
def integrate_f_numba(a, b, N):
    s = 0
    dx = (b - a) / N
    for i in range(N):
        s += f_plain(a + i * dx)
    return s * dx


@numba.jit
def apply_integrate_f_numba(col_a, col_b, col_N):
    n = len(col_N)
    result = np.empty(n, dtype='float64')
    assert len(col_a) == len(col_b) == n
    for i in range(n):
        result[i] = integrate_f_numba(col_a[i], col_b[i], col_N[i])
    return result


def compute_numba(df):
    result = apply_integrate_f_numba(df['a'].to_numpy(),
                                     df['b'].to_numpy(),
                                     df['N'].to_numpy())
    return pd.Series(result, index=df.index, name='result')


In [4]: %timeit compute_numba(df)
1000 loops, best of 3: 798 us per loop  #结果比Cython
```



## 向量化

```python
import numba

def double_every_value_nonumba(x):
    return x * 2

@numba.vectorize
def double_every_value_withnumba(x):  # noqa E501
    return x * 2

# Custom function without numba
In [5]: %timeit df['col1_doubled'] = df['a'].apply(double_every_value_nonumba)  # noqa E501
1000 loops, best of 3: 797 us per loop

# Standard implementation (faster than a custom function)
In [6]: %timeit df['col1_doubled'] = df['a'] * 2
1000 loops, best of 3: 233 us per loop

# Custom function with numba
In [7]: %timeit df['col1_doubled'] = double_every_value_withnumba(df['a'].to_numpy())
1000 loops, best of 3: 145 us per loop
```



## 小结

Numba将在任何函数上执行，但只能加速某些类的函数

- 数值函数应用于NumPy数组的函数(以nopython模式执行)



# 表达式|eval()

pandas.eval()实现Series和DataFrame对象的表达式求值

实际上， eval()较小的表达式/对象要比普通的Python慢许多个数量级

=> eval()适合在具有 DataFrame10,000行以上的行时使用

- 数据越大
- 表达式越长





## 支持语法

- 除了左移<<和右移>>之外的运算符：df + 2 * pi / s ** 4 % 42 - the_golden_ratio
- 比较运算：2 < df < df2
- 布尔运算(and or not)：df < df2 and df3 < df4 or not df_bool
- list和tuple literals
- 属性访问：df.a
- 下标访问：df[0]
- 简单变量：pd.eval('df')(但意义不大)
- 数学函数：
  - sin, cos
  - exp, log, expm1, log1p，log10
  - sqrt, 
  - sinh, cosh, tanh
  - arcsin, arccos, arctan，arctan2
  - arccosh, arcsinh, arctanh
  - abs

## 不支持的pthon语法

- 表达式
  - 除了数学函数之外的函数
  - is/is not
  - if
  - lambda
  - list/set/dict comprehensions
  - dict和set literals
  - yield表达式
  - 生成表达式
  - 质保函标量值的布尔表达式
- 语句
  - for
  - while
  - if



## 示例

```python
In [13]: nrows, ncols = 20000, 100
In [14]: df1, df2, df3, df4 = [pd.DataFrame(np.random.randn(nrows, ncols)) for _ in range(4)]
    
### 针对数学运算
In [15]: %timeit df1 + df2 + df3 + df4
13.2 ms +- 44.1 us per loop (mean +- std. dev. of 7 runs, 100 loops each)

In [16]: %timeit pd.eval('df1 + df2 + df3 + df4')
6.92 ms +- 19.8 us per loop (mean +- std. dev. of 7 runs, 100 loops each)


### 针对比较
In [17]: %timeit (df1 > 0) & (df2 > 0) & (df3 > 0) & (df4 > 0)
8.25 ms +- 38.7 us per loop (mean +- std. dev. of 7 runs, 100 loops each)

In [18]: %timeit pd.eval('(df1 > 0) & (df2 > 0) & (df3 > 0) & (df4 > 0)')
9.52 ms +- 69.9 us per loop (mean +- std. dev. of 7 runs, 100 loops each)


### 针对 非对齐对象
In [19]: s = pd.Series(np.random.randn(50))

In [20]: %timeit df1 + df2 + df3 + df4 + s
16.4 ms +- 78.9 us per loop (mean +- std. dev. of 7 runs, 10 loops each)

In [21]: %timeit pd.eval('df1 + df2 + df3 + df4 + s')
7.48 ms +- 27.7 us per loop (mean +- std. dev. of 7 runs, 100 loops each)
```



## 例外|应该在Python中执行

```python
1 and 2  # would parse to 1 & 2, but should evaluate to 2
3 or 4  # would parse to 3 | 4, but should evaluate to 3
~1  # this is okay, but slower when using eval
```

如果尝试使用非bool或类型的标量操作数执行任何布尔/按位运算，则会引发异常np.bool_。

同样，您应该在普通的Python中执行这些类型的操作。





## df.eval()

```python
In [22]: df = pd.DataFrame(np.random.randn(5, 2), columns=['a', 'b'])

In [23]: df.eval('a + b')
Out[23]: 
0   -0.246747
1    0.867786
2   -1.626063
3   -1.134978
4   -1.027798
dtype: float64
    
    
df.eval('c = a + b', inplace=True)
df.eval('d = a + b + c', inplace=True)
df.eval('a = 1', inplace=True)
In [32]: df.eval("""
   ....: c = a + b
   ....: d = a + b + c
   ....: a = 1""", inplace=False)
    
    
### python中等价的表达
In [33]: df = pd.DataFrame(dict(a=range(5), b=range(5, 10)))

In [34]: df['c'] = df['a'] + df['b']

In [35]: df['d'] = df['a'] + df['b'] + df['c']

In [36]: df['a'] = 1

In [37]: df
Out[37]: 
   a  b   c   d
0  1  5   5  10
1  1  6   7  14
2  1  7   9  18
3  1  8  11  22
4  1  9  13  26

```

- 参数inplace => df.query()

```python
In [38]: df = pd.DataFrame(dict(a=range(5), b=range(5, 10)))

In [39]: df.query('a > 2')
Out[39]: 
   a  b
3  3  8
4  4  9

In [40]: df.query('a > 2', inplace=True)

In [41]: df
Out[41]: 
   a  b
3  3  8
4  4  9
```



## 局部变量

```python
In [42]: df = pd.DataFrame(np.random.randn(5, 2), columns=list('ab'))

In [43]: newcol = np.random.randn(len(df))

In [44]: df.eval('b + @newcol')
Out[44]: 
0   -0.173926
1    2.493083
2   -0.881831
3   -0.691045
4    1.334703
dtype: float64

In [45]: df.query('b < @newcol')
Out[45]: 
          a         b
0  0.863987 -0.115998
2 -2.621419 -1.297879


# 局部变量与列名相同
In [46]: a = np.random.randn()

In [47]: df.query('@a < a')
Out[47]: 
          a         b
0  0.863987 -0.115998

In [48]: df.loc[a < df['a']]  # same as the previous expression
Out[48]: 
          a         b
0  0.863987 -0.115998


### 报错
In [49]: a, b = 1, 2

In [50]: pd.eval('@a + b')
Traceback (most recent call last):

  File "/opt/conda/envs/pandas/lib/python3.8/site-packages/IPython/core/interactiveshell.py", line 3418, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)

  File "<ipython-input-50-af17947a194f>", line 1, in <module>
    pd.eval('@a + b')

  File "/pandas/pandas/core/computation/eval.py", line 330, in eval
    _check_for_locals(expr, level, parser)

  File "/pandas/pandas/core/computation/eval.py", line 158, in _check_for_locals
    raise SyntaxError(msg)

  File "<string>", line unknown
SyntaxError: The '@' prefix is not allowed in top-level eval calls.
please refer to your variables by name without the '@' prefix.

### 改正：想python一样直接使用
In [51]: pd.eval('a + b')
Out[51]: 3
```





# pandas.eval()解析器

可以将两个不同的解析器和两个不同的引擎用作后端

```python
In [52]: expr = '(df1 > 0) & (df2 > 0) & (df3 > 0) & (df4 > 0)'

### python解析器
In [53]: x = pd.eval(expr, parser='python')

In [54]: expr_no_parens = 'df1 > 0 & df2 > 0 & df3 > 0 & df4 > 0' #等价于expr_with_ands = 'df1 > 0 and df2 > 0 and df3 > 0 and df4 > 0'

### pandas解析器
In [55]: y = pd.eval(expr_no_parens, parser='pandas')

In [56]: np.all(x == y)
Out[56]: True
```



# pandas.eval()后端

使用'python'引擎通常没有用，除了针对它测试其他评估引擎。与一起使用将不会带来任何性能优势eval()，engine='python'并且实际上可能会导致性能下降。

```python
In [62]: %timeit df1 + df2 + df3 + df4
13.1 ms +- 23.8 us per loop (mean +- std. dev. of 7 runs, 100 loops each)

In [63]: %timeit pd.eval('df1 + df2 + df3 + df4', engine='python')
14 ms +- 67 us per loop (mean +- std. dev. of 7 runs, 100 loops each)
```





# pandas.eval()性能

旨在加快某些种类的操作。特别是那些涉及大型复杂的表达式运算：针对DataFrame/Series对象应该看到一个显著的性能优势

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20201222111702.png" alt="image-20201222111701870" style="zoom:67%;" />

Python适合于较小的数据(大约15,000至20k行)

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20201222111727.png" alt="image-20201222111727108" style="zoom:80%;" />