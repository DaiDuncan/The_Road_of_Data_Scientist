



# 评价指标|数值数据

- 决定系数：$R_i^2$
- MSE：均方差误差



注意：增加变量时，以上两个指标都被改善

![Some metrics are influenced by  Scale  feet, meters, inches, etc  Variables  Model Assum tions and T  es  Common Model  Evaluation Metrics  MSE  Mean-Squared Error  AIC  Akaike Information Criteria  BIC  Bayesian Information Criteria  Mallow's CP ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222084917.png)









# 评价指标|分类数据

针对二分问题



## 补充|阳性 阴性，真 假的理解⭐

@理论基础 数学-概统 假设检验：*原假设与备用假设⭐*

==P(推断pred|实际actuall)==



### 阴性 阳性：针对预测

首先在于H0与H1的定义：

- 法院定罪：H0 无罪推定
- 医院治病：H0 有病推定
  - 阳性是有病
  - 阴性是没病
- 产品质量：H0 有故障推定
- 识别
  - 阳性是当前对象@下例：图像识别



间而言之：阳性对应H0





### 真 假：预测是否与事实相符？

如果与事实相符，就是真

否则就是假





## 混淆矩阵 confusion matrix

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222101309.png" alt="img" style="zoom: 67%;" />



[Link：sklearn中的混淆矩阵](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)

```python
sklearn.metrics.confusion_matrix
```

![Thus in binary classification, the count of true negatives is Co,o,  false negatives is Cl,o, true positives is Cl,l and false positives  is Co,l. ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222171854.png)

注意：下列表格与上图不一致

| 真实情况↓模型预测→ | False  |  True  |
| :----------------: | :----: | :----: |
|       False        | ==TN== |   FP   |
|        True        |   FN   | ==TP== |





### #准确率accuracy

准确率 = (真阳性+真阴性)/全部样本



- 正确标记的行数/总行数

![ACCURACY  number of correct labels  number of rows  NOT ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222101350.png)

问题：数据不均衡时，产生偏差较大





### #假阳性 P(H0|H1) => P(+|-)

@回顾-假设检验——相当于II类错误：

- 阳性|推断为H0(无罪，有病，质量有问题)
- 假|推断与实际不相符 => 实际上是H1(有罪，没病，质量没问题)



误报：

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222103811.png" alt="posiKl,e  ٨e اله  المطه محله " style="zoom: 67%;" />

### #假阴性 P(H1|H0) => P(-|+)

![img](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222111109.png)





### 查全率recall(召回率)|**宁愿错杀，不可漏掉**

本质：所有对的样例，你找出了多少，或者说你判断对了多少

- 场景：识别垃圾邮件



前提：产品质量合格

- ==关注行==：真实数据被预测/分类错误 => 从预测结果中“召回”

![img](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222103902.png)

### 查准率precision|**宁愿漏掉，不可错杀**

本质：推断/认为是对的样例中，到底有多少真是对的

- 场景：金融风控领域，希望系统能够筛选出所有有风险的行为或用户，然后交给人工鉴别，漏掉一个可能造成灾难性后果



前提：在预测的范围内进行计算

- ==关注列==：预测结果==中==的**准**确性



![o ranpybaqv  ranpysq  asaY± ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222104905.png)







### 实例|理解

主成分分析PCA——>基于特征对应的姓名(面部图)，识别人脸

主成分分析PCA：提取面部图特征，再输入到SVM，结果如下：

![image-20210222104105928](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222104106.png)

1 有多少Chavez的图片(数据集中)？——True行

2 Chavez预测的准确性？除了对角线，都被分类错误 ——关注行：基于产品质量合格的前提

3 根据预测结果，确实是Chavez的概率？——关注列：针对预测的结果

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222104143.png" alt="img" style="zoom: 67%;" />



### 小结

一般来说，查全查准不可兼得，除非在一些简单任务中。

- 很好理解，做出正预测多，查全率必然上升，但查准率就要下降。

- 反之，尽量少预测，查准率必然高，但是查全率要低很多。



## F1度量

F1度量是基于查准率和查全率的调和平均（harmonic mean）定义的：

- 相比于算术平均和几何平均，调和平均更注重较小值

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222111617.png" alt="image-20210222111617108" style="zoom:67%;" />



## $F_{\beta}$度量

==加权==调和平均，是F1度量的一般形式：

- 若认为 Precision 更重要，则减小 β，若认为 Recall 更重要，则增大 β

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222111706.png" alt="image-20210222111705949" style="zoom: 67%;" />

