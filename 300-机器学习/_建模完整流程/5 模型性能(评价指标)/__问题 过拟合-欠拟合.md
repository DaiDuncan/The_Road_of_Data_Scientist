# 判断模型性能|过拟合 欠拟合

然而，通常情况下，我们并不知道什么函数能以最好的方式代表我们的数据，也不知道什么模型可能是最适合我们的。那么，我们如何找到最佳拟合模型，我们可以遵循哪些标志来判断一个模型的性能呢？



## 1 分散交叉验证和训练错误

这里的总体思路是将训练数据集分割成 k 个较小的子集（fold）。随后，你在其中 k-1 个子集上训练你的模型，并评估模型在剩余子集上的性能。

你重复这个过程 k 次，最后得到 k 个评价分数。为了得到总体交叉验证得分，你可以简单地取 k 个分数的平均值。



如果一个模型在训练集上表现良好，但交叉验证分数很低，那么这个模型就是过拟合

如果模型在训练集上的表现很差，而根据交叉验证得分同样很差，则模型为欠拟合



@线性回归模型

1）简单线性回归的均方根误差：平均偏差约为 0.77，这就是我们的训练误差

```python
from sklearn.metrics import mean_squared_error
np.sqrt(mean_squared_error(y, linear_reg.predict(X)))
0.7736957615287954
```

2）计算一下线性模型的交叉验证分数

```python
from sklearn.model_selection import cross_val_score
lin_reg_scores = cross_val_score(linear_reg, X, y, scoring = “neg_mean_squared_error”, cv = 10)

# 总共进行了 10 次
p.mean(np.sqrt(-lin_reg_scores))
0.7917563622242139
```

最后，我们得到了平均交叉验证 RMSE 为 0.79。如果我们将此误差与训练集误差进行比较，我们可以看到大约 0.02 的差异。

交叉验证误差高于训练误差是正常的，但 0.02 是好是坏？是高还是低？





@二次多项式回归

均方根误差是0.27

对于多项式模型，我们得到的交叉验证 RMSE 为 0.28，与训练数据的 RMSE 仅相差 0.01



在我们的例子中，

- 线性回归的 RMSE 远高于多项式回归的 RMSE。

- 此外，对于线性回归，训练数据和交叉验证之间的 RMSE 差异更大 (0.02>0.01)。

这两个标志得出结论，线性回归是欠拟合的数据。





@高次多项式回归的均方根误差

- 训练数据是0.24
- 交叉验证 RMSE是 1020471.12

该模型严重过拟合训练数据



### 结论

- 高训练误差和更高的交叉验证误差 →**欠拟合的标志**
- 低训练误差和略高的交叉验证误差 →**完美拟合的标志**
- 极低的训练误差和极高的交叉验证误差 →**过拟合的标志**



## 2 学习曲线

学习曲线可视化了模型性能与训练数据大小之间的关系

### 欠拟合学习曲线

```python
#split training set into training and validation set
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=4)
train_errors = [] #append training errors for plot
val_errors = []  #append validation errors for plot


#loop over each observation and iteratively compute RMSE for the new training and the entire validation set
#in each iteration add one more observation to the training set
for i in range(1, len(X_train)):
linear_reg.fit(X_train[:i], y_train[:i])
y_train_predicted = linear_reg.predict(X_train[:i])
y_val_predicted = linear_reg.predict(X_val)
train_errors.append(mean_squared_error(y_train[:i], y_train_predicted))
val_errors.append(mean_squared_error(y_val, y_val_predicted))
plt.plot(np.sqrt(train_errors), “r-”, linewidth=2, label=”trainining set”)
plt.plot(np.sqrt(val_errors), “b-”, linewidth=2, label=”validation set”)
plt.legend(loc=”upper right”, fontsize=15)
plt.xlabel(“Training / Validation set size”, fontsize=15)
plt.ylabel(“Root Mean Square Error”, fontsize=15)
```

<img src="https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317114628.png" alt="image-20210317114628405" style="zoom:80%;" />

训练集的 RMSE（红线）

- 最初只有几个实例的时候，训练误差是非常低的，因为线性模型可以很好地拟合一两个实例
- 但是一旦训练集开始变大，RMSE 就开始非常快速地上升，直到 30 个实例左右达到一个恒定的水平
- 这时，算法停止了它能学习的东西（记住我们的数据是二次的，而我们的模型是线性的），增加训练数据大小已经没有帮助了



验证集误差（蓝线）

- 最初非常高，因为线性模型只在少数实例上训练
- 然而，随着每一个新实例加入到训练集中，它迅速变得越来越小
- 直到很快达到一个比训练集误差略高的水平的平稳状态

这些类型的曲线是数据欠拟合的模型的特征。





### 过拟合学习曲线

一个高的验证误差和一个低的训练误差

然而，在蓝线的最末端可以看到一个非常有趣的细节：随着训练实例的增多，验证误差开始显著下降，最终非常接近训练误差——最终得到一个更好的模型。

<img src="https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317114723.png" alt="image-20210317114722849" style="zoom:80%;" />



# 解决方法

## 过拟合

- **使用更多的数据**！

  如果你不断向训练数据集添加新的特征，验证误差最终会下降，模型也会停止过拟合。然而，通常情况下，训练数据集是有限的，因此需要一个不同的策略。

- **正则化**：换句话说，对模型施加一些约束，==降低自由度，对模型施加的约束越多==（模型的自由度越少），数据就越难被过拟合。

  在我们的例子中，这意味着例如降低多项式的次数。

  在回归方面，你也应该研究一下 Ridge、Lasso 或 Elastic Net Regression，它们对模型权重有不同的约束。

- 降低模型复杂度
- 集成学习方法⭐



## 欠拟合

- **使用更多的数据** => 添加新特征⭐

  是的，在这种情况下，更多的数据很可能会在一定程度上提高模型的性能。

  但是，如果对数据的假设是错误的，你决定使用的分类器无法捕捉到数据的真实性质，那么单纯的增加更多的数据是不会有效果的。

- **增加复杂度**：在欠拟合的情况下，对模型施加较少的约束并增加其复杂度，将很有可能得到更好的模型。复杂性的增加可能意味着超越简单的线性模型，

  利用多项式模型，或者甚至基于树的模型。
  
- 减少正则化





当然还有更多的策略来克服这个问题，但是==数据量==和==模型复杂度==可以看做是大部分策略中最小的公分母。

然而，在你开始切换模型并改变其复杂度之前，你应该首先检查你的模型是否过拟合或欠拟合，这样你就可以开始走向正确的方向。