# 主题|模型的泛化能力

泛化generalization能力

一般来说，训练集越大，模型的泛化能力越强。如何理解呢？通常假定样本空间中全部样本服从一个未知分布（distribution）N，我们的训练样本是独立地从这个分布采样得到的，即==独立同分布==。

一般而言，训练样本越多，我们得到的关于分布 N 的信息就越多，这样就越有可能通过学习获得更强泛化能力的模型。







希望通过机器学习学得的模型的泛化能力比较强：学得的模型不仅仅在在训练样本中工作得很好，更应该在新的样本中工作很好。

- 分类错误的样本数占总样本数的比例称为错误率（error rate）
- 准确度（accuracy）= 1 - 错误率



将模型在训练集上的误差称为训练误差（train error），在测试集上的误差称为测试误差（test error）

在==假设测试数据与真实数据独立同分布的前提==下，测试误差可以作为泛化误差（generalization error）的近似



希望能够得到泛化误差小的模型，但是由于我们事先不知道测试集是什么样子，所以我们在使用机器学习算法时，不会提前固定参数，而是调整参数去降低训练误差

在整个过程中，泛化误差的期望会大于等于训练误差的期望。

想要保证模型效果好，也就是泛化误差比较小，可以通过以下两个因素来实现：

1. 降低训练误差。
2. 缩小训练误差和泛化误差的差距。



![image-20210317093943378](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317093943.png)

### 欠拟合（underfitting）

模型不能在训练集上获得足够低的误差



### 过拟合（overfitting）

过拟合是指训练误差和泛化误差之间的差距太大

示例：上学考试的时候，有的人采取题海战术，把每个题目都背下来。但是题目稍微一变，他就不会做了。因为他非常复杂的记住了每道题的做法，而没有抽象出通用的规则。



相比于欠拟合，过拟合在实际工作中更为常见，出现过拟合的原因常见的有以下几种：

- ==训练集和测试集分布不一致==。
- 训练集的==数量级和模型的复杂度不匹配==。训练集的数量级小于模型的复杂度。
- 样本里的==噪音数据干扰过大，大到模型过分记住了噪音特征==，反而忽略了真实的输入输出间的关系。



### 偏差和方差

希望在能够得到一个泛化误差比较小的模型的同时，也希望能够解释为什么模型的泛化误差比较小（或者比较大）

将模型的期望泛化误差分解为两部分：泛化误差 = 偏差 + 方差

- 偏差度量了学习算法的期望预测与真实结果偏离程度，即刻画了学习算法本身的拟合能力
- 方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响，或者说学习算法的稳定性

泛化性能是由学习算法的能力、==数据的充分性==以及学习任务本身的难度所共同决定的。

给定学习任务，为了取得好的泛化性能，则需使偏差较小，既能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小。

示例：扔飞镖

<img src="https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317094418.png" alt="image-20210317094417720" style="zoom:80%;" />



- 左上角的低偏差、低方差是理想中的模型，类似于把飞镖扔到了离靶心很近的地方，并且聚集效果也很好
- 右上角的低偏差、高方差是模型过拟合的表现，类似把飞镖扔到了离靶心很近的地方，但是聚集效果效果不好
- 左下角的高偏差、低方差是模型欠拟合的表现，类似把飞镖扔到了离靶心很远的地方，但是都集中在一个位置
- 右下角的高偏差、高方差是最差的模型了，类似于把飞镖扔到了靶子上，但是飞镖离靶心也很远，而且彼此间很分散

一般来说，偏差和方差是有冲突的，也就是说

- 当模型==复杂度较低==时，模型的偏差较高，方差较低； => 欠拟合
- 当模型复杂度较高时，模型的偏差较低，方差较高。 => 过拟合

![image-20210317094528418](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317094528.png)

意义：当我们有了模型的偏差和方差之后，就能够知道下一步该如何优化算法。

假设说，我们的分类器模型在训练集上的错误率为1%，测试集上的错误率为11%，我们==估计它的偏差为1%==，方差为11%-1%=10%(测试集与训练集错误率的差异)，明显过拟合了，所以下一步优化时应该考虑降低方差。

如果说一个分类器模型在训练集上的错误率为15%，测试集上的错误率为16%，我们==估计它的偏差为15%==，方差为16%-15%=1%，明显欠拟合了，所以下一步优化时应该考虑降低偏差。



### 贝叶斯误差

贝叶斯误差也叫最优误差，指的就是现有技术下人和机器==能做到最好的情况下==，出现的误差。



人类擅长很多任务，比如图像识别和语音识别这类处理自然数据的任务，人类水平和贝叶斯水平相差不远，通常用人类水平来近似成贝叶斯水平，也就是说人的误差可以近似地看成贝叶斯误差。

有了贝叶斯误差之后，饿哦们可以将偏差分解为贝叶斯误差与可避免偏差之和。

即：偏差 = 贝叶斯误差 + 可避免偏差



假设我们训练了一个分类器模型，在训练集上的错误率有15%，在测试集上的错误率有30%

- 如果说==贝叶斯误差==为14%，那么我们可以知道它的==可避免误差==有15%-14%=1%
- 方差有30%-15%=15%

这时候，我们应该考虑如何降低方差，而不是降低偏差。



## 方法|降低偏差和方差

1 降低模型的偏差，能够降低模型欠拟合的风险；

- 增加新特征。比如挖掘组合特征、上下文特征、ID类特征。
- ==增加模型复杂度==。比如在线性模型中增加高次项，在神经网络中增加网络层数或神经元个数。
- ==减少或去除正则化系数==。比如L1、L2、dropout等。



2 降低模型的方差，能够降低模型过拟合的风险。

- 增加更多的训练数据。
- 降低模型复杂度。比如决策树模型中降低树深度、进行剪枝等。
- ==加入正则化==。使用正则化能够给模型的参数进行一定的约束，避免过拟合。









## 定理|没有免费的午餐

No Free Lunch Theorem，简称 NFL：无论我们能设想到的最先进的算法还是多么笨拙的算法（比如胡乱猜测），它们的期望性能其实都是相同的



经常听人谈论“什么算法更好”或者“A算法比B算法好”这样类似说法，其实这样的说法忽略了一个前提，那就是在解决某一个具体的问题（任务）上。



为什么这么说呢，因为如果考虑所有潜在的问题，所有的学习算法都一样好。

要谈论算法的相对优劣，必须要==针对具体的问题和任务==才有意义。

- 每个算法都有它适合的数据集，也就是说它适合的任务



=> 所以我们关注的就是在当前要解决的问题下（或者任务下），为它找到一个合适的解决方案。

所以说，**机器学习研究的目标不是找一个通用学习算法或是绝对最好的学习算法。**

**反之，我们的目标是理解什么样的分布与机器学习获取经验的“真实世界”相关，什么样的学习算法在我们关注的数据生成分布上效果最好。**





## #小结-思考|问题

1. 小明在平时模拟考试时基本上都是考95分，但是一上考场遇到真实考题，就只能考70分，小明的这种情况对应机器学习中的哪种现象？

   过拟合：训练成绩好，测试成绩差(偏差小，方差大)

2. 思考下欠拟合和过拟合与模型复杂的之间的关系什么？

   模型复杂度小，那么容易偏差大，方差小，也就造成欠拟合的情况

3. 对于模型来说，如果训练集和测试集的分布不一致，会造成什么问题呢？

   

4. 医生或者机器可以通过片子看病，普通的医生的准确诊断率为92%，有经验的专家为95%，多个专家组成的专家组的为98%，机器学习给出的预测的准确率为99%，那贝叶斯误差是多少呢？

   贝叶斯误差是最好情况下出现的误差：也就是1%

