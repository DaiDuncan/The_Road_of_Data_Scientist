拟合问题比较简单，所用到的衡量指标也相对直观，假设：

- $y_i$是第i个样本的真实值
- $\hat{y}_i$是第i个样本的预测值



## 示例|线性回归

一元变量 & 二元变量

<img src="https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316212310.png" alt="image-20210316212310371" style="zoom:80%;" />

### 残差不合适

![image-20210316212343758](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316212343.png)



## 1 MAE平均绝对误差

平均绝对误差MAE（Mean Absolute Error）又被称为L1范数损失

![image-20210316164730367](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316164730.png)

### 思考|MAE有哪些不足？

MAE虽能较好衡量回归模型的好坏，但是绝对值的存在导致函数不光滑，在某些点上不能求导，可以考虑将绝对值改为残差的平方，这就是均方误差。



## 2 MSE平均平方误差 => RMSE均方根误差

Mean Squared Error

一般情况下， RMSE 能够很好地反映回归模型预测值与真实值的偏离程度

但在实际问题中，如果存在个别偏离程度非常大的离群点(Outlier）时,即使离群点数量非常少,也会让RMSE指标变得很差。



==遵循一个假设，即误差无偏，遵循正态分布==

- “平方根”使该指标能够显示大的偏差
- 有更多样本时，使用RMSE重建误差分布被认为更可靠
- ==RMSE受异常值的影响很大==。因此，请确保在使用此指标之前已从数据集中删除了异常值。
- 与平均绝对误差相比，RMSE提供更高的权重并惩罚大错误

![image-20210316164746382](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316164746.png)



### 思考|还有没有比MSE更合理一些的指标？

由于MSE与我们的==目标变量的量纲==不一致，为了保证量纲一致性，我们需要对MSE进行开方 。





## 2.1 均方根对数误差

Root Mean Squared Error

在均方根对数误差的情况下，采用预测和实际值的对数

预测值和真值都很庞大时不希望处理预测值和实际值存在的==巨大差异==的话，通常采用RMSLE

![image-20210316173910686](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316173910.png)

- 如果预测值和实际值都很小：RMSE和RMSLE相同
- 如果预测值或实际值很大：RMSE> RMSLE
- 如果预测值和实际值都很大：RMSE> RMSLE（RMSLE几乎可以忽略不计）



### 思考|RMSE有没有不足的地方？有没有规范化（无量纲化的指标）？

上面的几种衡量标准的取值大小与具体的应用场景有关系，很难定义统一的规则来衡量模型的好坏

- 比如说利用机器学习算法预测上海的房价RMSE在2000元，我们是可以接受的
- 但是当四五线城市的房价RMSE为2000元，我们还可以接受吗？



## 2.2 MAPE

平均绝对百分比误差（Mean Absolute Percent Error, MAPE）

<img src="https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317141037.png" alt="image-20210317141037735" style="zoom:80%;" />

相比RMSE,MAPE相当于把每个点的误差进行了归一化,降低了个别离群点带来的绝对误差的影响



## 3 解释变异

![image-20210316164801165](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316164801.png)



## 4 决定系数$R^2$

注意：==增加变量时==，以下两个指标都被改善

- 决定系数：$R_i^2$
- MSE：均方差误差

![Some metrics are influenced by  Scale  feet, meters, inches, etc  Variables  Model Assum tions and T  es  Common Model  Evaluation Metrics  MSE  Mean-Squared Error  AIC  Akaike Information Criteria  BIC  Bayesian Information Criteria  Mallow's CP ](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317143731.png)





Coefficient of determination是一个无量纲化的指标

- 反映因变量的全部变异，能通过回归关系被自变量解释的比例
  - 如果结果是0，就说明模型预测不能预测因变量
  - 如果结果是1。就说明是函数关系

![image-20210316213828415](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316213828.png)

上式恒等变形：

![image-20210316213925708](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316213925.png)





已知RMSE降低时，模型的性能将会提高。但仅凭这些值并不直观

在分类问题的情况下，如果模型的准确度为0.8，可以衡量模型对随机模型的有效性，哪个准确度为0.5。

因此，随机模型可以作为基准。

但是在谈论RMSE指标时，却没有比较基准。

这里可以使用R-Squared指标。R-Squared的公式如下：

![image-20210316174053042](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316174053.png)

- MSE（模型）：预测值与实际值的平均误差
- MSE（基线）：==平均预测值==与实际值的平均误差





Coefficient of determination又被称为$R^2$分数

![image-20210316164827455](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316164827.png)

### 思考| 以上评估指标有没有缺陷，如果有，该怎样改进？

以上的评估指标是==基于误差的均值==对进行评估的，均值对异常点（outliers）较敏感，如果样本中有一些异常值出现，会对以上指标的值有较大影响，即均值是非鲁棒的。



### 解决评估指标鲁棒性问题⭐

1 剔除异常值

设定一个相对误差 ，当该值超过一定的阈值时，则认为其是一个异常点，剔除这个异常点

将异常点剔除之 后。再计算平均误差来对模型进行评价



2 使用误差的分位数来代替

如利用中位数来代替平均数。

例如 MAPE：$MAPE=median(\frac{|y_i - \hat{y}_i|}{y_i})$

MAPE是一个相对误差的中位数，当然也可以使用别的分位数。





### Adjusted R-Squared

调整后的可决系数（参考）

模型表现与baseline相同时，R-Squared为0。

模型越好，$R^2$值越高。最佳模型含所有正确预测值时，R-Squared为1。

但是，向模型添加新功能时，R-Squared值会增加或保持不变。R-Squared不会因添加了对模型无任何价值的功能而被判“处罚”。

因此，R-Squared的改进版本是经过调整的R-Squared。

调整后的R-Squared的公式如下：

![image-20210316174209434](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210316174209.png)

- k：特征数量
- n：样本数量

此指标会考虑特征的数量。

添加更多特征时，分母项n-（k +1）减小，因此整个表达式在增大。

如果R-Squared没有增大，那意味着添加的功能对模型没有价值。

因此总的来说，在1上减去一个更大的值，调整的r2，反而会减少。





# #补充|非线性回归

一般的假设是，多项式回归比简单的线性回归更能拟合数据

但是更高次（100）多项式模型严重过拟合数据

