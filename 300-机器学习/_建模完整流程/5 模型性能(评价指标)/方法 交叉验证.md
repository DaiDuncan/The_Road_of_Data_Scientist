# [Scikit-learn|交叉验证](https://scikit-learn.org/stable/modules/cross_validation.html)

交叉验证不是真正的评估指标(公开用于传达模型的准确性)

但交叉验证提供了足够直观的数据来概括模型的性能

模型变得高度复杂时，过度拟合也会开始捕捉噪音。这种“噪音”对模型没有任何价值，只会让其准确度降低。



作用：决定添加什么有效变量？

![CROSS-VALIDATION  How do we know which variables to include  ...if all of them improve the model? ](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317124807.png)

k-fold k次交叉验证



## 1 训练集与测试集

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222085213.png" alt="TEST  PRICE  $634K  $120K  $920K  $134K  $200K  $220K  $133K  TRAIN  Obtain the metric on this data  NEIGHBORHOOD  c  c  AREA  1600  3200  1200  1600  3200  1200  700  BEDROOMS  4  7  2  4  5  6  2  BATHROOMS  2  3  2  2  3  2  1  STYLE  ranch  victorian  ranch  ranch  victorian  ranch  lodge  Fit the model on this data " style="zoom: 80%;" />

不断更改训练集和测试集：交叉进行验证

- 数据集：训练数据集
- 测试集：训练数据当中的验证集





## 2 交叉验证

### 2-折

定义：试着留下一个样本集，但并不在这个样本集上训练模型，在最终确定模型之前，用建立的模型测试该样本集

- 这种方法一个消极面就是在训练模型时丢失了大量数据。因此，模型的偏差会很大。



### k-折交叉验证

示例：k=10个容器，每个容器单独做一个测试集，其余为训练集

- 一旦拥有所有这10个模型，就可以利用平均误差项找到最好的模型

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222085338.png" alt="- C?os VALiDM1DO  و4  بس با امع eم٥حهط طس  - ام يده لمة  - حسم  إرل ناديا ، لم  ر عييه انها دلف. إه ا ولنمهحوه " style="zoom:80%;" />

### 意义

k折交叉验证广泛用于检查模型是否是过度拟合

如果k次建模中的每一次的性能指标彼此接近，那么指标的均值最高

在Kaggle比赛中，你可能更多地依赖交叉验证分数而不是Kaggle公共分数。这样就能确保公共分数不单单是偶然出现。





### 实践|如何选择k？

对于小k，有更高的选择偏差但性能差异很小。

对于大k，有小的选择偏差但性能差异很大。



想想极端情况：

k = 2：只有2个样本，类似于50-50个例子。在这里，每次仅在50％的人口中构建模型。但由于验证会有很多人，所以 验证性能的差异是最小的。

k =样本数( n )：这也称为“留一法”。有n次样本，建模重复n次，只留下一个样本集进行交叉验证。因此，选择偏差很小，但验证性能的差异非常大。



通常，针对大多数情况，建议使用k = 10的值。





在训练样本上评估模型毫无意义。留出大量的样本来验证模型也是在浪费数据

k折交叉验证为我们提供了一种使用单个数据点的方法，可以在很大程度上减少选择偏差。同时，K折交叉验证可以与任何建模技术一起使用。



## 3 对比效果：一次训练测试 VS 交叉验证

运行时间：在训练结束之后的部署运行(已经决定了学习算法)

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222085421.png" alt="img" style="zoom:80%;" />



## 4 小结

模型训练中典型的交叉验证工作流程的流程图。

最佳参数可以通过网格搜索技术确定。

- .split()只是**简单划分**了 训练集和测试集

```python
# k-fold
kf = KFold(n_splits=2)
for train, test in kf.split(iris.data):
    print("k折划分：%s %s" % (train.shape, test.shape))
    break
```

