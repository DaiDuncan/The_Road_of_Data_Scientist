

# 一、数据分布distribution不同

针对真实数据，实验数据



假设我们只能收集到8千个真实数据，但是实际需要的可能是10万个数据，那我们就写代码自己生成这10万个数据，但是这里就有一个问题，我们自己生成的数据和实际数据肯定存在一些差异



### 协变量偏移Covariate Shift

协变量是指模型的输入变量（自变量）

协变量偏移指的是训练集和测试集中的==输入变量具有不同的数据分布==。

协变量偏移意味着只有输入分布发生变化，而输入到输出的映射关系保持不变。



协变量偏移是最常见的数据偏移类型，理想情况下测试集与训练集应该有相同的数据分布

然而，在现实中，外界环境中各种因素的变化都可能导致这个假设不成立。所以几乎真实世界的每个数据集都有这个问题

<img src="https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317100242.png" alt="image-20210317100242493" style="zoom:80%;" />

学习函数试图去拟合训练数据，但是在这里，我们可以看到训练集和测试集的分布是不同的，所以使用这个学习函数进行预测肯定会给出错误预测结果



那么图像数据中的数据分布到底是什么呢？以下是我的个人理解：

- **各类别比例**：比如训练集中30%的车、40%的人和30%的树，而测试集中有10%的车、20%的人和70%的树，那么我们可以猜测训练集中的数据可能来自街景场景，而测试集中的数据可能来自公园场景。

  因为两者各类别的比例不同，所以数据分布不同。

- **图像特征**：比如训练集是我们在网上收集的非常清晰的猫狗图像，而测试集是我们自己拍的比较模糊的猫狗图像；或者训练集是白色的狗和黄色的猫的图像，而测试集是黄色的狗和白色的猫的图像

  那么它们也可以看做数据分布不同。

而我们所说的**独立同分布**就是要求训练集和测试集中==各类别的比例相近，图像特征相近==。

在训练集上学习到的规律可以直接应用于测试集。



## 方法|划分训练/验证/测试集

将两个数据集组合起来，然后随机洗牌。并将结果数据集分割成训练/验证/测试集

假设对训练/验证/测试集采用 96:2:2 的分割，这个过程将是这样的：

- 100k是生成数据集
- 8k是真实数据集

<img src="https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317100503.png" alt="image-20210317100503284" style="zoom:80%;" />



通过这种处理，训练/验证/测试集都来自相同的分布，如上图中的颜色所示，这是我们所期望的。 



然而此时存在一个问题：

在验证集中，2000张图片中平均==只有148张图片来自真实数据集==。

这意味着，在大多数情况下，我们都在根据生成数据的分布来优化网络模型(2000幅图像中有1852幅)，因此这不是一个好的方法。



另一个方法是让验证/测试集来自真实数据集，训练集来自==生成数据集==。

假设像以前一样对训练/验证/测试集使用96:2:2的划分。

- 验证/测试集将各有2000张真实图像数据
- 剩下的真实数据(4k张)和全部生成数据都为训练集

<img src="https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317100735.png" alt="image-20210317100734948" style="zoom:80%;" />

使用这种划分方式，我们可以优化网络模型，以便在测试集上的有很好的效果，因为验证集的图像仅来自真实数据集。

然而，训练集现在不同于验证/测试集。这意味着在很大程度上，我们是在生成图像上训练网络模型。因此，优化模型需要花费更多更长的时间。



更重要的是，当训练集和验证集上的损失差别较大时，我们==无法判断这是由过拟合还是数据不匹配造成的==。



---

假设训练误差为2%，验证误差为10%。鉴于这两组数据来自不同的分布，这两组数据之间8%的差异中有多少是由于数据不匹配造成的，有多少是由于模型过拟合造成的，我们并不能判断。



取出训练集的一小部分，称之为“桥集”。

桥集将不用于训练网络模型。它是一个独立的集合，划分方式如下所示：

![image-20210317101558512](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317101558.png)



### 问题|过拟合

通过这种划分方式，假设训练误差和验证误差分别为2%和10%，而桥集误差为9%，如下所示：

![image-20210317101622058](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317101622.png)



因为桥集与训练集来自相同的分布，排除了数据不匹配（数据分布）的影响，它们之间的误差相差为7%，

- 所以有7%的误差来自==方差误差（过拟合 ）==。

桥集和验证集有1%的差异，

- 所以有1%的误差来自==数据不匹配==误差。



### 问题|数据不匹配

现在假设桥集误差为3%，其余的如前所示：

![image-20210317101720403](https://raw.githubusercontent.com/DaiDuncan/PicUploader/main/img2/20210317101720.png)

根据上面的分析，训练集和桥集的误差相差为1%，所以有1%的误差来自方差误差。

桥集和验证集有7%的差异，所以有7%的误差来自数据不匹配误差。





## 小结

1 ==减少方差误差==是机器学习中的一项常见任务。例如可以使用各种正则化方法。

2 对于数据不匹配误差，我们可以==想办法收集更多的真实数据==，并加入到训练集中参与模型训练，或者尽可能地生成和真实数据非常相似的数据加入到训练集中。







# 二、数据分类不均衡

针对数据的分类情况





# 三、线下评估 VS 线上测试