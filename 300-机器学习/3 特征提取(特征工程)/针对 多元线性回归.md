```python
import sklearn.preprocessing as p
```

# 特征工程

- 处理缺失值
- 尺度变化：导致回归系数无法解释——>所以不热衷于回归模型
  - log, exp
  - 标准化
  - 平方
- ==编码==
  - 虚拟变量

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222083039.png" alt="Feature Engineering  Techniques  Handling missing values  Scaling values  Changing text and images  to numeric values  Creating dummy variables " style="zoom:50%;" />



特征工程预处理改善预测，但是解释性降低



## 处理缺失值

```python
import numpy as np
import pandas as pd
import statsmodels.api as sm;
import sklearn.preprocessing as p

df = pd.DataFrame({'response': [2.4, 3.3, -4.2, 5.6, 1.5, 8.7], 
                         'x1': ['yes','no','yes','maybe','no','yes'],
                         'x2': [-1,-3,np.nan, 0, np.nan, 1],
                         'x3': [2.4, 15, 3.3, 2.4, 1.8, 0.4],
                         'x4': [np.nan, np.nan, 1, 1, 1, 1],

                         'x5': ['A', 'B', np.nan, 'A', 'A', 'A']})
```

![2  3  4  5  response  1.0  1.0  1.0  1.0  2.4  3.3  _4_2  6.6  8.7  xl  yes  no  yes  maybe  no  yes  -3.0  NaN  0.0  NaN  1.0  x3  2.4  16.0  3.3  2.4  1.8  0.4  x4  NaN  NaN  x5  NaN ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222084127.png)

数据集行数肯定要比待预测变量多，不过有 nan 值在的话，就没有足够的数据来预测模型系数了。



### 1 均值填充

```python
df_mean = df.fillna(df.mean())
df_mean['intercept'] = 1

mod = sm.OLS(df_mean['response'], df_mean[['x2', 'x3', 'x4', 'intercept']])
res = mod.fit()
print(res.summary())
```

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222084344.png" alt="image-20210222084344377"  />



### 2 (均值填充后)标准化

p.scale表示标准化

```python
df_stand = df_mean.copy()
df_stand[['x2', 'x2', 'x4']] = p.scale(df_stand[['x2', 'x2', 'x4']])
df_stand
```

![image-20210222084521827](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222084521.png)

```python
mod = sm.OLS(df_stand['response'], df_stand[['x2', 'x3', 'x4', 'intercept']])
res = mod.fit()
print(res.summary())
```

![image-20210222084608879](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222084609.png)







# 选择特征

选择自变量中相关性强的特征

方法：

- 统计显著性(p值)
- VIFs
- 交叉验证
- 正则化

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222082559.png" alt="Feature Selection  Techniques  P-VALUES  VlFs  CROSS VALIDATION  REGULARIZATION " style="zoom:50%;" />



