# 理论思想

在统计推断中, 假设检验的任务是**用样本信息检验**关于**总体参数**的可检验假设。

假设检验的所有方法都基于这样一个逻辑: 总体参数的**任何具体估计值**都来自**估计量的抽样分布**, 这个估计值仅仅是**诸多可能估计值中的一个**。



20 世纪30 年代英国杰出统计学家费歇尔提出的显著性检验是假设检验的经典方法, 其**目的在于检验是否出现了小概率事件**,指出“效应的发生并非偶然”的证据

以回归分析为例, 大多数研究者都用显著性检验确定某一特定变量是否对因变量有作用。其具体做法是: 假定某一个或某一组**回归系数的真值为0,** 然后再确定系数为0的偶然事件的发生概率p 值, 如果这一概率p 值小于显著性水平( 一般为1%、5% 或10% ) , 我们就拒绝原假设, 认为这一系数是起作用的。

我们将这种通过统计推断得出来的显著性称为”统计显著性”。



无论你从事何种领域的**科学研究**还是**统计调查**，显著性检验作为判断两个乃至多个数据集之间==是否存在差异==的方法被广泛应用于各个科研领域。



## 本质

**全称命题不能被证明**，只能被否定

XX都是……——>无法验证全部样本

| 例子-全称命题 | “人都是两条腿的”                                             |
| ------------- | ------------------------------------------------------------ |
| 假设          | 存在不是两条腿的人——>全称命题只能被否定                      |
|               | @数据支持假设——>否定命题                                     |
|               | @数据不支持假设——>保留命题，而非支持  **找不到**不是两条腿的人 ！=都是两条腿  理解：样本有限 |
|               |                                                              |
| #p值          | 拒绝原假设——>“这是错误”的概率                                |
| 例子          | H0：马蓉没有出轨，α=0.05                                     |
|               | p>α：不能否定H0                                              |
|               | p<α：小概率事件发生——>否定H0  (在H0的假设前提下：小概率事件发生) |

不希望否证自己的研究假设——>设定相反的虚无假设H0

- 否定H0——>相当于证明自己的研究假设

基于抽样的前提：不可能绝对否证

个案中的小概率事件 == 不可能事件：按事先约定的概率水平(α：显著性水平)去拒绝H0





## 显著性检验|针对第一类错误

所谓统计假设检验就是**事先对总体（随机变量）的参数或总体分布形式做出一个假设**，然后**利用样本信息**来判断这个假设是否合理。

而把==只限定第一类错误概率的统计假设检验==就称之为显著性检验。



1 为什么要做显著性检验？

因为我们想要判断样本与我们对总体所做的假设之间的差异是纯属**机会变异**(偶然)，还是由我们所做的假设与总体真实情况之间不一致所引起的。 



2 怎么做显著性检验？

显著性检验可以分为参数检验和非参数检验。

- 参数检验要求样本来源于正态**总体**（服从正态分布），且这些正态总体**拥有相同的方差**，在这样的基本假定（==正态性假定和方差齐性假定==）下**检验各总体均值是否相等**，属于参数检验。

- 当数据不满足正态性和方差齐性假定时，参数检验可能会给出错误的答案，此时应采用**基于秩**的非参数检验。







基本思想("显著性"地拒绝对总体分布的H0)：

- 小概率原理：小概率事件在一次试验中是几乎不可能发生的，假若在一次试验中事件 事实上发生了。那只能认为事件 不是来自我们假设的总体，也就是认为我们对总体所做的假设不正确



显著性检验的结果：

- 不能评价差异的大小和重要性
- 不能回答差异产生的原因
- 不能检查我们对实验所作的设计是否有缺陷



显著性检验中的总体和样本：

1、显著性检验的对象是无限总体。

2、==大样本可能会使检验统计量过分敏感==。

3、从有限总体中抽取样本用于显著性检验时，必须作**概率抽样**。



## 参数检验

方差分析(基于matlab)：比较均值(@下文：常用的显著性检验)

1）单因素一元方差分析  <br />		2）双因素一元方差分析  <br />		3）多因素一元方差分析  <br />		4）单因素多元方差分析    



机器学习中的“标签个数” @因素(自变量)：影响未知变量的行为（事件）称之为“因素”    

机器学习中的“**特征**个数” @元(特征 自变量)：待检验的未知变量的个数(一元二次方程)  

| 1）单因素一元方差分析                               | 函数一：anova1( X, Group,  displayopt)                       |
| --------------------------------------------------- | ------------------------------------------------------------ |
|                                                     | 在第一种用法中，X是一个n行1列的数组，Group也是一个n行1列的数组。<br />X为待检验的样本集，这个样本集中包括若干个对照组和实验组的全部数据。<br />那么机器怎么知道哪个数据属于哪个组呢？很简单，通过Group这个列向量一一对应指明即可。 |
| @例子  因素：**同等地位**的标签/分组  元：数值/分数 | 假定现在有**三组数据**  <br />组一（st）：82  86 79 83 84 85 86 87  <br />组二（al1）：74  82 78 75 76 77  <br />组三（al2）：79  79 77 78 82 79     <br /><br />现在需要对这三组数据做方差检验，使用anova1函数的方法如下  <br />1.首先将**所有的数据**放在同一个数组strength中：  <br />>>  strength = [82 86 79 83 84 85 86 87 74 82 78 75 76 77 79 79 77 78 82 79];  <br /><br />2.设置对应与strength**对应位置的标签为alloy**：  <br />>>  alloy =  {'st','st','st','st','st','st','st','st','al1','al1','al1','al1','al1','al1','al2','al2','al2','al2','al2','al2'};  <br /><br />3.调用anova1函数  <br />>> p  = anova1(strength,alloy)     <br />p = 1.5264e-004  <br />显然，从p值看，三组值之间存在显著性差异。<br /> |
|                                                     | 有一点必须提一下：这里p存在显著性差异并不意味着三组之间两两都存在显著性差异，而只是说明显著性差异在这三组之间存在。 |
| ANOVA表                                             | ![sourc.  Groups  Error  total  SS  134. s  102  us  92. 4  ANOVA Table  o. 0002  2  19 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221094540.png) |
|                                                     | Source表示方差来源（谁的方差），这里的方差来源包括Groups（组间），Error（组内），Total（总计）；<br /><br />SS（Sum of squares）表示平方和<br />df（Degree of freedom）表示自由度df（Degree of freedom）表示自由度<br />MS（Mean squares）表示均方差<br /><br />F表示F值（F统计量），F值等于**组间均方**和**组内均方**的**比值**，它反映的是**随机误差作用的大小**。<br />Prob>F表示p值 |
|                                                     | F值在本例中等于15.4，它正是组间方差92.4和组内方差6的比值<br />查F分布表：<br />![image-20210221094752136](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221094752.png) |
|                                                     | 根据 n=19( Total 的df)，m=2（Groups的df） (m=组数-1，n=样本数-1)<br />  可得$F_{0.05}(m, n-m-1)=F_{0.05}(2, 16)=3.634$<br />  实际值15.4大于表格数据，所以可以判定显著性差异存在，此时p值<0.05 |
| 补充\|数据的分布 箱型图                             | ![0  0  样 本 上 界  上 1 罔 分 位 线  中 位 线  下 1 ' 4 分 位 线  样 本 下 界  st ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221095005.png) |
| 补充\|调用anova1                                    | 这里有必要提一下anova1函数中的参数displayopt 的作用。<br />在大规模的anova1调用中（例如把anova1放在for循环中反复调用），需要把displayopt设置为'off'，否则anova1**每调用一次就会绘制两幅图**，这样会迅速的耗费计算机的内存，容易造成程序崩溃。 |
| 补充\|均衡方差分析                                  | 除了上文中介绍的第一种调用anova1的方式，还有一种方式用于**均衡**的方差分析。 |
|                                                     | 所谓均衡就是要求**不同的组别内的统计数据个数必须相同**。<br />在上例中出现的各个组的统计个数分别为{8,6,6}就属于非均衡。<br />在均衡状态下，每个组的数据单独构成X中的一列，这样便可以省略参数Group，调用方式就可以简化为anova1(X) |
|                                                     | ==方差分析必须满足两条假设，分别是正态性假定和方差齐性假定==。<br />因此，在一个完整的统计工程中，必须首先检测数据的正态性假定和方差齐性假定，这就涉及到另外两个函数：<br />  lillietest**正态检验函数**（这正是我们上文提到的分布假设检验而不是参数检验，它检验的目标是数据集服从何种分布）<br />  vartestn方**差齐性检验**（这正是我们上文提到的参数检验而不是分布假设检验 ，它检测的目标是数据集的分布服从什么样的参数，这里就是**方差**） |
| 分布检验：是否服从正态分布                          | lillietest(X)<br />\>> [h,p] = lillietest (strength(1:8))<br />h = 0<br />p = 0.5000 |
|                                                     | 解释：<br />h = 0可以认为数据服从正态分布，h=1则认为不服从正态分布<br />p >0.05可以认为**接受**原假设h = 0，则数据服从正态分布 |
|                                                     | 第二组数据：[h,p] = lillietest (strength(9:14))<br />第三组数据：[h,p] = lillietest (strength(15:20)) |
| 参数检验：方差是否相等                              | vartestn(X, Group)<br /><br />\>> p = vartestn(strength,alloy,'off')<br />p=0.5142 |
|                                                     | 注意：X和Group必须是列向量，否则会报错<br />p>0.05则说明X中的不同Group是齐次的，也就是方差性齐。 |



| 2）**双因素**一元方差分析                           | 多个标签                                                     |
| --------------------------------------------------- | ------------------------------------------------------------ |
| 双因素 => 二联表                                    | 双因素一元方差分析要求数据是均衡的，所以它的标签可以省略     |
| @例子<br />因素：品牌，制作工艺<br />元：质量的评分 | 有一批爆米花数据，现在我们知道这些爆米花的质量打分同两个因素相关<br />一个是爆米花的品牌（有三个品牌：Gourmet，National，Generic）<br />另一个是爆米花的制作工艺（油炸，气压）。这些数据如下所述：<br />![brand  methods  Gourmet  5.5000  5.5000  6.0000  6.5000  7 .oooo  7 .oooo  National  4.0000  5.0000  5.5000  5.0000  Generic  3.5000  4.0000  3.0000  4.0000  5.0000 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221095743.png) |
|                                                     | 目标有三个：<br />第一：**列和列**之间是否有显著性差异（**品牌间**的显著性差异），**原假设**是显著性差异不存在；<br />第二：**行与行**之间是否存在显著性差异，**原假设**是显著性差异不存在 ；<br />第三：**品牌和方法之间**的交互作用是否明显，原假设是交互作用不明显 |
| p = anova2( X, **reps**, displayopt)                | X即为待检验数组。其中，X的每列代表一种因素，X的每**若干行**代表另一种因素，这里的若干使用reps指明 |
|                                                     | ![o.oooo  Source  Col unns  Int •r•c ion  > > popcorn =[  5.oooo 40000  5.5000 50000  [p,table,stats] = anova2(popcorn,3)  15. 75  5.5000  5.5000  6.oooo  6.5000  7 .oooo  7 .oooo  3.5000  3.oooo  4,0000  5.oooo  0.0001  o. 0833  1. 6667  0.7462  ANOVA Table  2  2  12  7. 875  o. 04187  O. 13îî9  32. 4  Prob  0. 0001  o. 7462 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221095828.png) |
|                                                     | 解释：<br />p(1) = 0.0000, **推翻原假设**，所以列与列之间的显著性差异存在（品牌间存在显著性差异）；<br />p(2) = 0.0001,**推翻原假设**，所以行与行之间的显著性差异存在（方法间的显著性差异存在）；<br />p(3) = 0.7462，保留原假设，则品牌和方法间的交互作用不明显。 |



| 3）多因素**一元**方差分析                                    |                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| p = anovan(X, Group, Opt);                                   | X代表着待检验数据；<br/>	Group代表着X的因素，由于是多因素，所以Group是多个列组成的。<br/>	Opt可以选择为'model'，<br/>	model后面可以填写'full'和'interaction'。<br/>比如因素有三个x，y，z，那么如果model为interaction，计算结果会包括x的显著性，y的显著性，z的显著性，xy，xz，yz的交互影响显著性<br/><br/>如果model为full，计算结果会包括x的显著性，y的显著性，z的显著性，xy，xz，yz的交互影响显著性以及xyz的交互显著性。 |
| @例子<br/>	因素：3个不同类别的标签<br/><br/>元：y中的数值 | y是待检验的数据，<br/>g1,g2,g3是与y中数据一一对应的3个因素（数据标签）<br />![y = [52.7 57.5 45.9 44.5 53.0 57.0 45.9 44.0]';  gl = [1 212121 2];  {'may';'may';'may';'may';'june';'june';'june';'june'};  > > p anovan(y,{gl g2  0.0347  0.0048  0.2578  0.0158  O. 1444  0.5000  Sourc  XI*X2  x: 8x3  Tot AI  sun  Analysis of Variance  Prob)F  33€. II  199. ou  16.  221. 379  o. 211  o. 011  o. 011  199.  o. 211  o. 011  5. 44  o. 0347  O. 257î  O. 1444 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221100112.png) |
| 补充\|小窍门                                                 | 如果你想做**非平衡**双因素一元方差分析，那么也可以采用多因素一元方差分析函数。 |

| 4）单因素多元方差分析                                        |                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| [d, p] = manova1(X, Group);<br/>	p，X和Group与之前相同    | 该方差分析的==原假设==是“各组的组均值是相同的多元向量”<br/>这里对d做出解释：<br/>	d=0，接受原假设<br/>	d=1，拒绝原假设，认为各组的组均值不完全相同，但是不能拒绝它们共线的假设。<br/>    d=2，拒绝原假设，各组的组均值向量可能共面，但是不共线。 |
| @例子<br/>	单因素：同一种类别的标签<br/><br/>多元：4种商品 | 四种商品（x1,x2,x3,x4）按照不同的两种销售方式进行销售，数据如下：<br />![疇三 xl  x2  60  80  51  51  65  33  34  63  69  78  63  54  51  338  233  260  429  403  480  468  416  377  299  390  416  507  x3  338  233  260  429  403  480  468  416  377  299  390  416  507  210  330  203  150  205  260  295  265  260  360  320  310  320  x4 톤肖售疔式  2  3  4  5  6  7  8  9  10  11  12  13  125  119  63  65  130  65  100  65  110  88  73  103  64  210  330  203  150  205  260  295  265  260  360  320  310  320  2  2  2  2  2  2  2  >> X  125  119  63  65  130  65  100  65  110  88  73  103  64  60  80  51  51  65  33  34  63  69  78  63  54  51 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221100351.png) |
|                                                              | ![> > Groups —  manoval()(, Groups); ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221100407.png) |
|                                                              | d =0<br/>p =0.0695<br/>因此，接受原假设，各组的组均值是相同的多元向量。 |

参数检验的四种函数分为anova1，anova2，anovan，manova1。

他们都基于共同的两个假设：正态性假定和方差齐性假定 ，分别对应着函数lillietest 和vartestn。



检验的目标：该参数是否存在显著差异





## 非参数检验

在实际工作中，不可能总是遇到满足这两个假定的统计数据，这时候，如果强行采用参数检验就会造成错误。此时，可以采用基于秩和的非参数检验。(检验时是以等级（Rank）为主要统计量)

- 缺陷：检验力较弱，处理方式无一致性



非参数检验主要涉及五个方面，即单样本、两独立样本、两配对样本、多独立样本、多配对样本的非参数检验。

### 1 Kruskal-Wallis检验

又被称之为**单因素**非参数方差分析，是非参数版的anova1。

该检验的原假设是：**k个独立样本**来自于相同的正态总体。



p = kruskalwallis(X,Group)

- X,Group,p和参数检验里的完全相同。





### 2 Friedman检验

又被称之为**双因素**秩方差分析，是非参数版的anova2。

同anova2一样，待检验的数据也**必须是均衡**的。



但是需要特别注意的是，Friedman检验和anova2检验不完全相同

- anova2同时注意两个因素对待检验数据的影响
- 但是，Friedman检验只注重2个因素中的其中一个对待检验数据的影响，而**另一个因素则是用来区分区组用的**。

![Х111  Х121  Х112  Х122  1211  х•221  Х222  хд11  ХД21  вез  1312  Х322 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221100553.png)



如上图所示矩阵X，Friedman检验只关注X的各个列（因素A）水平之间有无显著差异，他对各行之间（因素B，也被称之为区组因素）完全不感兴趣。

因此，Friedman检验的原假设是k个独立样本（X的各列）来自于相同的正态总体。



至于为何Friedman检验对因素B不感兴趣，这里通过一个例子说明@《MATLAB统计分析与应用40个案例分析》

有4名美食评委1234对来自于**四个地区ABCD的名厨**的名菜水煮鱼做出评价打分，数据如下：

![t也凶  美食i平委  2  3  4  A  85  87  90  80  8  82  75  81  75  C  82  86  80  81  0  79  82  76  75 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221100619.png)

现在我们想知道，这四个地方的**水煮鱼品质是否相同**。(各个列：因素A) =>对因素B(行与行之间)不感兴趣

![85  87  90  80  82  75  81  75  82  86  80  81  79  82  76  75  p = friedman(X,1)  p = 0.0434 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221100628.png)

因此可以认为，四个地区制作水煮鱼的水平有显著性差别。

至于是**哪两个之间**有显著性差别还需要一一比较。







# 参数估计与假设检验

![image-20210220211021972](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210220211022.png)

## 常用的显著性检验

假设检验中建立传统置信区间的方法：

1 单样本T-Test：针对总体均值

2 双样本T-Test：比较两个均值

3 成对 T-Test：将个体与自己比较

4 Z-Test

5 卡方检验

6 F检验

| 检验类型                      |                                                              |
| ----------------------------- | ------------------------------------------------------------ |
| F检验                         | 要求误差呈正态分布且各组方差整齐                             |
| t检验                         | 适用于**计量资料**、正态分布、方差具有齐性的==两组间**小样本**比较==。<br />包括配对资料间、样本与均数间、两样本均数间比较三种，三者的计算公式不能混淆 |
|                               | 单样本T检验                                                  |
|                               | 两独立样本T检验                                              |
|                               | 两配对样本T检验                                              |
| t'检验                        | 应用条件与t检验大致相同<br />用于两组间**方差不齐时**，t′检验的计算公式实际上是==方差不齐时==t检验的校正公式 |
| U检验                         | 应用条件与t检验基本一致，只是当==大样本时用U检验==，而小样本时则用t检验，t检验可以代替U检验 |
| ==方差分析==ANOVA             | 用于正态分布、方差齐性的==多组间计量比较==。<br />常见的有单因素分组的多样本均数比较及双因素分组的多样本均数的比较<br />方差分析首先是比较**各组间总的差异**，如总差异有显著性，**再进行组间的两两比较**，组间比较用q检验或LST检验等 |
|                               |                                                              |
| $\chi^2$检验                  | **计数资料**主要的显著性检验方法。<br />用于两个或多个百分比(率)的比较。<br />常见以下几种情况：四格表资料、配对资料、多于2行*2列资料及组内分组$\chi^2$检验 |
| 零反应检验                    | 用于**计数资料**。<br />是当实验组或对照组中出现概率为0或100％时，$\chi^2$检验的一种特殊形式。<br />属于直接概率计算法 |
| 符号检验、秩和检验和Ridit检验 | 三者均属非参数统计方法，共同特点是简便、快捷、实用。<br />可用于各种非正态分布的资料、未知分布资料及半定量资料的分析。<br />其主要缺点是容易**丢失数据中包含的信息**。 |
| Hotelling检验                 | 用于计量资料、正态分布、两组间多项指标的综合差异显著性检验   |

不同的检验方法，比较的统计量是不同的。

- T检验等检验方法都是比较的**均值**；

- 卡方检验、K-S检验等**比较频数**；

- 曼－惠特尼U检验等是对秩进行比较；

- 符号检验法比较的是前后变化差值的符号
- 而符号秩检验法则是对差值及符号一同比较的检验。









## 假设检验的基本步骤及其要点

![image-20210220211229474](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210220211229.png)



### 显著性水平：小概率准则

### 原假设与备用假设⭐

- H0一般是需要反驳的，而H1是需要支持的

- |      |                                                              |
  | ---- | ------------------------------------------------------------ |
  | @H0  | 基于数据的直觉判断                                           |
  | @H1  | 仅作为H0的备择假设  +与p值计算的**不等号方向**相符合：<br />  本质上，p值就是要拒绝H0的一种试探指标，从而接受H1的概率 |

#### 区分概念⭐

@贝叶斯概率

- 事实(参数)/disease  VS  检测(观测)/test

- 原因(cause)  VS  结果(effect)

  

@贝叶斯法则：

- **先验**概率 P(disease)
- 条件概率 P(test | **disease**) @检测(敏感度：检测存在偏差)
- 似然概率 P(**test** | disease)
- 目标：后验概率 P(disease | test)



@检测：真-假；阳性-阴性

敏感度Sensitivity disease——>检测阳性 

- 带有敏感度，但并非100%确定

特异度Specitivity not disease——>阴性



小结|所以：阳性表示有病

---



P(predict|actual) => P(predict|result)

- 基本印象：无罪推定 => H0是无罪
  - 基于这个印象：来理解两种错误类型
    - 误判$\alpha$
    - 漏判$\beta$
- 医学上：==有病推定==

- (真/假)阳性：实际上是H0正确(没有罪，有病)
  - 假阳性 => 对于罪来说是误判$\alpha$(无罪，却**被推断为有罪**)，对于病来说是漏判(有病，却**诊断为无病**)
  - 但两者的后果都是最严重的
- (真/假)阴性：实际上是H1正确(有罪，没有病)
  - 假阴性 => 对于罪漏判$\beta$(有罪，却被推断为无罪)，对于病来说是错诊(无病，却**诊断为有病**)
  - 还有机会“防范”





### 错误类型

- Type I|误判 $\alpha$ ：事实无罪，被判为有罪(拒绝H0，选择H1) => H0实际上正确
- Type II|漏判$\beta$：事实有罪，被定为无罪(接受H0) => H1实际上正确

![image-20210221132026812](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221132027.png)

无罪推定：H0无罪，要证明H1有罪

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210117210703.png" style="zoom:80%;" />



### p值：根据H1的范围不同进行分类

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210117210941.png" style="zoom:80%;" />



### 双尾检验与单尾检验

#### T检验与U检验：样本观测值均符合正态分布的前提下

- 当样本容量n够大，可采用U检验
- 当样本容量n较小，采用T型检验









## 如何应用？

### 1 首先，了解各检验方法的适用范围及其特点。

1）对==总体==有特殊的要求

2）不同的检验方法，==比较的统计量==是不同的



### 2 认清研究目的

研究目的是市场调研中一切实务的根本出发点

==研究目的需要细化==，具体到要通过哪些数据、得到什么信息、何种结果的问题，如希望通过对消费者**购买哪些品牌的数据**来得出市场占有率的信息。



### 3 分析数据特点

1）弄清楚要分析的数据属于什么类型，是连续型，还是非连续型？

对于连续型数值，均值具有实际意义

对于非连续性的数值，均值并不具备实际意义，而是**频数，百分比**才有意义，所以，数据属于连续型时，适用比较均值的显著性检验，若是非连续型的级数类，则适用比较频数、比例的检验方法；

2）数据也是可以跟据不同情况，灵活处理

如对于满意度的衡量，我们可以根据不同的需求**看为连续型分值**，也可以看为几个等级的级数

3）还需要了解样本数据的分布特点，弄清楚样本数据是否服从某一分布

==分布明确：参数检验==

==分布不明确：非参数检验==

4）判断要检验差异的两组样本的关系

属于独立样本，还是属于**配对**样本@符号检验

独立样本即指在一个总体中随机抽样对在另一个总体中随机抽样没有影响的情况下所获得的样本，样本之间相互独立；

配对样本可以是同一个体在前后两种状态下某种属性的两种状态，也可以是对某事物两个不同侧面或方面的描述，两样本不是相互独立，而是有相关性的。



### 4 灵活运用检验方法

检验方法虽然有各自特点和适用范围，但是可以对数据做稍微的处理、变化，或是换个角度分析，便可运用不同的检验方法@me-试探

 

比如：

- 独立样本T检验法判断AB产品对于抗过敏的功效评价在均值上是否有差异
- 而卡方检验可判断他们在各评价水平上的分布有无差异，假如判断出他们功效水平无差异之后，我们还想知道他们到底是同样的好还是同样的差，
  - 这时可以再使用单样本 T 检验对以与均值评价水平相近的满意度水平进行差异性检验来进行定位。

此外，我们还需要合理解释检验结果。





# 实际显著性 VS 统计显著性⭐

显著性的含义是指两个群体的态度之间的任何差异是**由于系统因素**而不是偶然因素的影响

统计上的显著性通常用p来衡量，而实际上的显著性含义不是很清楚，



注意：由于“显著”这个词的日常意义的干扰，统计上的显著性不是一个好术语。应该换种表达方式，比如采用“==有统计上的意义==”这种比较中性的表达方式。





## 1 统计显著性 p值

基于置信区间，假设检验的数据

+更大的样本容量——>更可能具有统计显著性

p的含义是在零假设H0成立的条件下，得到**比实际测量所得的数据**==更加极端==的数据（D）的概率，也就是p（D | H0）

- 比如：硬币抛10次，有8次是正面(样本)，9、10次是正面的情况(更极端)





举例而言，如果我们要检验假设“北京的雾霾比上海的雾霾严重”，那么我们会收集北京和上海在同一个时间段内的有对比意义的区域的雾霾严重程度。

简便起见，就以PM2.5的量为衡量雾霾的指标，那么我们收集的就是北京和上海的空气中PM2.5的含量，假设结果显示北京和上海的PM2.5相差200微克每立方米。

用独立t检验可以得到一个p，就假设是p = 0.04吧。

通常一个小于0.05的p就会让我们认为：北京和上海空气中PM2.5的含量是有显著差异的。

这个显著差异的意思是：**如果北京和上海的PM2.5含量是相同的**，那么测出来北京和上海的PM2.5的**差异大于200微克每立方米的概率是0.04**。0.04看上去不像是个不同可能发生的事，所以北京和上海的PM2.5含量应该是不同的**吧**。

要注意的是，p = 0.04不意味着看到收集的数据的结果后，北京和上海的PM2.5含量相同的概率（p（H0 | D））是0.04，p（H0 | D）要通过贝叶斯公式计算才知道是多少。

事实上，我们最想知道的答案（其实也是我们以为通过p我们知道了的答案）是==零假设正确与否==的概率，也就是p（H0 | D），而p给我们的确实另一个完全不同的东西p（D | H0）。







## 2 实际显著性

==统计上的效应量（effect size）==可以在一定程度上衡量实际上的显著性。

效应量的定义其实不是很清楚（因为有很多不同的指标，所以定义也不严格统一），大概指的是==自变量和因变量相关的程度==

- 在t检验中，最常用的是Jacob Cohen提出来的d
  d的计算公式是：d = （M1 - M0 ）/ s，其中M1、M0代表两个实验组的均值，s指的是联合标准差。

  从这个公式中看出来，d 和 t之间的差异就是t受到样本量的影响，但是==d的公式中是没有样本量n==的，而p是由t和自由度决定的，所以d和p之间的**差异也就在样本量n上**。

- +其它衡量效应量的指标，比如方差分析中的$η^2$，相关分析中的 r 等等
  这些指标不一定符合“实际上的显著性”，因为它们说到底也就是一些统计量而已，**不能完全刻画**现实生活中人们认为的显著

  因为它们说到底也就是一些统计量而已，不能完全刻画现实生活中人们认为的显著，不过至少比p是高到不知道哪里去了。



p的缺陷：理论上，只要钱多随便花，可以得到**足够大的样本**==**取平均**，那么p肯定可以做到小于0.05，不管d有多么小







## 3 统计意义并不意味着实际意义

即使样本平均数和总体平均数存在微小的差异，==在样本容量很大时：也非常显著==

统计意义：样本容量越大，==统计意义变得越不相干==



统计显著性与实际显著性⭐

- 1）没有决定性关系
- 2）样本容量大：没有统计意义
  - ![image-20210220221253292](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210220221253.png)
- 3）但是样本容量太小：假设分布很可能不成立(没有足够的数据支撑**零假设分布**)









# 区分|假设检验/置信区间 VS 机器学习

注意：大样本容量不适合假设检验

| 统计学   | 注重理解变量之间的关系：运行机制         |
| -------- | ---------------------------------------- |
| 机器学习 | 注重预测结果的准确性，而不是输入的正确性 |

## 机器学习：学习+预测

机器学习采用个别方法得出结论，因为通过每个单独数据点预测结果——预测：某人是否喝咖啡

机器学习两种最基础的方法：线性 回归和 逻辑 回归





可复现性问题：

- 模型的学习误差收敛速率与样本量正比，样本量越大，模型收敛速度越快。

| 特点  |                                                              |
| ----- | ------------------------------------------------------------ |
| @肯定 | 在样本量足够大的情况下，样本其实与分布的差异已经默认足够小了，于是我们单纯靠样本数据就可以学习到可以很好模拟分布的模型。<br />到这里，假设检验**也就没有必要**。 |
|       | 如果有一个机器学习面临的任务，他的样本量不够大，或test data 与 train data分布可能有差别时，也许人们可以参考使用一些类似假设检验的思想或方法来提高模型的健壮性。<br />当然这一点在**机器学习的迁移学习**领域也是一个很热门的话题。 |
|       | 交叉验证                                                     |
| @否定 | ml用了假设检验，大多数paper就跪了啊  <br />模型训练：**特殊**的条件——>**假**阳性  <br />   数据集及划分，初始化，网络结构…… |
|       | 评价这个领域是”科学精神的倒退“。  大家把这行叫做**炼丹**，我们又回到了培根之前的时代 |
|       | 有效果，但用于学术研究的话，往往人们无法信任纯粹的对比和变量重要性排序 |



机器学习中主要涉及了两种假设检验：

1）针对**特定**数据集上的**特定**模型（如逻辑回归），分析不同变量的显著性

2）在多个数据集上**对比**多个分类器的性能，分析不同模型表现的差异



@针对假设检验1）特定性

在社科类文章中的数据分析（如回归）是工具，目的是**从**数据中归纳结论。

而在计算机领域，目的是设计新的模型，而不是分析数据，一般不会专门对实验数据下结论。

换句话说：社科类研究中数据分析是工具，而机器**学习的目的往往是模型**而不是数据本身。

在机器学习中，一个变量是否重要，往往是通过“特征选择”和“特征重要性排序”来体现的。

- 比如大部分决策树模型和集成树模型都可以提供一个变量重要性排序，可以等同视为统计检验。从实际效果上看，往往更好。

 



@针对假设检验2）对比优劣

机器学习领域，越来越多的论文要求提供统计检验







## 假设检验：解释+推断

**大样本容量**不适合假设检验

- 样本容量很大时，假设检验会产生 统计意义 最小的发现。然而，这些发现可能根本不具有现实意义。



比如，医学：小样本

举个例子，医学上每一个采样，可能都来源于病人（比如癌症病人）。那么每一个sample可能就价值5000刀以上，binary data给你50个samples



生物、医学问题往往感兴趣的是某个predictor和response是否**有关**

|           |                                                              |
| --------- | ------------------------------------------------------------ |
| @使用情境 | 统计学用假设检验是：在样本量足够少的前提下，为了推断出置信度足够高的总体分布。 |
| @肯定     |                                                              |
| @否定     | 即使数据全是由噪音构成，在适当的处理后，也能发现数据中显著的相关性：<br />  6个特征显著且对回归所做的F-test的p值远小于0.05，即回归存在统计学意义。 |
|           | 广义线性模型的数据挖掘能力有限，对于**复杂的非线性数据**可能无法很好的拟合。  <br />——>但具备好的解释性，机器学习模型却是黑箱 |



置信区间 (和假设检验) ：帮助推断总体，理解总体的参数

 置信区间采用综合方法，基于数据得出结论，因为这些测试旨在理解总体的参数 (即总体数值的集合)

- 不能利用置信区间讨论**个人用户**。置信区间针对总体的集合 ，如比例或平均数。

- 具体表述：这种药物可以针对**特定群体中的成员**降低发病率，**可信度**一般为95%



==偏向于选择置信区间==

现状(统计学领域)：假设检验的解读引起误差——>偏向于选择置信区间，效应值，机器学习技术

 



## 两者结合

统计学更严谨，机器学习更有效

随着做数据分析的人越来越多，得到的谬误结论也越来越多，下结论前要小心小心再小心。

说到底，数据驱动不代表要尽信数据分析的结果，**正确的使用分析方法**才能得到有意义的结论。





问题|在机器学习模型上做统计检验？

在传统机器学习领域，尤其是大量使用UCI上数据集的研究（如很多无监督学习），其实是可以做统计检验的，因为==数据集都不大且数量众多==。

![- (paired) (paired t test)  - E*Wilcoxon Signed Ranks testo  Whitney U testo (independent measures)  - (repeated measure) ,  ANOVAO  - test%Nemenyi testmpost-hoco  - EJPÅ*Kruskal Wallis  %Dunn's testo ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221132738.png)

有些经济学家还是在研究==机器学习与计量的新方法==，比如Stanford的Susan Athey。

毕竟==因果推断==对一些学科来说比较重要。不仅仅是经济学，就拿题主举例的医学统计领域来说，如果能在提高预测的基础上同时又能做假设检验，何乐而不为呢？



@评论

-但是我觉得prediction并不算是完备的统计推断。

统计推断的核心还是要刻画有限样本本身带来的不确定性。好比说如果用机器学习方法做回归，对回归给出的预测能有一个**比较准的区间估计**，才能算完成了统计推断吧。Stefan Wager就有一些如何对random forest结果做推断的文章。

-我同意你的观点。但是我也没说prediction是一个完备的统计推断吧，我写的只是**等同于假设检验**而已。

 

-术业有专攻，能把实验做好就很不容易了，毕竟并不是每个实验室都能养一个专门做**统计和理论**的scientist



-很多研究都会用==随机森林==这样**有一定解释性的ML算法**来降维，深度学习在医学影像的领域也有非常好的应用前景。

 





1 工业界的应用

例如ML之后对网站的改善用A/B Testing测



# 补充|注意细节

## 样本容量

计量经济学：使用大样本做微观计量实证，是否存在潜在的问题？



在检验理论中，我们通常是控制第I类错误，而尽量减少第II类错误。

针对第II类错误，定义`power= P(not H0 | H1 is True) = 1- β`

保持其他条件不变，当**样本量增加的时候**，power会越来越高的，意味着当**备择假设为真的时候**，犯第II类错误的**可能性越来越小**。

 

换句话说，如果**参数本来就是「显著」的**，那么当样本量增加的时候，你更不会因为**运气的原因**做出不显著的结果来

在我看来，至少现在我还没想到什么原因使得「大样本」劣于「小样本」，至少从统计理论方面来看。

只不过如果做不出统计显著性，好像也没必要探讨经济显著性。而只有做出了统计显著性，才有余地讨论经济显著性（scale）。

 

@评论：

我们老师对数据的一句描述是：rubbish in，rubbish out.

数据不在庞大==**而在于精准**和没有太多的干扰因素==。但是绝对的完美无干扰数据在自然社会里当然是不存在的





## 邦弗朗尼校正

完成**多个假设检验**时，纠正I类错误阈值的方法

如果你想在 20 个假设检验中把 I 类错误率维持在 1%，邦弗朗尼 校正率应为 0.01/20 = 0.0005。你应该使用这个新比率，对比每 20 个检验的 p 值，做出决定。

 

这种校正法非常保守

如果你想在 20 个假设检验中把 I 类错误率维持在 1%，邦弗朗尼 校正率应为 0.01/20 = 0.0005。你应该使用这个新比率，对比每 20 个检验的 p 值，做出决定。

| #避免出现复合 I  类错误的其他技巧 |                                                              |
| --------------------------------- | ------------------------------------------------------------ |
| 1）图基校正                       | http://www.itl.nist.gov/div898/handbook/prc/section4/prc471.htm |
| 2）Q 值                           | http://www.nonlinear.com/support/progenesis/comet/faq/v2.0/pq-values.aspx |



@例子：将**每个个体**都视为一个单一的假设检验

![2  3  4  defendant id  22574  36637  39919  29610  38273  actual  innocent  innocent  innocent  guilty  innocent  pvalue  0294126  0417981  0.177542  001S023  0076371 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221195922.png)







# 基本案例分析

## 1 苹果重量均值

苹果重量的均值理想情况下是152g，有几个样本是149g，那么相应的p值(H0：μ≥152)

计算：$P(\bar{X} \le 149 \ | \ \mu=152)$

如果p<α(α是确定的，需要计算p)，说明小概率事件发生了(实际发生的样本 X_bar=149)：从而拒绝H0，接受H1，即μ<152







## 2 大豆籽粒品种检验分析



## 3 信用评级对企业债券市场定价影响力的判断

@控制变量：期限结构完全相同，同一个月——>比较发行的利差

|          | A1 A2  n=67 | **B1 B2**  **n=76** | C1 C2  n=58 | D1 D2  n=49 |
| -------- | ----------- | ------------------- | ----------- | ----------- |
| 债项评级 | ——          | **B2>B1**           | ——          | D1≠D2       |
| 主体评级 | ——          | **B2>B1**           | C1≠C2       | ——          |

显著性水平α=0.05

### F检验：先看方差是否齐性

![表 1 Al 、 A2 的 方 差 齐 性 检 验 （ F 检 ）  顶 目 \ 分 类  平 均  方 差  观 测 值  P(F<=f)ææ  F 尾 临 界  彐 80997  890546  4509C7  881 67  0 ．  67  66  0 ．  67  66  ． 010C68  0 ．  48 彐 8 彐 彐  50 彐 6C7 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221092532.png)

P值分别等于0．483 833  ——>样本数据组A1与A2的**方差是齐性的**，即各两组数据的方差不存在显著性差异，可以进行t检验。



### t检验：前提条件 方差齐性(基于F检验)

![表 5A1 、  A2 均 值 分 折 （ t 检 验 ）  顶 目 \ 分 类  平 均  方 差  观 测 值  汩 松 关 系 数  假 设 平 差  t Stat  t 尾 临 界  t 双 尾 临 界  彐 80997  890546  4509C7  881 67  0 ．  67  0 ．  67  0 ． 70 彐 8C8  0  66  -O ． 78982  O.  21 623  ． 668271  0 ．  4 彐 2459  ． 996564 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221092632.png)

P(单尾)分别等于0．216 23

P(双尾)分别等于0．432 459

——>样本数据组A1与A2在统计学上没有显著性差异，即各两组数据的均值在统计意义上是相等的





## 4 日用百货公司销售额

例子：赵先生开了一家日用百货公司，该公司分别在郑州和杭州开设了分公司。现在存在下列数据作为两个分公司的销售额，集合中的每一个数代表着一年中某一个月的公司销售额。

   郑州分公司Z = {23,25,26,27,23,24,22,23,25,29,30}

   杭州分公司H = {24,25,23,26,27,25,25,28,30,31,29}

现在，赵先生想要知道两个公司的销售额是否有存在明显的差异（是否存在郑州分公司销售额>杭州分公司销售额，抑或反之），以便对接下来公司的战略业务调整做出规划。下属们知道赵老板的难处，纷纷建议“只需要求平均值就知道哪个分公司的销售额更大了”。但是作为拥有高学历的赵先生懂得这样一件哲学即“我们生活在概率的世界之中”。

赵先生最终决定，使用方差验检查这两个数据。

方差检验的**p 值= 0.2027**，那也就意味着，虽然杭州分公司的年平均销售额26.63大于郑州分公司的销售额25.18，但是实质上，两个分公司的销售额并没有明显的差异。



在上例中，我们的假设就是一种显著性检验。因为方差检验不适用于估计参数和估计总体分布，而是用于检验试验的两个组间**是否有差异**。

而==方差检验==正是用于检测我们所关心的是这两个集合（两个分布）的均值是否存在差异。







# #参考文献

德语公式

| 【概率】                |                                                              |
| ----------------------- | ------------------------------------------------------------ |
| 排列组合                | 有放回  无放回                                               |
| 概率空间                | 基本事件                                                     |
|                         | 彩球模型：抽不同颜色的球(同一容器)                           |
|                         | 分配模型：不同的容器                                         |
| 概率                    | 加法                                                         |
|                         | 独立性                                                       |
|                         | 条件概率  全概公式  贝叶斯公式                               |
| 常见分布  S.209-210     | 伯努利试验  离散分布  0-1分布  B(n, p)二项分布  H(N, r, n)超几何分布  几何分布  P(λ)泊松分布  负二项分布  连续分布  均匀分布  正态分布  γ分布：指数分布  卡方分布  t分布  F分布 |
| 随机变量                | 分布的参数  期望  方差  标准差  分位数：α，1-α  中位数  矩：原点矩，中心矩 |
|                         | 计算法则  期望  方差                                         |
| 多元随机变量  S.211-212 | 相加的计算公式：  期望  方差  协方差  相关系数               |
|                         | 独立的随机变量相加                                           |
|                         | 中心极限定理：分布的渐近表示                                 |

| 【统计】                       |                                                              |
| ------------------------------ | ------------------------------------------------------------ |
| 样本                           | 总体：随机变量X  分布：F  样本：x1,  x2,…, xn  样本分布服从总体分布：X1, X2,…, Xn ~ F |
|                                | 直方图==概率分布                                             |
| 样本函数与计算                 | 样本均值  样本方差  修饰后的样本方差                         |
| @统计量                        | 统计量(==特殊的样本函数)服从其他分布  比如一般正态分布——>归一化正态分布 |
| @==统计量的分布== => 抽样分布  |                                                              |
| 点估计                         | 常用点估计  已知分布，未知参数                               |
| 置信区间                       | 置信区间  已知分布，未知参数  置信水平 α  单边/单尾  双边/双尾 |
| 分布假设的参数检验  ==假设检验 | 零假设；备择假设  I类错误；II类错误  拒绝域                  |
| @基于显著性水平α的参数检验     | 统计量是否在置信域？                                         |
| @Kolmogorov检验                | 分布未知——>检验分布                                          |
| @卡方检验                      | 分布未知——>检验分布  基于直方图：数据密度分布                |