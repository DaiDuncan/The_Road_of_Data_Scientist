@Roam 领域: 数学(运筹学: 最优化 图论)

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221195420.png" alt="PROBABILITY  MODEL  CAUSES  DATA  EVENTS  STATISTICS " style="zoom:67%;" />





# 概率

统计与概率的关系：

- 基于已知模型——>数据的概率分布

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210117205908.png" alt="image-20210117205907893" style="zoom:80%;" />



| 概率模型 |                                    |
| -------- | ---------------------------------- |
| 排列组合 | 有放回                             |
|          | 无放回                             |
| 概率空间 | 基本事件                           |
|          | 彩球模型：抽不同颜色的球(同一容器) |
|          | 分配模型：不同的容器               |
| 概率计算 | 加法                               |
|          | 独立性                             |
|          | 条件概率：全概公式，贝叶斯公式     |



## 常见分布

| 常见分布@德语版公式 |            |
| ------------------- | ---------- |
| 【离散】伯努利试验  |            |
| 0-1分布             |            |
| 二项分布            | B(n, p)    |
| 超几何分布          | H(N, r, n) |
| 几何分布            | P(λ)       |
| 泊松分布            |            |
| 负二项分布          |            |
|                     |            |
| 【连续】            |            |
| 均匀分布            |            |
| 指数分布 => γ分布   |            |
| 正态分布            |            |
| 卡方分布            |            |
| F分布               |            |
| t分布               |            |

## 正态normal分布与偏态skewed分布

- 中位数跟着频数分布(高峰凸起的地方)走：在平均数和众数中间

![img](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222132319.png)

| 偏态分布                                                    |      |
| ----------------------------------------------------------- | ---- |
| 左偏态 = 左尾分布(也叫负偏态negatively skewed distribution) |      |
| 右偏态 = 右尾分布(也叫正偏态positively skewed distribution) |      |





## 条件概率

全概公式

贝叶斯公式



## 贝叶斯概率⭐

区分**事实**(参数)disease VS 检测(观测值)test ——>根据检测/观察推断事实

- 事实(参数)/disease  VS  检测(观测)/test

- 原因(cause)  VS  结果(effect)

  

贝叶斯法则：

- **先验**概率 P(disease)
- 条件概率 P(test | **disease**) @检测(敏感度：检测存在偏差)
- 似然概率 P(**test** | disease)
- 目标：后验概率 P(disease | test)



@检测：真-假；阳性-阴性

敏感度Sensitivity disease——>检测阳性 

- 带有敏感度，但并非100%确定

特异度Specitivity not disease——>阴性



```python
# numpy.random模块
np.random.randint()
np.random.choice()  #含概率权重

.mean()
.var()
.std()
```



## 技巧|计算概率

- [Generating functions](https://brilliant.org/wiki/generating-functions-solving-recurrence-relations/) 生成函数是一种将事件与多项式关联的方法，可以将概率的计算减少为代数计算
- [bijections](https://brilliant.org/practice/bijections-overview/?chapter=advanced-techniques) 即座位间插入隔离
  - x+y+z+w=10 有多少个非负整数解
    - ![image-20210214221735287](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210214221735.png)
  - 分配座位
  - 确定给定概率问题中的双射本身可能是一项艰巨的任务
- [Geometric probability](https://brilliant.org/wiki/1-dimensional-geometric-probability/)
- [recurrence relation](https://brilliant.org/wiki/recurrence-relations/)
  - 数字序列中的一个元素如何取决于之前的元素@Markov







# 统计

| 概念   |                                                              |
| ------ | ------------------------------------------------------------ |
| 总体   | 随机变量X                                                    |
| 分布   | F                                                            |
| 样本   | 服从总体的分布 X1, X2, …, Xn                                 |
|        | (模拟试验) 二项分布：抛硬币 np.random.binomial(n, p, size=n_trial)<br />结果：一共有**n_trial**次重复抽样**(样本数)，每一次抽样Xi~B(n, p)，得到**样本的统计量**Xi<br />Xi是**一个数：表示n次抛硬币后k次正面朝上的次数(假设p表示正面朝上的概率)<br />  Xi的试验/观测值==(x1, x2, …, xn)——>{正，反，反，正……} |
|        | (总体的抽样) 总体是 np.range(1, 11)：{1, 2, …, 10}<br />假设样本容量为3<br />  样本X1={2, 3, 5}<br />  样本X2={1, 5, 7}<br />  样本X3={4, 3, 5}<br /><br />样本方差的计算：**无偏估计的分母**是n-1 |
| 直方图 | 等价于概率分布                                               |



| 数据类型             |            |
| -------------------- | ---------- |
| 【分类】             |            |
| 定类                 |            |
| 定序                 |            |
|                      |            |
| 【数值】连续，离散   |            |
| 定距                 | 日期、时间 |
| 定比(没有“零”的概念) | 温度       |
| 绝对数量             | 苹果数     |



## 1.1 描述统计|描述收集的数据

度量描述收集的数据：集中趋势度量、离散程度度量、分布形状和异常值

| 【集中趋势】       |                                                              |
| ------------------ | ------------------------------------------------------------ |
| 均值               |                                                              |
| 中位数             |                                                              |
| 众数               |                                                              |
|                    |                                                              |
| 【差异】           |                                                              |
| 极差               |                                                              |
| 矩：原点矩，中心矩 | 方差，标准差                                                 |
|                    | 协方差                                                       |
| 四分位数：含中位数 | @五数概括法：min + np.percentile(a, [25, 50, 75]) + max => 箱线图 |
|                    | 对于**非对称的数据集**，五数概括法和相应的箱形图是了解数据离散程度的很好方法 |
|                    | 四分位差 (IQR):Q3和Q1之间的差值                              |
|                    |                                                              |
| 【分布形状】       |                                                              |
| 正态/对称          |                                                              |
| 偏态               |                                                              |



### 分布形状

![对 称 （ 正 态 ）  右 偏 态  左 偏 态  均 值 与 中 位 数  均 值 等 于 中 亻 立 数  均 值 大 于 中 亻 立 数  均 值 小 于 中 亻 立 数  现 实 世 界 中 的 应 用  身 高 、 体 生 、 误 差 、 降 雨 量  血 液 中 残 留 的 药 物 量 ， 呼 叫 中 心 的 电 讠 占 间 隔 时 间 ， 灯 多 久 熄 火  许 多 大 学 的 成 缋 百 分 比 ， 死 亡 年 龄 ， 资 产 价 格 变 动 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221194514.png)



### 异常值|删除 修正 保留

明显偏离我们其余数据点的点

​	-极大地影响均值和标准差等度量

​	+而对五数概括法中的**第**1四分位数、中位数、第2四分位数的影响较小



==五数概括法==的值通常能比均值和标准差等度量更好地体现异常值的存在



[Link: 论文|如何识别异常值](http://d-scholarship.pitt.edu/7948/1/Seo.pdf)

1. 注意到它们的存在以及对**概括性度量**的影响——均值，方差

2. 如果有拼写错误 —— 删除或改正。

3. 了解它们为什么会存在，以及对我们要回答的关于异常值的问题的影响。

4. 当**有异常值时**，报告五数概括法的值通常能比均值和标准差等度量更好地体现异常值的存在。

5. 报告时要小心。知道如何提出正确的问题。



处理建议：

1. 绘制你的数据以确定是否有异常值。

2. 通过上述方法处理异常值。

   +删除

   +修正

   +保留

3. 正态：==如果**无异常值**==，且你的数据遵循正态分布，==使用**均值和标准差来描述你的数据集**，并报告数据为正态分布==。

@正态分布检验

+正态分位图Q-Qplot https://data.library.virginia.edu/understanding-q-q-plots/

+KS test [https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test](https://en.wikipedia.org/wiki/Kolmogorov–Smirnov_test)

4. 偏态/异常：则使用五数概括法来概括你的数据并报告异常值。





### 注意|标准差

1 方差和标准差都能用于比较两组不同数据的离散程度。

方差/标准差较高的一组数据相比较低的一组数据，其分布更为广泛。

但是注意，有可能只有一个（或多个）异常值提高了方差或者标准差，而大多数数据实际上比较集中。

 

2 在比较两个数据集之间的离散程度时，每个数据集的单位必须相同。



3 当数据与货币或经济有关时，方差（或标准差）更高则表示风险越高。



4 在实践中，标准差比方差更常用，因为它使用原始数据集的单位。



#### 应用

标准差经常用于评估金融风险

帮助确定药物在医学研究中的意义

以及测量预测类计算的结果误差，例如预测明天的降雨量或通勤时间。



@投资

注意，如果你没有全部投在投资 1 或全部投在投资 2，而是分散投资在了这两个选择中，会比单独投资一个赚取更多收益。

这是长期投资情况下多样化投资组合的好处。

对于短期投资，你可能不需要或想要多样化。你可以选择投资 2，幸运地遇到上涨行情（12%、10% 或 7%）并获得短期收益。





## 1.2 推论统计|基于收集的数据推断总体

使用我们收集的数据对更大的总体数据得出结论

- 总体 => 参数
- 样本 => 统计量



大数法则：样本容量越大，统计量越接近参数

中心极限定理：样本容量足够大，样本平均数这个特征量服从正态分布

![image-20210117210242727](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210117210242.png)



| 统计量            |                                                              |
| ----------------- | ------------------------------------------------------------ |
| 【单个指标】      |                                                              |
| 1）绝对指标       | 单个样本组：均值，方差，百分位数等<br />  +点估计<br />  +(置信)区间估计 |
|                   | 多个样本组：均值差等@实验组、对照组                          |
| 2）相对指标(比例) | 单个样本组：点击率等                                         |
|                   | 多个样本组：点击率在网页更新前后的差异@实验组、对照组        |
|                   |                                                              |
|                   |                                                              |
| 【多个指标】      | 注意：校正α                                                  |
|                   |                                                              |



### 抽样分布

抽样：总体的样本

抽样分布的对象：样本的统计量

| 统计量   |                              |
| -------- | ---------------------------- |
| 样本均值 | $\bar{X} = μ$                |
| 样本方差 | $S^2 = \frac{\sigma^2}{n-1}$ |



@放回抽样：bootstrap



### 大数法则⭐

随着**样本容量**增加，样本平均数越来越接近总体平均数(选择合适的统计量，该统计量接近总体参数)

估计方法：

- 最大似然估计

- 矩估计方法

- 贝叶斯估计



### 中心极限定理⭐

**样本容量**足够大，==**平均数**的抽样分布==越接近正态分布







## 2 辛普森悖论(观察数据的角度)

总体绝对数量 VS 样本比例

- 大的样本量&小比例：整体数量依然很大







## 3 置信区间⭐

注意：不能利用置信区间讨论个人用户。置信区间针对总体的集合 ，如比例或平均数。

### 1）传统置信区间(公式法)

基于抽样分布相关知识(大数定理，中心极限定理) ——>建立针对任何参数的置信区间

![image-20210117210500743](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210117210500.png)

| 1 单样本T-Test | 针对总体均值     |
| -------------- | ---------------- |
| 2 双样本T-Test | 比较两个均值     |
| 3 成对 T-Test  | 将个体与自己比较 |
| 4 Z-Test       |                  |
| 5 卡方检验     |                  |
| 6 F检验        |                  |



### 2）Bootstrap(有放回地抽样)⭐

python 中使用 random.choice 实际上是自助法bootstrap



Bootstrap 可以替代上述任何一种方法

1 模拟实验：coffee_red为样本 ==95%置信区间==的构建

- 有放回抽样 .sample()



height是模拟实验均值的汇总列表：即均值的分布

```python
height = []
for _ in range(int(1e4)):
    sample_200 = coffee_red_sample(200, replace = True)
    height.append(sample_200[sample_200['drinks_coffee'] == False]['height'].mean())

inval = (np.percentile(height, 2.5), np.percentile(height, 97.5))
inval	#结果是(65.99291328, 67.5840273828)
```



2 模拟实验：coffee_red为样本 不同样本的**均值差异**

```python
coffee_full = pd.read.csv('coffee-dataset.csv')
coffee_red = coffee_full.sample(200)

bootsample = coffee_red.sample(200, replace=True)
mean_coff = bootsample[bootsample['drinks_coffee']==True]['height'].mean()
mean_noncoff = bootsample[bootsample['drinks_coffee']==False]['height'].mean()
mean_coff - mean_noncoff	#结果是1.960424
```



3 多次重复试验：样本均值差异的分布 => 95%置信区间

![image-20210220213106215](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210220213106.png)

95%置信区间不包含0，说明两种情况的身高确实存在差异(假如没有差异，则身高差为0)





## 4 假设检验⭐(单独成章)



# 重点：回归

[Link: 经典教材]([http://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf](http://www-bcf.usc.edu/~gareth/ISL/ISLR First Printing.pdf))

回归是常用的一种数据分析的方法，通过**规定因变量和自变量**来确定**变量之间的因果关系**，是一种**建立回归模型**，并根据实测数据来**求解模型的各个参数**，然后评价回归模型是否能够很好的拟合实测数据。

学习回归分析，可以帮助我们对数据做出合理的预测。



回归则是监督机器学习的范例之一：

- 线性回归
- 逻辑回归



小结：

1 你学习了如何在 python 里创建**多元线性回归模型**，创建方法其实与创建简单线性回归模型十分类似。

2 你学习了如何编码虚拟数据并解释相应的系数。

3 你学习了**高阶项**，也知道了高阶项会怎么影响系数解释。

4 你知道了多元线性回归模型需要**交互项**意味着什么，也学习了如何确定其它高阶项。但这里需要重申一次，涉及到交互项和高阶项，直接解释系数的重要性就居于其次了，你的==**模型将更侧重于预测效果**，所以其解释效果有所降低==。

5 你学习了模型假设，我们还进一步探讨了**多重共线性**。你学习了**方差膨胀因子**，也知道了多重共线性会如何影响**模型系数和标准误差**。

6 你学习了模型**选择**和特征工程技巧。

7 你学习了**交叉验证**，知道要如何把测试集拆分成训练-测试集，从而判断模型**最好要保留哪些解释变量**(**自变量**)。

## 线性回归

最小二乘法





## 多元线性回归

多元线性回归的基本假设：自变量之间没有相关性

- 警惕：多重共线性

```python
import numpy as np
import pandas as pd
import statsmodels.api as sms;

df = pd.read_csv('./house_prices.csv')
df.head()
```



### 数值变量

![std err  intercept  47.863  area  bedrooms  -0.285  bathrooms  coef  1.007e+04  345.9110  -2925.8063  7345.3917  1.04e+04  7.227  1.03e+04  1.43e+04  0.972  0.515  P>ltl  0.331  0.000  0.775  0.607  (0.025  -1.02e+04  331.743  -2.3e+04  -2 .06e+04  0.9751  3 .04e+04  360.079  1.72e+04  3 .53e+04  Smaller p-values suggest these variables are statistically significant  in relating to the response variable.  Here, only area is statistically significant. ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221201136.png)



### 分类变量

#### 编码方式

 -1 0 1 编码：基于平均值，作为比较的基准线

![Interpretations  1, O ENCODING  Each category is a comparison  to the baseline category  1, O, -1 ENCODING  Each category is a comparison  to the average of all categories ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221215319.png)

要用 1、0 编码预测基准类别，你要用到截距；

![Dep. Variable:  Model:  Method:  Date:  Time:  No. Observations:  Of Residuals:  Of Model:  Covariance Type:  price  OLS  Least Squares  wed, IS Nov 2017  6028  6026  2  nonrobust  R-squared:  Adj. R-squared:  F-statistic:  Prob (F-statistic):  Log-Likelihood:  intercept  ranch  victorian  coef  3_05e+OS  2.701+06  7.411e+OS  std err  1 _21e+04  1 _44e+04  25120  17153  61396  P>ltl  0000  0000  0000  AIC:  BIC:  [0.025  2.81+06  2.39+06  7.13+06  2004  3232810  0.00  4.77  0339  0339  1548.  0.00  -86683  1.734+06  1.734+06  0.975]  3.29+06  3_01e+OS  7.69+06  Omnibus: 1340.120  Prob(Omnibus):  Skew:  Kurtosis:  0000  1.230  5611  Durbin-Watson:  Jarque-Bera (JB):  Prob(J8):  Cond. No. ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221215433.png)



而用 1、0、-1 编码时，你则得让各分类系数分别乘以 -1，从而填补缺失的分类。

示例：

![(df, Col) :  def  INPUT :  df —  the dataframe where col is stored  the categorical colu_mn you want to du_mmy (as a string)  col  OUTPUT :  df —  the dataframe with the added colu_mns  for du_mmy  variables using 1, 0,  —1 coding  (df [coll. l_mique ( ) ) :  f or  idx, val 0  In enu_merate  idx  df [val_0]  df [val_0]  df [coll. nunique :  df [coll. apply(: anbda  df [coll. apply(: anbda  1 if  x: —1 if  val 0  val 0  (df [coll. l_mique ( ) ) :  f or  idx, val 1  In enu_merate  df [coll. nunique :  idx  df [val_l]  df [val_0]  df [val_l]  df [val_l]  del  r e t urn ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222172257.png)

![style  ranch  victorian  ranch  ranch  victorian  lodge  victorian  victorian  ranch  victorian  price  598291  1744259  571669  493676  1101539  456236  1489871  821931  299903  321976  ranch  victorian ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222172302.png)

![Dep. Variable:  Model:  Method:  Date:  Time:  No. Observations:  Of Residuals:  Of Model:  Covariance Type:  price  OLS  Least Squares  wed, IS Nov 2017  6028  6026  2  nonrobust  R-squared:  Adj. R-squared:  F-statistic:  Prob (F-statistic):  Log-Likelihood:  AIC:  BIC:  0.339  0339  1548.  0.00  -86683  1.734+06  1.734+06  intercept  ranch  victorian  coef  6.421+06  -6.695+04  4 _ 04e+OS  std err  5864251  8233489  7377372  109877  -8.131  64763  P>ltl  0000  0000  0000  [0.025  6.31+06  -8.31+04  3.9+06  2004  0.975]  6_S4e+OS  -6.08+04  4_18e+OS  Omnibus: 1340.120  Prob(Omnibus):  Skew:  Kurtosis:  0 000  1.230  5611  Durbin-Watson:  Jarque-Bera (JB):  Prob(J8):  Cond. No.  3232810  0.00  1.84 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221215423.png)

分别让变量牧场式和维多利亚式乘以 -1，可得到如下结果：642100 + 66950 - 404000 = 305050。

还请注意，这与用 0、1 编码模型得出的预测结果是一样的 （舍掉 50 的话）





#### @线性相关

| 满秩                            |                                           |
| ------------------------------- | ----------------------------------------- |
| 行满秩                          |                                           |
| 列满秩                          |                                           |
| 方阵满秩：行列式不为0(充要条件) |                                           |
| 非方阵m*n(假设m>n)              | 那么m所代表的行 永远线性相关              |
|                                 | 所以**非方阵满秩**：假设m>n——相当于列满秩 |

列满秩 => 列线性独立

- 创建虚拟变量时，如果你不舍弃掉一列，那你就得不到稳定解，从 python 里得到的结果也不会可靠到哪去。



注意添加截距列



#### 案例|房屋价格与风格的关系

![img](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221215119.png)

![img](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221215136.png)

舍弃Victoria类型——作为基准变量

​	+截距：如果是Victoria风格，房价是……

​	+lodge：相比Victoria风格，减少741,100美元

​	+ranch：相比Victoria风格，减少471,000美元



#### 例子|非满秩

![Intercept  coef  7. Ole+17  7. Ole*17  7. Ole*17  7. Ole*17  std err  8. 86+17  8. 86+17  8. 86+17  8. 868+17 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221215213.png)

这些置信区间都很大，以致结果并没有什么帮助。

如果你创建的 X 矩阵不满秩，就会出现这种后果

换句话说，在处理每个分类变量时，如果你不舍弃一个相应的虚拟变量列，就会出现这种后果。







## ⭐线性模型假设的常见问题

探索目标：

- 1 相关性关系
- 2 最佳预测
- 3 与因变量关系紧密的因素



常见问题：

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221215652.png" alt="Gareth James  Daniela Witten  Trevor Hastie  Robert Tibshirani  n Introduction  to Statistical  Learning  with Applications in R  @Springer  Problems in  Multiple Linear Regression  A linear relationship doesn't exist  Correlated errors  Non-constant variance  Outliers  Multicollinearity " style="zoom:80%;" />



### 1 线性假设？

如果线性假设不为真，那你的预测结果就不会很准确，此外，与系数有关的线性关系也就没什么用了。



为了评估某段线性关系是否合理，一个很实用的方法是做预测值$\hat{y}$的残差图$y-\hat{y}$

- 如果图中出现多个曲线部分，那就意味着线性模型实际上可能并不拟合数据，自变量和因变量存在其它关系。





@偏差 模型

![(a) Unbiased and  Homoscedastic  (c) Biased and  (b) Biased and  Homoscedastic  Homoscedastic  (d) Unbiased and  (e) Biased and  (f) Biased and  Heteroscedastic  Heteroscedastic  Heteroscedastic ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221220031.png)

理想来说，我们想要的是像图片左上角残差图那样的随机散点图(图a)。



创建非线性模型的办法有很多（甚至可以线性模型的形式来创建）

#### 模型中增加交叉项或高阶项

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221221253.png" alt="img" style="zoom:80%;" />

不推荐：解释起来很复杂

​	+保留低阶项

​	+低阶项和高阶项同时作用：无法区分作用来源



#### 如何确定高阶项？

看的是解释变量和反应变量的关系里有多少条曲线

@二次项

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221221346.png" alt="1200  1000  800  600  400  200  -200  —400  -150  100  150 " style="zoom:67%;" />



@三次项：折了两个弯，我们就会想添加一个三阶的关系

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221221401.png" alt="1940  1960  1980  2000 " style="zoom:67%;" />



@交叉项：斜率不一样时，添加交叉项

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221221421.png" alt="¯ I)IXI 4- l)'2X'2  AREA  neighborhood B  neighborhood A  price  area  neighborhood " style="zoom: 50%;" />



#### 小结：从线性关系切入分析

@线性综合模型

![image-20210221221539934](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221221540.png)

![image-20210221221618759](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221221618.png)

结果：最佳模型可能只涉及面积和一个虚拟变量，该虚拟变量应该是关于B住宅区与其他住宅区的比较变量





### 2 相关误差

如果我们是随时间变化来收集的数据（比如预测未来股价或利率），或数据**与空间有关**（如预测洪涝或干旱地区），那就很容易出现相关误差。

通常，我们可以用过去数据点提供的信息（针对与时间有关的数据）或用相邻数据点提供的信息（针对与空间有关的数据）来提高预测结果。



==不考虑相关误差的主要原因==在于：往往你会利用这一相关性，得到更好的未来事件预测数据或空间关联事件预测数据。

要判断是否有相关误差，最常用的方法是观察收集数据的域。

要是你不确定的话，你可以试试一个叫 Durbin-Watson 的检验方法，人们常用该测试来评估误差相关性是否造成问题。还有 ARIMA 或 ARMA 模型，人们常用这两个模型来==利用误差相关性，以便做出更佳预测==。



[Link：Durbin-Watson]([https://en.wikipedia.org/wiki/Durbin%E2%80%93Watson_statistic](https://en.wikipedia.org/wiki/Durbin–Watson_statistic))

[Link：ARIMA 或 ARMA](http://www.statsref.com/HTML/index.html?arima.html)



### 3 非恒定方差和正态分布误差

你预测的值不同，得到的预测值范围也不同，那就意味着方差不恒定。



非恒定方差对预测好坏影响不大，但会导致置信区间和 p 值不准确

这种时候，在预测值接近实际值的那部分区域，系数的置信区间会太泛，而在预测值较远离实际值的区域则会太窄。



通常来说，对数函数（或使用其它反应变量的变换方式）能够 “摆脱” 非恒定方差，而要选择合适的变换方式，我们一般会用 Box-Cox。

[Link：Box-Cox](http://www.statisticshowto.com/box-cox-transformation/)



用预测值的残差图也可以评估非恒定方差。

在上面的残差图中，非恒定方差的标签为 异方差heteroscedasticity。

理想来说，我们要的是一个有异方差残差heteroscedasticity的无偏模型（其**异方差残差**在一定数值范围内保持不变）



虽然并不探讨残差的正态性，如果你想**创建可靠的置信区间**，正态性回归假设就十分重要了

http://www.itl.nist.gov/div898/handbook/pri/section2/pri24.htm



### 4 异常值

远离数据正常趋势的点

异常值**也可能**是准确真实的数据点，而不一定是测量或数据输入错误。

在这种情况下，'修复'就会变得更为主观。



要如何处理这些异常值往往取决于你的分析目的。

线性模型，特别是使用最小二乘法的线性模型，比较容易受到影响，也就是说，大异常值可能会大幅度地左右我们的结果。

当然，异常值也有一些解决技巧，也就是我们常说的==正则化==。



### 5 共线性（多重共线性）⭐

如果我们的==自变量彼此相关==，就会出现多重共线性。

多重共线性的一个主要问题在于：它会导致简单线性回归系数偏离我们想要的方向。



判断是否有多重共线性，最常见的办法是借助==二变量图或 方差膨胀因子 (即 VIFs)==



[Link：多重共线性multicollinearity](https://etav.github.io/python/vif_factor_python.html)

#### 导致问题：

- 1 回归系数与预期关系的反转偏差(预期正，结果系数为负)
- 2 不准确的假设检验结果



#### 判断多重共线性

1）散点图矩阵sb.pairplot

seaborn模块：sb.pairplot(变量列表)

![img](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221220905.png)



2）方差膨胀因子VIFs Variance inflation factors

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221221052.png" alt="v IFi  Xi bo bl.T1 -+- b'2X'2 —f— l)nXn  All other x-variables - excluding - are used to predict then compute " style="zoom:80%;" />

通过所有**其他变量**预测xi变量时，得到R的平方

如果xi与其他变量高度相关：(亮点@可视化要素：变量增减关系)

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221221141.png" alt="VARIABLE  Bedrooms  Bathrooms  Area  Neighborhood  I Type  VIF  23.7  24.5  5.6  3.4  2.7 " style="zoom:80%;" />









某变量的VIFs > 10 说明该变量与其他变量相关性强

```python
# pasty模块中导入dmatrices方法：得到矩阵
from patsy import dmatrices
# statemodels.stats.outliers_influence子类中导入variance_inflation_factor方法
import statsmodels.api as sm;
from statsmodels.stats.outliers_influence import variance_inflation_factor
```

注意：[Link：patsy.dmatrices函数](https://www.jianshu.com/p/e46a1ac36aa5
)接收一个公式字符串和一个数据集（可以是DataFrame或数组的字典），为线性模型创建设计矩阵

```python
# A formula string like "x1 + x2" (for dmatrix()) or "y ~ x1 + x2" (for dmatrices()
patsy.dmatrix(formula_like, data={}, eval_env=0, NA_action='drop', return_type='matrix')
```

![image-20210221221027906](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221221028.png)





#### 处理 

在VIFs>10的变量中，删除最不感兴趣的变量

我们应该删除其中一个变量，因为这些变量彼此相关，所以删除一个会使另一个高 VIF 的变量的 VIF 变小。



#### 结果|删除 bathrooms后

![o  2  VIF Feature  6063896  5346400  5346400  features  Intercept  area  bedrooms ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221221215.png)

删除bathrooms后，并不会影响模型的预测效果





## ⭐特征工程

@Typora 机器学习 特征工程 *针对 多元线性回归*



## ⭐模型评估

@Typora 机器学习 *模型评估*



## ⭐案例|完整过程

@Typora 机器学习 监督学习 *线性回归*





## 逻辑回归

目标：事件(分类情况)**出现的概率** **p**

- 公式1：$\frac{p}{1-p}$ => 可视作概率值 0-1之间

- 公式2：函数转换 $log(\frac{p}{1-p})$

=> 

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210117211341.png" alt="log(  P  bo + blŒ1 + b2Œ2 + " style="zoom:80%;" />

<img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210117211350.png" alt="the Sigmoid  1.0  0.8  0.6  0.2  o.o  bo+b1T1 +b2T'2+••• " style="zoom:80%;" />

横坐标：线性回归方程

纵轴表：概率——>事件发生概率



### 1 数据探索

```python
import numpy as np
import pandas as pd
import statsmodels.api as sm

df = pd.read_csv('./fraud_dataset.csv')
df.head()

df.head()
df.describe()
df.info()
```

![image-20210222100336755](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222100337.png)

#### 虚拟变量

为了保证线性无关：需要删除其中一列

```python
df[['no_fraud', 'fraud']] = pd.get_dummies(df['fraud'])
df = df.drop('no_fraud', axis=1)
```



### 2 建模

```python
#注意添加截距 仅限于statsmodels.api
df['intercept'] = 1 

logit_mod = sm.Logit(df['fraud'], df[['intercept', 'duration']])
results = logit_mod.fit()
results.summary()
```

![Logit Regression Results  Dep. Variable:  Model:  Method:  Date:  Time:  converged:  day_weekday  duration  intercept  fraud  True  Logit  MLE  No. Observations:  Of Residuals:  Of Model:  Pseudo R-squ.:  Log-Likelihood:  LL-Null:  LLR p-value:  8793  8790  Fri, 27 Dec 2019  coef  2.6466  -1_4637  9.8709  True  std err  0804  0290  1.944  z  2816  -5039  5078  P>lzl  o oos  0000  0000  [0.025  0774  -2033  6061  2  0.975]  $319  -0894  13681 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222100623.png)

结果解释：

```python
np.exp(-1.4637), np.exp(2.5465)	#结果(0.231378, 12.762357)
1/np.exp(-1.4637)	#结果4.321921
```

关于duration：0.2313

表示每增加一个单位的duration，诈骗率变为0.23倍(**降低**)

由于$e^{-x}$和$e^x$互为倒数：说法改为每减少一个单位的duration，其他变量不变时，诈骗率**增加**为4.3219倍







#  重点：A/B Test

帮一家公司决定公司网站要不要推出两个新元素

- 本质：假设检验



对照组 & 实验组：

- 对照组为网页旧版本 control group
- 实验组为网页新版本 experimental group



### 注意|评估指标

评估的指标越多，你观察到显著差异的偶然性就越高

好在这个多重比较问题有多种办法可以解决

| [多重比较问题](https://en.wikipedia.org/wiki/Multiple_com) | 1992年瑞典有个研究试图找出电源线对健康的影响，他们收集了高压电源线300米范围内所有住户的样本长达25年，对超过800种疾病一一检查发生率的统计差异。<br />他们发现幼年白血病的发病率是一般人的4倍，还推动政府为此采取行动。  <br />然而，当我们比对超过800种疾病时，有一种以上的疾病因为随机效应而呈现发病率增加是非常可能的。<br />果不其然，后续的研究再也没有发现电源线和幼年白血病的相关及因果关系。 |
| ---------------------------------------------------------- | ------------------------------------------------------------ |
| @解决办法                                                  | Bonferroni 校正：让原显著值除以测试数量  考虑到结果**没几个具有显著性**的，而且指标之间具明显关联，所以我们可以认为的确太保守了。  <br /><img src="https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210221200445.png" alt="亻 吏 用 Bonferroni 校 正 显 著 值 下 列 哪 个 扌 引 示 仍 有 统 计 显 蓍 庄 ？ 谙 选 出 所 有 正 确 选 项 。  汪 册 率  @ 平 均 浏 览 时 长  平 均 教 室 逗 兰 时 长 " style="zoom:80%;" /> |
|                                                            | 一旦指标间有关联，Bonferroni 方案就显得太过保守              |
| 【其余方法  】                                             | 会把**指标间的相关性**考虑在内                               |
| 封闭测试程序                                               | http://en.wikipedia.org/wiki/Closed_testing_procedure        |
| Boole-Bonferroni  联合校正                                 | http://en.wikipedia.org/wiki/Bonferroni_bound                |
| Holm-Bonferroni                                            | [http://en.wikipedia.org/wiki/Holm%E2%80%93Bonferroni_method](http://en.wikipedia.org/wiki/Holm–Bonferroni_method) |
|                                                            | @注意  如果你真的选了没那么保守的方案，请确保方案假设的确适用于你的情况，而不是在  糊弄 p 值。  <br />为了得到显著性结果而**选择不适合的测试方法**只会造成决策有失偏颇，长期下来会伤害到你的公司业绩。 |
|                                                            | @P-HACKING  https://freakonometrics.hypotheses.org/19817     |





### 案例|产品运营测试

假设你在一家**办公软件公司**工作，公司正想办法增加购买其软件的用户数量。

目前产品运营的方式是，用户可以下载软件**并免费试用 7 天**。试用结束后，用户需要购买许可证才能继续使用软件。

 

公司目前**担心**的是，一些潜在用户没有看到试用期，所以没去使用软件。

所以，想更改首页的布局，使 7 天试用期的宣传语**更加醒目**，并放在更靠上的页面位置。如果有更多的用户下载软件并试用，那么就有可能在看到软件的功能后，吸引更多用户购买软件。

 

1 构建用户漏斗

2 分组 & 确定指标

3 实验容量大小

4 检查|有效性

5 分析数据

6 得出结论



# #实验设计

## 分类

实验分类：

- 组间实验：实验对象分组/隔离 =>  A/B Test
- 组内设计：同一实验对象，不同情境
- 析因设计：=> 控制变量法(对照组)



抽样分类：

- 简单随机抽样
- 分层随机抽样
- 非概率抽样：街头问卷调查
  - 务必要考虑结果是否适用于整个人群 => 是否具有代表性





## 实验指标

- 可衡量性(客观量化)



## 实验评估

### 有效性

### 偏差

### 实验道德

### 团队项目

SMART 记忆法包括了如何规划团队项目的几个关键点

Specific（具体）：确保实验目标很具体。

Measurable（可衡量）：结果必须能用客观指标衡量。

Achievable（切实可行）：实验采取的措施和目标必须符合现实，具有可行性。

Relevant（相关）：实验必须有一定的目的。

Timely（及时）：必须能在合理的期限内获得结果。



### 注意：相关!=因果





## 统计分析

显著性

- 实际显著性
- 统计显著性





## 非参数检验1

主要优势是，不依赖于对底层总体做出很多假设，与标准检验相比，非参数检验适用于更广泛的情形



### 1 自助法 Bootstrap

有放回地抽样：局限于样本(不产生异常值)

- 对照组归对照组

- 实验组归实验组







### 2 置换检验 Permutation

置换组与组之间的数据分布

标签/数据置换：检验极端/异常值

- 置换/打乱对照组和实验组：比较两组90%分位数的差异





## 非参数检验2

不需要重新抽样，仅对存在的数据进行检验

### 1 秩和检验（曼-惠特尼U检验）





### 2 符号检验





# 补充|样本方差的计算公式

[Link: 参考|知乎](https://www.zhihu.com/question/20099757)

| #概念          |                                                              |
| -------------- | ------------------------------------------------------------ |
| 总体X          | 个体：$x_i$                                                  |
| @总体均值      | $\mu = E\{X\}$                                               |
| @总体方差var() | $\sigma^2=E\{(X-\mu)^2\}$                                    |
|                |                                                              |
| 样本$X_i$      | 个体：$x_i$                                                  |
| @样本均值      | $\bar{X_i}=\frac{1}{n} \cdot \sum_{i=1}^n x_i$               |
| @样本方差$S^2$ | 结论：  ![img](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222114907.png) |



## 关于样本方差$S^2$

关键点：无偏估计

| 问题背景                                                     | 不知道μ的大小——只能计算出$\bar{X_i}$                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1 对于某次采样而言(感性认识)                                 | 当$\mu=\bar{X}$时，下式取得最小值：$\sum_{i=1}^{n}(X_i - \mu)^2$ |
|                                                              | ![image-20210222115533451](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222115533.png) |
|                                                              | ![image-20210222115555831](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222115556.png) |
| 2 无偏估计                                                   | ![E[S2] ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222115616.png) |
| @$\bar{X}$和$\mu$都是常数                                    | ![image-20210222115716246](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222115716.png) |
| 3 证明  <br />![1 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222115732.png) | [Link: stackexchage](https://math.stackexchange.com/questions/1363505/prove-that-e-overlinex-mu2-frac1n-sigma2)<br />@样本Xi随机独立(计算过程：基于均值 & 方差的性质)<br />![Let  2 results  1) var(aXi)  be n independent random variables with mean and variance a2. We need  a2 x var(Xi)  2) = war(Xi).  Also, Expectation is a linear operator. That is  E[ax + W] = aE[X] + bE[Y] ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222115828.png) |
| @结论1                                                       | 样本均值的期望等于总体的均值   <br />![Ε[Χι] ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222115849.png) |
| @结论2                                                       | ==样本均值的方差等于总体方差的1/n==<br />——利用==**样本均值的方差**==估计方差(@IF 信息融合)  <br />![( ざ ミ  (tx)aoa  x ー ざ Ⅱ ち 、 ・ ・ ざ 強 ](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222115913.png) |
| 4 最终结论(结合上述2 和 3)                                   | ![image-20210222120002997](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222120003.png) |
| @保证无偏估计  ![img](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222120017.png) | ![img](https://cdn.jsdelivr.net/gh/DaiDuncan/PicUploader/img/20210222120030.png) |

